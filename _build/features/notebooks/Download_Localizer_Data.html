---
redirect_from:
  - "/features/notebooks/download-localizer-data"
interact_link: content/features/notebooks/Download_Localizer_Data.ipynb
kernel_name: dartbrains
kernel_path: content/features/notebooks
has_widgets: false
title: |-
  Download Localizer Data
pagenum: 8
prev_page:
  url: /features/notebooks/2_Introduction_to_Pandas.html
next_page:
  url: /features/notebooks/Glossary.html
suffix: .ipynb
search: data lets dataset download available osfclient file osf io bids using dimension image imaging tutorials task different read only package github sure course our datasets need standard format pybids functional ok try looks nifti open pinel localizer several types visual e modality also auditory trials across total original paper com provides create subjects working smaller files entire version already python command us being downloaded neuroimaging test docker container install run get load braindata debugging d dimensional nibabel dimensions correctly extra squeeze new back worked written luke chang designed probe basic cognitive processes such perception finger tapping language math tasks cued

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Download Localizer Data</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Download-Data">Download Data<a class="anchor-link" href="#Download-Data"> </a></h1><p><em>Written by Luke Chang</em></p>
<p>Many of the imaging tutorials will use open data from the Pinel Localizer task.</p>
<p>The Pinel Localizer task was designed to probe several different types of basic cognitive processes, such as visual perception, finger tapping, language, and math. Several of the tasks are cued by reading text on the screen (i.e., visual modality) and also by hearing auditory instructions (i.e., auditory modality). The trials are randomized across conditions and have been optimized to maximize efficiency for a rapid event related design. There are 100 trials in total over a 5-minute scanning session. Read the original <a href="https://bmcneurosci.biomedcentral.com/articles/10.1186/1471-2202-8-91">paper</a> for more specific details about the task and the <a href="https://doi.org/10.1016/j.neuroimage.2015.09.052">dataset paper</a>.</p>
<p>This dataset is well suited for these tutorials as it is (a) publicly available to anyone in the world, (b) relatively small (only about 5min), and (c) provides many options to create different types of contrasts.</p>
<p>There are a total of 94 subjects available, but we will primarily only be working with a smaller subset of about 30.</p>
<p>Downloading the data is very easy as it is currently available on the <a href="https://osf.io/vhtf6/files/">OSF website</a>.</p>
<p>We will use the <code>osfclient</code> <a href="https://github.com/osfclient/osfclient">package</a> to download the entire dataset. Note, that the entire dataset is fairly large (~5.25gb), so make sure you have space on your computer. At some point, we will make a smaller version for the dartbrain course available for download.</p>
<p>If you are taking the Psych60 course at Dartmouth, we have already made the download available on the jupyterhub server.</p>
<p>Let's first make sure the <code>osfclient</code> package is installed in our python environment.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>pip install osfclient
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Requirement already satisfied: osfclient in /Users/lukechang/anaconda3/lib/python3.7/site-packages (0.0.3)
Requirement already satisfied: six in /Users/lukechang/anaconda3/lib/python3.7/site-packages (from osfclient) (1.14.0)
Requirement already satisfied: tqdm in /Users/lukechang/anaconda3/lib/python3.7/site-packages (from osfclient) (4.42.1)
Requirement already satisfied: requests in /Users/lukechang/anaconda3/lib/python3.7/site-packages (from osfclient) (2.23.0)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /Users/lukechang/anaconda3/lib/python3.7/site-packages (from requests-&gt;osfclient) (2.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /Users/lukechang/anaconda3/lib/python3.7/site-packages (from requests-&gt;osfclient) (3.0.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /Users/lukechang/anaconda3/lib/python3.7/site-packages (from requests-&gt;osfclient) (2019.11.28)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /Users/lukechang/anaconda3/lib/python3.7/site-packages (from requests-&gt;osfclient) (1.25.8)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>osfclient provides a command line interface built in python that can help us easily download (and also upload) datasets being shared on the Open Science Framework (OSF).</p>
<p>All we need to do is specifiy the OSF project id and the directory where we would like the data downloaded.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">project_id</span> <span class="o">=</span> <span class="s1">&#39;vhtf6&#39;</span>
<span class="n">output_directory</span> <span class="o">=</span> <span class="s1">&#39;/Users/lukechang/Dropbox/Dartbrains/Data&#39;</span>

<span class="o">!</span>osf -p <span class="o">{</span>project_id<span class="o">}</span> clone <span class="o">{</span>output_directory<span class="o">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The dataset has been converted to be in a standard data format known as the <a href="https://bids.neuroimaging.io/">Brain Imaging Data Structure</a> format or BIDS for short. BIDS is a specification to organize imaging datasets in a standard way across different laboratories. It contains a structured format for people to find relevant information for analyzing the dataset.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Test-Data">Test Data<a class="anchor-link" href="#Test-Data"> </a></h1><p>Let's look at the data to make sure everything downloaded properly.</p>
<p>This example assumes that you are using the docker container associated with the course.</p>
<p>We will use <a href="https://bids-standard.github.io/pybids/">pybids</a> to explore the dataset. It should already be in included in the dartbrains docker container. Otherwise, you can install it using pypi with <code>!pip install pybids</code>.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">bids</span> <span class="kn">import</span> <span class="n">BIDSLayout</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;/home/jovyan/Data&#39;</span>

<span class="n">layout</span> <span class="o">=</span> <span class="n">BIDSLayout</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">derivatives</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">layout</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>BIDS Layout: .../home/jovyan/Data | Subjects: 94 | Sessions: 0 | Runs: 0</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This shows us that there are 94 subjects with only a single functional run.</p>
<p>We can query the <code>BIDSLayout</code> object to get all of the file names for each participant's functional data. Let's just return the first 10.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">file_list</span> <span class="o">=</span> <span class="n">layout</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;subject&#39;</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;file&#39;</span><span class="p">,</span> <span class="n">extension</span><span class="o">=</span><span class="s1">&#39;nii.gz&#39;</span><span class="p">)</span>
<span class="n">file_list</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;/home/jovyan/Data/sub-S01/func/sub-S01_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S02/func/sub-S02_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S03/func/sub-S03_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S04/func/sub-S04_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S05/func/sub-S05_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S06/func/sub-S06_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S07/func/sub-S07_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S08/func/sub-S08_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S09/func/sub-S09_task-localizer_bold.nii.gz&#39;,
 &#39;/home/jovyan/Data/sub-S10/func/sub-S10_task-localizer_bold.nii.gz&#39;]</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok, now let's try to load one of the functional datasets using <code>Brain_Data</code> from the nltools package.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nltools.data</span> <span class="kn">import</span> <span class="n">Brain_Data</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">file_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/miniconda-latest/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.
  warnings.warn(message, FutureWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">-----------------------------------------------------------------------</span>
<span class="ansi-red-fg">DimensionError</span>                        Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-11-02e4f9a25936&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> <span class="ansi-green-fg">from</span> nltools<span class="ansi-blue-fg">.</span>data <span class="ansi-green-fg">import</span> Brain_Data
<span class="ansi-green-intense-fg ansi-bold">      2</span> 
<span class="ansi-green-fg">----&gt; 3</span><span class="ansi-red-fg"> </span>data <span class="ansi-blue-fg">=</span> Brain_Data<span class="ansi-blue-fg">(</span>file_list<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/opt/miniconda-latest/lib/python3.7/site-packages/nltools/data/brain_data.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, data, Y, X, mask, output_file, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    132</span>                 <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    133</span>                     data <span class="ansi-blue-fg">=</span> nib<span class="ansi-blue-fg">.</span>load<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 134</span><span class="ansi-red-fg">                 </span>self<span class="ansi-blue-fg">.</span>data <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>nifti_masker<span class="ansi-blue-fg">.</span>fit_transform<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    135</span>             <span class="ansi-green-fg">elif</span> isinstance<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">,</span> list<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    136</span>                 <span class="ansi-green-fg">if</span> isinstance<span class="ansi-blue-fg">(</span>data<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> Brain_Data<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/miniconda-latest/lib/python3.7/site-packages/nilearn/input_data/base_masker.py</span> in <span class="ansi-cyan-fg">fit_transform</span><span class="ansi-blue-fg">(self, X, y, confounds, **fit_params)</span>
<span class="ansi-green-intense-fg ansi-bold">    205</span>                                 ).transform(X, confounds=confounds)
<span class="ansi-green-intense-fg ansi-bold">    206</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 207</span><span class="ansi-red-fg">                 </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">**</span>fit_params<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>transform<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">,</span> confounds<span class="ansi-blue-fg">=</span>confounds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    208</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    209</span>             <span class="ansi-red-fg"># fit method of arity 2 (supervised transformation)</span>

<span class="ansi-green-fg">/opt/miniconda-latest/lib/python3.7/site-packages/nilearn/input_data/base_masker.py</span> in <span class="ansi-cyan-fg">transform</span><span class="ansi-blue-fg">(self, imgs, confounds)</span>
<span class="ansi-green-intense-fg ansi-bold">    175</span>         self<span class="ansi-blue-fg">.</span>_check_fitted<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    176</span> 
<span class="ansi-green-fg">--&gt; 177</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>transform_single_imgs<span class="ansi-blue-fg">(</span>imgs<span class="ansi-blue-fg">,</span> confounds<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    178</span> 
<span class="ansi-green-intense-fg ansi-bold">    179</span>     <span class="ansi-green-fg">def</span> fit_transform<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> X<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> confounds<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>fit_params<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/miniconda-latest/lib/python3.7/site-packages/nilearn/input_data/nifti_masker.py</span> in <span class="ansi-cyan-fg">transform_single_imgs</span><span class="ansi-blue-fg">(self, imgs, confounds, copy)</span>
<span class="ansi-green-intense-fg ansi-bold">    403</span>             confounds<span class="ansi-blue-fg">=</span>confounds<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    404</span>             copy<span class="ansi-blue-fg">=</span>copy<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 405</span><span class="ansi-red-fg">             </span>dtype<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>dtype
<span class="ansi-green-intense-fg ansi-bold">    406</span>         )
<span class="ansi-green-intense-fg ansi-bold">    407</span> 

<span class="ansi-green-fg">/opt/miniconda-latest/lib/python3.7/site-packages/joblib/memory.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    360</span> 
<span class="ansi-green-intense-fg ansi-bold">    361</span>     <span class="ansi-green-fg">def</span> __call__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 362</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>func<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    363</span> 
<span class="ansi-green-intense-fg ansi-bold">    364</span>     <span class="ansi-green-fg">def</span> call_and_shelve<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/opt/miniconda-latest/lib/python3.7/site-packages/nilearn/input_data/nifti_masker.py</span> in <span class="ansi-cyan-fg">filter_and_mask</span><span class="ansi-blue-fg">(imgs, mask_img_, parameters, memory_level, memory, verbose, confounds, copy, dtype)</span>
<span class="ansi-green-intense-fg ansi-bold">     39</span>                     copy<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     40</span>                     dtype=None):
<span class="ansi-green-fg">---&gt; 41</span><span class="ansi-red-fg">     </span>imgs <span class="ansi-blue-fg">=</span> _utils<span class="ansi-blue-fg">.</span>check_niimg<span class="ansi-blue-fg">(</span>imgs<span class="ansi-blue-fg">,</span> atleast_4d<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> ensure_ndim<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">4</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     42</span> 
<span class="ansi-green-intense-fg ansi-bold">     43</span>     <span class="ansi-red-fg"># Check whether resampling is truly necessary. If so, crop mask</span>

<span class="ansi-green-fg">/opt/miniconda-latest/lib/python3.7/site-packages/nilearn/_utils/niimg_conversions.py</span> in <span class="ansi-cyan-fg">check_niimg</span><span class="ansi-blue-fg">(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)</span>
<span class="ansi-green-intense-fg ansi-bold">    274</span> 
<span class="ansi-green-intense-fg ansi-bold">    275</span>     <span class="ansi-green-fg">if</span> ensure_ndim <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span> <span class="ansi-green-fg">and</span> len<span class="ansi-blue-fg">(</span>niimg<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">!=</span> ensure_ndim<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 276</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">raise</span> DimensionError<span class="ansi-blue-fg">(</span>len<span class="ansi-blue-fg">(</span>niimg<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> ensure_ndim<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    277</span> 
<span class="ansi-green-intense-fg ansi-bold">    278</span>     <span class="ansi-green-fg">if</span> return_iterator<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">DimensionError</span>: Input data has incompatible dimensionality: Expected dimension is 4D and you provided a 5D image. See http://nilearn.github.io/manipulating_images/input_output.html.</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Uh, oh...  This simple command isn't working. Here is your first lesson that things are always a little messy and require debugging.</p>
<p>Let's try to figure out what is going on.</p>
<p>First, let's look at the error and try to see what went wrong.</p>
<blockquote><p>DimensionError: Input data has incompatible dimensionality: Expected dimension is 4D and you provided a 5D image. See <a href="http://nilearn.github.io/manipulating_images/input_output.html">http://nilearn.github.io/manipulating_images/input_output.html</a>.</p>
</blockquote>
<p>It looks like that the data is being read in as a 5 dimensional image rather than a four dimensional image. <code>Brain_Data</code> can't read this type of data. Perhaps it's because this nifti file was created using an older version of SPM.</p>
<p>Let's test our hypothesis and use nibabel to load the data and inspect the shape of the data file.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">nibabel</span> <span class="k">as</span> <span class="nn">nib</span>

<span class="n">dat</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">dat</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(64, 64, 40, 1, 128)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ok, it looks like the first 3 dimensions are correctly describing the spatial dimensions of the data and the fifth dimension reflects the number of volumes in the dataset.</p>
<p>Notice that there is an extra dimension of <code>1</code> that we need to remove. We can do that with the numpy <code>squeeze</code> function.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/miniconda-latest/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).

* deprecated from version: 3.0
* Will raise &lt;class &#39;nibabel.deprecator.ExpiredDeprecationError&#39;&gt; as of version: 5.0
  &#34;&#34;&#34;Entry point for launching an IPython kernel.
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(64, 64, 40, 128)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>squeeze</code> gets rid of that extra dimension. Now we need to create a new nifti image with the correct data and write it back out to a file that we can use later.</p>
<p>We will initialize a new nibabel nifti instance and write it out to file.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dat_fixed</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">dat</span><span class="o">.</span><span class="n">get_data</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">dat</span><span class="o">.</span><span class="n">affine</span><span class="p">)</span>
<span class="n">nib</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">dat_fixed</span><span class="p">,</span> <span class="n">file_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/opt/miniconda-latest/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).

* deprecated from version: 3.0
* Will raise &lt;class &#39;nibabel.deprecator.ExpiredDeprecationError&#39;&gt; as of version: 5.0
  &#34;&#34;&#34;Entry point for launching an IPython kernel.
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's double check that this worked correctly.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(64, 64, 40, 128)</pre>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ok! Looks like it worked!</p>
<p>Now let's fix the rest of the files so we can work with the data in all of the tutorials.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">file_list</span> <span class="o">=</span> <span class="n">layout</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="s1">&#39;subject&#39;</span><span class="p">,</span> <span class="n">suffix</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">return_type</span><span class="o">=</span><span class="s1">&#39;file&#39;</span><span class="p">,</span> <span class="n">extension</span><span class="o">=</span><span class="s1">&#39;nii.gz&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">file_list</span><span class="p">:</span>
    <span class="n">dat</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">dat</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">:</span>
        <span class="n">dat_fixed</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">dat</span><span class="o">.</span><span class="n">fget_data</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">dat</span><span class="o">.</span><span class="n">affine</span><span class="p">)</span>
        <span class="n">nib</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">dat_fixed</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's go back to our original code we tried to run that initially failed.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">file_list</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It works!</p>
<p>Get used to debugging, it is a crucial part of neuroimaging data analysis, but can be a frustrating process.</p>

</div>
</div>
</div>
</div>

 


    </main>
    