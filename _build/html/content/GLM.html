
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Introduction to the General Linear Model &#8212; DartBrains</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e2363ea40746bee74734a24ffefccd78.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="http://dartbrains.org/content/GLM.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Modeling Single Subject Data" href="GLM_Single_Subject_Model.html" />
    <link rel="prev" title="Preprocessing" href="Preprocessing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/dartbrains_logo_square_transparent.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DartBrains</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Course Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Instructors.html">
   Instructors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Schedule.html">
   Schedule
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Computing Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_JupyterHub.html">
   Introduction to JupyterHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Download_Data.html">
   Download Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Programming.html">
   Introduction to programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Pandas.html">
   Introduction to Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Plotting.html">
   Introduction to Plotting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Glossary.html">
   Glossary
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Course Topics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_to_Neuroimaging.html">
   Introduction to Neuroimaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Measurement.html">
   Signal Generation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ICA.html">
   Separating Signal From Noise With ICA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Neuroimaging_Data.html">
   Introduction to Neuroimaging Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Processing.html">
   Signal Processing Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Preprocessing.html">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction to the General Linear Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="GLM_Single_Subject_Model.html">
   Modeling Single Subject Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Group_Analysis.html">
   Group Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Thresholding_Group_Analyses.html">
   Thresholding Group Analyses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Connectivity.html">
   Connectivity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multivariate_Prediction.html">
   Multivariate Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="RSA.html">
   Representational Similarity Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Resampling_Statistics.html">
   Resampling Statistics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Additional Courses
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="http://naturalistic-data.org/">
   Naturalistic Data Analysis
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Project Gallery
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2019_Spring.html">
   Spring 2019
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Spring.html">
   Spring 2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Fall.html">
   Fall 2020
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ljchang/dartbrains">
   GitHub Repository
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Post questions to <a href='https://www.askpbs.org/c/dartbrains'>DartBrains Discourse</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/GLM.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ljchang/dartbrains"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ljchang/dartbrains/issues/new?title=Issue%20on%20page%20%2Fcontent/GLM.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/ljchang/dartbrains/edit/master/content/GLM.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ljchang/dartbrains/master?urlpath=tree/content/GLM.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://jhub.dartmouth.edu//hub/user-redirect/git-pull?repo=https://github.com/ljchang/dartbrains&urlpath=tree/dartbrains/content/GLM.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/ljchang/dartbrains/blob/master/content/GLM.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#are-you-ready-for-this">
   Are you ready for this?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-a-voxel-time-course">
   Simulate a voxel time course
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-design-matrix">
   Construct Design Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimate-glm">
   Estimate GLM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-errors">
     Standard Errors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explained-variance">
     Explained Variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-error-of-beta-estimates">
     Standard Error of $\beta$ estimates
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#statistical-significance">
     Statistical Significance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contrasts">
     Contrasts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#efficiency">
     Efficiency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#varying-the-inter-trial-interval-with-jittering">
     Varying the Inter-Trial Interval with Jittering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autocorrelation">
     Autocorrelation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1-what-happens-when-we-vary-the-signal-amplitude">
     Exercise 1. What happens when we vary the signal amplitude?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-2-what-happens-when-we-vary-the-noise">
     Exercise 2. What happens when we vary the noise?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-3-how-many-trials-do-we-need">
     Exercise 3. How many trials do we need?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-4-what-is-the-impact-of-the-stimulus-duration">
     Exercise 4. What is the impact of the stimulus duration?
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction-to-the-general-linear-model">
<h1>Introduction to the General Linear Model<a class="headerlink" href="#introduction-to-the-general-linear-model" title="Permalink to this headline">¶</a></h1>
<p><em>Written by Luke Chang</em></p>
<p>This tutorial provides an introduction for how the general linear model (GLM) can be used to make inferences about brain responses in a single subject. We will explore the statistics in the context of a simple hypothetical experiment using simulated data.</p>
<p>In this lab we will cover:</p>
<ul class="simple">
<li><p>How to use a GLM to test psychological hypotheses.</p></li>
<li><p>Simulating brain data</p></li>
<li><p>Estimating GLM using ordinary least squares</p></li>
<li><p>Calculating Standard Errors</p></li>
<li><p>Contrast Basics</p></li>
</ul>
<p>Let’s start by watching two short videos introducing the general linear model by Tor Wager and how this can be applied to fMRI.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>

<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;GDkLQuV4he4&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/GDkLQuV4he4"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;OyLKMb9FNhg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/OyLKMb9FNhg"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<div class="section" id="are-you-ready-for-this">
<h2>Are you ready for this?<a class="headerlink" href="#are-you-ready-for-this" title="Permalink to this headline">¶</a></h2>
<p>This lab assumes that you have some basic background knowledge in statistics from an introductory course. If you are already feeling overwhelmed from Tor Wager’s videos and think you might need to slow down and refresh some basic concepts and lingo, I highly encourage you to watch Jeannette Mumford’s crash course in statistics. These are certainly not required, but she is a wonderful teacher and watching her videos will provide an additional explanation of the core concepts needed to understand the GLM. You could watch these in one sitting, or go back and forth with working through the notebooks. There is so much to know in statistics and people can often feel lost because the concepts are certainly not intuitive. For example, even though advanced statistics have been an important part of my own work, I still find it helpful to periodically revisit core concepts. In general, I find that learning neuroimaging is an iterative process. In the beginning, it is important to get a broad understanding of the key steps and how neuroimaging can be used to make inferences, but as you progress in your training you will have plenty of opportunities to zoom into specific steps to learn more about particular details and nuances that you may not have fully appreciated the first time around.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/apt8uAgtgdY">Basic statistics terminology</a> This video gently introduces some of the key concepts that provide the foundation for statistics.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=yLgPpmXVVbs">Simple Linear Regression</a> This video explains how a regression works using a single variable.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=fkZj8QoYjq8">Matrix Algebra Basics</a> This video provides the background linear algebra needed for understanding the GLM.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=qdOG7YMolmA">Multiple Linear Regression</a> This video explains how multiple regression works using linear algebra.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=ULeg3DH3g9w">Hypothesis Testing</a> This video covers the basics of hypothesis testing.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=yLgPpmXVVbs&amp;t=631s">Contrasts in Linear Models</a> This video provides an overview of how to test hypotheses using contrasts in the context of the GLM.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=uClfe4pLrCo">Intepreting Regression Parameters</a> This video covers how to interpret the results from a regression analysis.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=K4S576j90N8">Mean Centering Regressors</a> This video covers a more subtle detail of why you might consider mean centering your continuour regression variables.</p></li>
</ul>
<p>Ok, let’s get started. First, we will need to import all of the modules used in this tutorial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">nltools.stats</span> <span class="kn">import</span> <span class="n">regress</span>
<span class="kn">from</span> <span class="nn">nltools.external</span> <span class="kn">import</span> <span class="n">glover_hrf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/lukechang/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.
  warnings.warn(message, FutureWarning)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="simulate-a-voxel-time-course">
<h2>Simulate a voxel time course<a class="headerlink" href="#simulate-a-voxel-time-course" title="Permalink to this headline">¶</a></h2>
<p>To generate an intuition for how we use the GLM to make inferences in fMRI data analysis, we will simulate a time series for a single voxel. A simulation means that we will be generating synthetic data that will resemble real data. However, because we know the ground truth of the signal, we can evaluate how well we can recover the true signal using a general linear model. Throughout this course, we frequently rely on simulations to gain an intuition for how a particular preprocessing step or statistic works. This is important because it reinforces the assumptions behind the operation (which are rarely met in real data), and also provides a method to learn how to answer your own questions by generating your own simulations.</p>
<p>Imagine that we are interested in identifying which region of the brain is involved in processing faces. To explore this question, we could show participants a bunch of different types of faces. Each presentation of a face will be a <em>trial</em>. Let’s simulate what a design might look like with 5 face trials.</p>
<p>First, we will need to specify the number of volumes in the time series. Then we need to specify the timepoint, in which a face is presented.</p>
<p><img alt="faces" src="../_images/faces.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">plot_timeseries</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Plot a timeseries</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        data: (np.ndarray) signal varying over time, where each column is a different signal.</span>
<span class="sd">        labels: (list) labels which need to correspond to the number of columns.</span>
<span class="sd">        linewidth: (int) thickness of line</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">linewidth</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Intensity&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">!=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Need to have the same number of labels as columns in data.&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    
<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">face</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_7_0.png" src="../_images/GLM_7_0.png" />
</div>
</div>
<p>We now have 5 events where a face is shown for 2 seconds (i.e., one TR). If we scanned someone with this design, we might expect to see any region involved in processing faces increase in activation around the time of the face presentation. How would we know which of these regions, if any, <em>selectively</em> process faces? Many of the regions we would observe are likely involved in processing <em>any</em> visual stimulus, and not specifically faces.</p>
<p>To rule out this potential confound, we would need at least one other condition that would serve as a visual control. Something that might have similar properties to a face, but isn’t a face.</p>
<p>One possibility is to create a visual stimulus that has all of the same visual properties in terms of luminance and color, but no longer resembles a face. Here is an example of the same faces that have been Fourier transformed, phase-scrambled, and inverse Fourier transformed. These pictures have essentially identical low level visual properties, but are clearly not faces.</p>
<p><img alt="phase" src="../_images/phase_scrambled.png" /></p>
<p>However, one might argue that faces are a type of object, and regions that are involved in higher visual processing such as object recognition might not be selective to processing faces. To rule out this possibility, we would need to add an additional visual control such as objects.</p>
<p><img alt="objects" src="../_images/objects.png" /></p>
<p>Both of these conditions could serve as a different type of visual control. To keep things simple, let’s start with pictures of objects as it controls for low level visual features, but also more complex object processing.</p>
<p>To demonstrate that a region is processing faces and not simply lower level visual properties or objects more generally, we can search for regions that are selectively more activated in response to viewing faces relative to objects. This is called a <em>contrast</em> and is the basic principle of the subtraction method for controlling for potential experimental confounds. Because BOLD fMRI is a relative and not absolute measure of brain activity, the subtraction method is a key aspect of experimental design.</p>
<p>Figures are from Huettel, Song, &amp; McCarthy (2008)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">voxel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">face</span><span class="p">,</span><span class="n">obj</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_9_0.png" src="../_images/GLM_9_0.png" />
</div>
</div>
<p>Let’s imagine that in a voxel processing face specific information we might expect to see a larger activation in response to faces. Maybe two times bigger?</p>
<p>In our simulation, these two values are parameters we are specifying to generate the data. Specifically they refer to the amplitude of the response to Faces and Houses within a particular region of the brain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face_intensity</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">object_intensity</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="n">face_intensity</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="n">object_intensity</span>
<span class="n">voxel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">face</span><span class="p">,</span><span class="n">obj</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_11_0.png" src="../_images/GLM_11_0.png" />
</div>
</div>
<p>Ok, now we have two conditions that are alternating over time.</p>
<p>We know that the brain has a delayed hemodynamic response to events that has a particular shape, so we will need to convolve these events with an appropriate HRF function. Here, we will use the double-gamma HRF function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tr</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hrf</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hrf</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Intensity&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Time&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_13_1.png" src="../_images/GLM_13_1.png" />
</div>
</div>
<p>We will use <code class="docutils literal notranslate"><span class="pre">np.convolve</span></code> from numpy to perform the convolution.  The length of the convolved data will be the length of the time series plus the length of the kernel minus 1. To make sure everything is the same length, we will chop off the extra time off the convolved time series using <code class="docutils literal notranslate"><span class="pre">mode='same'</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">face_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
<span class="n">obj_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
<span class="n">voxel_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">face_conv</span><span class="p">,</span> <span class="n">obj_conv</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel_conv</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_15_0.png" src="../_images/GLM_15_0.png" />
</div>
</div>
<p>While this might reflect the expected HRF response to a single event, real data is much noiser. It is easy to add different types of noise. For example, there might be a low frequency drift, autocorrelation, or possibly some aliased physiological artifacts.</p>
<p>For now, let’s start with something simple, like independent white noise drawn from a random Gaussian distribution</p>
<p>$$\epsilon \sim \mathcal{N}(\mu,,\sigma^{2})$$</p>
<p>where $\mu = 0$ and $\sigma = 0.15$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_tr</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">voxel_conv_noise</span> <span class="o">=</span> <span class="n">voxel_conv</span> <span class="o">+</span> <span class="n">epsilon</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel_conv_noise</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_17_0.png" src="../_images/GLM_17_0.png" />
</div>
</div>
<p>Now this is looking much more like real BOLD activity.</p>
<p>Remember, the goal of this exercise is to generate simulated activity from a voxel. If we were to extract signal from a specific voxel we wouldn’t know which condition was which, so let’s combine these two signals into a single simulated voxel timeseries by adding the two vectors together with the <code class="docutils literal notranslate"><span class="pre">.sum()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">voxel_conv_noise</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_19_0.png" src="../_images/GLM_19_0.png" />
</div>
</div>
</div>
<div class="section" id="construct-design-matrix">
<h2>Construct Design Matrix<a class="headerlink" href="#construct-design-matrix" title="Permalink to this headline">¶</a></h2>
<p>Now that we have our simulated voxel timeseries, let’s try and see if we can recover the original signal using a general linear model in the form of:</p>
<p>$$Y = X\beta + \epsilon$$</p>
<p>where $Y$ is our observed voxel time series. $X$ is our model or design matrix, and is where we will specify a predicted response to each condition. $\beta$ is a vector of values that we will estimate to scale our model. $\epsilon$ is independent gaussian noise. This model is linear because we can decompose $Y$ into a set of features or independent variables that are scaled by an estimated $\beta$ parameter and summed together. The $\epsilon$ parameter is not usually known and can also be estimated.</p>
<p>You may be wondering how our model is distinct from our simulated data. Remember when we simulated the data we specified 3 parameters - face amplitude, object amplitude, and $\epsilon$, we could have also added a mean, but for now, let’s just assume that it is zero. When we fit our model to the simulated data, we should in theory be able to almost perfectly recover these three parameters.</p>
<p>Now let’s build a design matrix $X$ using an intercept, and a regressor indicating the onset of each condition, convolved with the hemodynamic response function (HRF).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">intercept</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_22_0.png" src="../_images/GLM_22_0.png" />
</div>
</div>
<p>We can write our model out so that it is very clear what we are doing.</p>
<p>$$Voxel = \beta_0 \cdot Intercept + \beta_1 \cdot Faces + \beta_2 \cdot Objects + \epsilon$$</p>
<p>We can also make a plot and rotate the timeseries, to better reflect the equation.</p>
<p>It should be clear how each of these components relate to the regression equation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Faces&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Objects&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_24_0.png" src="../_images/GLM_24_0.png" />
</div>
</div>
</div>
<div class="section" id="estimate-glm">
<h2>Estimate GLM<a class="headerlink" href="#estimate-glm" title="Permalink to this headline">¶</a></h2>
<p>Now that have created our simulated voxel timeseries $Y$ and our design matrix $X$, we need to fit our model to the data by estimating the three $\beta$ parameters.</p>
<p>There are several ways to estimate the parameters for our general linear model. The Ordinary Least Squares (OLS) estimator finds the $\hat\beta$ hyperplane that minimizes the error between the observed $Y$ and predicted $\hat Y$.</p>
<p>This can be formulated using linear algebra as:</p>
<p>$$\hat{\beta} = (X^T X)^{-1}X^TY$$</p>
<p>There is also maximum likelihood estimator, which should produce an almost identical result to the ordinary least squares estimator when the error terms are normally distributed.</p>
<p>$$L(\beta, \sigma^2 | Y, X) = \displaystyle \prod_{i=1}^{n}\frac{1}{\sqrt(2\pi\sigma^2)} \cdot e^{-\frac{(Y_i - \beta X_i)^2}{2\sigma^2}}$$</p>
<p>where</p>
<p>$$\mathcal{N}(0,\sigma^{2})$$</p>
<p>For this class, we will primarily be focusing on the Ordinary Least Squares Estimator. In fact, just to demonstrate that the math is actually relatively straightforward, we will write our own function for the estimator using the linear algebra formulation. In practice, we typically will use a premade function, which is usually slightly more computationally efficient and will also calculate standard errors, etc.</p>
<p>For a more in depth overview of GLM estimation, watch this <a class="reference external" href="https://www.youtube.com/watch?v=Ab-5AbJ8gAs">video</a> by Tor Wager and Martin Lindquist.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ols_estimator</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)),</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">beta</span> <span class="o">=</span> <span class="n">ols_estimator</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span><span class="s1">&#39;Faces&#39;</span><span class="p">,</span> <span class="s1">&#39;Objects&#39;</span><span class="p">],</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Regressor&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Beta Value&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;beta Faces - beta Objects: </span><span class="si">{</span><span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">beta</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s1">.2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>beta Faces - beta Objects: 0.95
</pre></div>
</div>
<img alt="../_images/GLM_26_1.png" src="../_images/GLM_26_1.png" />
</div>
</div>
<p>We can see that our model is working pretty well. We did not add a mean to the simulated timeseries, so our estimator correctly figures out that the intercept parameter should be zero. The model also correctly figured out that the scaling parameter for the faces regressor was 2, and 1 for the objects regressor, with the difference between them equal to approximately 1.</p>
<p>Another way to evaluate how well our model is working is to plot our predicted $\hat Y$ on top of our simulated $Y$.</p>
<p>We can quantify the degree to which our model is accurately predicting the observed data by calculating the residual.</p>
<p>$$residual = Y - \hat Y$$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

<span class="n">predicted_ts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">predicted_ts</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Simulated Voxel&#39;</span><span class="p">,</span> <span class="s1">&#39;Predicted Voxel&#39;</span><span class="p">])</span>

<span class="n">residual</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">predicted_y</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Residual&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Residual&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_28_1.png" src="../_images/GLM_28_1.png" />
<img alt="../_images/GLM_28_2.png" src="../_images/GLM_28_2.png" />
</div>
</div>
<div class="section" id="standard-errors">
<h3>Standard Errors<a class="headerlink" href="#standard-errors" title="Permalink to this headline">¶</a></h3>
<p>As you can see, we are doing a reasonable job recovering the original signals.</p>
<p>You may recall that we specified 3 parameters in our simulation</p>
<ul class="simple">
<li><p>a $\beta$ weight for faces</p></li>
<li><p>a $\beta$ weight for objects</p></li>
<li><p>an $\epsilon$ noise parameter.</p></li>
</ul>
<p>The <em>standard error of the estimate</em> refers to the standard deviation of the residual.</p>
<p>Formally, this can be described as:</p>
<p>$$\hat \sigma = \sqrt{\frac{\displaystyle \sum_i^n(\hat Y_i - Y_i)^2}{n-k}}$$</p>
<p>where $n$ is the number of observations and $k$ is the total number of regressors.</p>
<p>This number is essentially an estimate of the overall amount of error in the model or $\epsilon$. This error is assumed to be independent and normally distributed. The smaller the residual variance $\hat\sigma$ the better the fit of the model.</p>
<p>As you can see, the parameter is close, but slightly higher than the one we simulated.  This might be because we have relatively little data in our simulation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">standard_error_of_estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Standard Error of the Estimate: </span><span class="si">{</span><span class="n">standard_error_of_estimate</span><span class="si">:</span><span class="s2">.2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Residual Error&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction Error&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Standard Error of the Estimate: 0.2
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Prediction Error&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_30_2.png" src="../_images/GLM_30_2.png" />
</div>
</div>
</div>
<div class="section" id="explained-variance">
<h3>Explained Variance<a class="headerlink" href="#explained-variance" title="Permalink to this headline">¶</a></h3>
<p>Sometimes we want a single metric to quantify overall how well our model was able to explain variance in the data. There are many metrics that can provide a quantitative measure of <em>goodness of fit</em>.</p>
<p>Here we will calculate $R^2$ using the following formula:</p>
<p>$$R^2 = 1 - \frac{\displaystyle \sum_i^n(\hat y_i - y_i)^2}{\displaystyle \sum_i^n(y_i - \bar y)^2}$$</p>
<p>where $y_i$ is the measured value of the voxel at timepoint $i$, $\hat y_i$ is the predicted value for time point $i$, and $\bar y$ is the mean of the measured voxel timeseries.</p>
<p>$R^2$ will lie on the interval between $[0,1]$ and can be interpreted as percentage of the total variance in $Y$ explained by the model, $X$, where 1 is 100% and 0 is none.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">r_square</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">):</span>
    <span class="n">SS_total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">SS_residual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">predicted_y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="n">SS_residual</span><span class="o">/</span><span class="n">SS_total</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R^2: </span><span class="si">{</span><span class="n">r_square</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">)</span><span class="si">:</span><span class="s2">.2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R^2: 0.6
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="standard-error-of-beta-estimates">
<h3>Standard Error of $\beta$ estimates<a class="headerlink" href="#standard-error-of-beta-estimates" title="Permalink to this headline">¶</a></h3>
<p>We can also estimate the uncertainty of regression coefficients. The uncertainty of the beta parameters is quantified as a standard error around each specific estimate.</p>
<p>$$\sigma = \sqrt{diag((X^TX)^{-1})} \cdot \hat \sigma$$</p>
<p>This is essentially a confidence interval around the $\beta_j$ estimate. One standard error, $1*\hat \sigma$ is approximately equivalent to a 68% confidence interval, while $2*\hat\sigma$ is approximately a 95% confidence interval.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">std_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)))))</span> <span class="o">*</span> <span class="n">standard_error_of_estimate</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span><span class="s1">&#39;Faces&#39;</span><span class="p">,</span> <span class="s1">&#39;Objects&#39;</span><span class="p">],</span> <span class="n">beta</span><span class="p">,</span> <span class="n">yerr</span> <span class="o">=</span> <span class="n">standard_error_of_estimate</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Regressor&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Beta Value&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Beta Value&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_35_1.png" src="../_images/GLM_35_1.png" />
</div>
</div>
</div>
<div class="section" id="statistical-significance">
<h3>Statistical Significance<a class="headerlink" href="#statistical-significance" title="Permalink to this headline">¶</a></h3>
<p>We could also perform a hypothesis test to evaluate if any of the regressors are statistically different from zero.</p>
<p>This exercise is simply meant to provide parallels to common statistical jargon. In practice, this is actually rarely done in neuroimaging analysis as we are typically more interested in making statistical inferences across the population rather than within a single participant.</p>
<p>The formula for calculating a t-statistic is very simple:</p>
<p>$$t = \frac{\hat \beta_j}{\hat \sigma_j}$$</p>
<p>where $\beta_j$ refers to the estimated parameter for a regressor $j$, and $\sigma_j$ refers to the standard error of regressor $j$.</p>
<p>$t$ values that are more than 2 standard errors away from zero are called <em>statistically significant</em>, which basically just means we are more confident that the estimate is stable and not just an artifact of small sample size. In general, we don’t recommend reading too much into significance for individual $\beta$ estimates in single subject fMRI analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">beta</span><span class="o">/</span><span class="n">std_error</span>
<span class="n">t</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.65716867, 15.83929013,  8.23580115])
</pre></div>
</div>
</div>
</div>
<p>Just like in intro statistics, we could find the p-value that corresponds to a particular t-statistic using the t-distribution. We will load the t distribution from <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> and calculate the corresponding p-values using the survival function or  $1- cdf$, which requires specifying the degrees of freedom (df), which is $n-1$. We multiply these values by 2 to calculated a two-tailed test.</p>
<p>You can see that the intercept $\beta$ is not significant, but the face and object regressors are well below <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;</span> <span class="pre">0.05</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">n_tr</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span> <span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">],</span> <span class="n">p</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;p-values&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Regressor&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[5.11831798e-01 4.26134329e-37 2.33906074e-14]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.LineCollection at 0x7fe020f135d0&gt;
</pre></div>
</div>
<img alt="../_images/GLM_39_2.png" src="../_images/GLM_39_2.png" />
</div>
</div>
</div>
<div class="section" id="contrasts">
<h3>Contrasts<a class="headerlink" href="#contrasts" title="Permalink to this headline">¶</a></h3>
<p>Contrasts are a very important concept in fMRI data analysis as they provide the statistical inference underlying the subtraction method of making inferences.</p>
<p>Let’s watch a short video by Tor Wager on contrasts. We will also spend much more time on contrasts in the group analysis tutorial. We also recommend watching Jeannette Mumford’s <a class="reference external" href="https://www.youtube.com/watch?v=yLgPpmXVVbs">overview</a> of contrasts for a more statistical perspective.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;7MibM1ATai4&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/7MibM1ATai4"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>Contrasts describe a linear combination of variables in a regression model whose coefficients add up to zero. This allows us to flexibly compare different experimental conditions.</p>
<p>For example, suppose we just wanted to know the magnitude of an effect for a single condition, such as the brain response to faces. We would create a contrast code that isolates the effect size (i.e., $\beta$ estimate for the face regressor)</p>
<p>If our GLM, was:</p>
<p>$$Y = \beta_0 \cdot Intercept + \beta_1 \cdot Faces + \beta_2 \cdot Objects$$</p>
<p>then, the corresponding contrast code or vector for faces would be:</p>
<p>[0, 1, 0]</p>
<p>The contrast code for the object condition would be:</p>
<p>[0, 0, 1]</p>
<p>and importantly the contrast <em>between</em> the face and object condition would be:</p>
<p>[0, 1, -1]</p>
<p>More simply, we are calculating the magnitude of the effect of the difference between viewing faces and objects in a single voxel.</p>
<p>To make this a little bit more clear, we will show a graphical representation of the design matrix to make it obvious what we are contrasting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">c1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">c3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="p">{(</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">]}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{(&#39;[0, 0, 1]&#39;, 1.0721521304389894),
 (&#39;[0, 1, -1]&#39;, 0.8735019759362619),
 (&#39;[0, 1, 0]&#39;, 1.9456541063752513)}
</pre></div>
</div>
<img alt="../_images/GLM_43_1.png" src="../_images/GLM_43_1.png" />
</div>
</div>
</div>
<div class="section" id="efficiency">
<h3>Efficiency<a class="headerlink" href="#efficiency" title="Permalink to this headline">¶</a></h3>
<p>We can estimate the efficiency, or the quality of an estimator for a specific experimental design or a hypothesis testing procedure. Efficiency is related to power, or the ability to detect an effect should one exist. However, unlike power, we can estimate efficiency from our design matrix and do not actually need to know the standard error for the model (unlike with power calculations). Specifically, efficiency is defined as the inverse of the sum of the estimator variances. For a more detailed explanation and general experimental design recommendations see this <a class="reference external" href="http://imaging.mrc-cbu.cam.ac.uk/imaging/DesignEfficiency">overview</a> by Rik Henson, or this <a class="reference external" href="https://theclevermachine.wordpress.com/tag/fmri-design-efficiency/">blog post</a> on efficiency in experimental designs.</p>
<p>$$e(c\hat\beta) = \frac{1}{c(X^TX)^{-1}c^T}$$</p>
<p>Reducing collinearity or covariance between regressors can increase design efficiency</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">contrast_efficiency</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">contrast</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">contrast</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">))),</span> <span class="n">c</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

<span class="n">c1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">c3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="p">[</span><span class="n">contrast_efficiency</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.44032677542221, 2.5429401030547045, 1.3578767952519295]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="varying-the-inter-trial-interval-with-jittering">
<h3>Varying the Inter-Trial Interval with Jittering<a class="headerlink" href="#varying-the-inter-trial-interval-with-jittering" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set Simulation Parameters</span>
<span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face_intensity</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">object_intensity</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.15</span>

<span class="c1"># Build Simulation</span>
<span class="n">face_trials</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="n">n_trial</span><span class="p">)</span>
<span class="n">obj_trials</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="n">n_trial</span><span class="p">)</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">face_trials</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">obj_trials</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">voxel_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="o">*</span><span class="n">face_intensity</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="o">*</span><span class="n">object_intensity</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_tr</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">voxel_conv_noise</span> <span class="o">=</span> <span class="n">voxel_conv</span> <span class="o">+</span> <span class="n">epsilon</span>

<span class="c1"># Build Model</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">voxel_conv_noise</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">face</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Estimate Model</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">ols_estimator</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">predicted_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">predicted_sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
<span class="n">predicted_ts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">predicted_ts</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Simulated Voxel&#39;</span><span class="p">,</span> <span class="s1">&#39;Predicted Voxel&#39;</span><span class="p">])</span>

<span class="c1"># Estimate Contrast Efficiency</span>
<span class="p">[</span><span class="n">contrast_efficiency</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.5597167760964403, 2.066820546582558, 1.1233445684652128]
</pre></div>
</div>
<img alt="../_images/GLM_47_1.png" src="../_images/GLM_47_1.png" />
</div>
</div>
</div>
<div class="section" id="autocorrelation">
<h3>Autocorrelation<a class="headerlink" href="#autocorrelation" title="Permalink to this headline">¶</a></h3>
<p>The BOLD signal has some intrinsic autocorrelation that varies with the length of the TR. Different software packages have provided varying solutions to this problem. For example, SPM implements an AR(1) model, which means that it trys to account for the fact that the signal is consistently correlated (i.e., autoregressive) with one lag. In practice, these will rarely change the beta estimates, but rather will adjust our standard errors around the estimates. As we will discuss soon, most group level analyses ignore these subject level, or first-level errors anyway. It is debatable if this is actually a good practice, but it reduces the importance of accounting for autocorrelation when looking at group level statistics in standard experimental design.</p>
<p>Another important thing to note is that there is some evidence that the AR(1) model can actually increase false positives, especiall in shorter TRs.  See this <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811912003825">paper</a> by Anders Ekland and colleagues for more details. Also, this is a helpful <a class="reference external" href="https://mandymejia.com/2016/11/06/how-to-efficiently-prewhiten-fmri-timeseries-the-right-way/">blog post</a> discussing prewhitening.</p>
<p>For the scope of this course we will largely be ignoring this issue, but I will plan to add some examples and simulations in the future.  For now, I encourage you to watch this video on <a class="reference external" href="https://www.youtube.com/watch?v=Mb9LDzvhecY&amp;list=PLfXA4opIOVrGHncHRxI3Qa5GeCSudwmxM&amp;index=24">AR models</a> if you are interested in learning more about this topic.</p>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p>For our homework exercises, let’s use the simulation to answer questions we might have about experimental design.</p>
<div class="section" id="exercise-1-what-happens-when-we-vary-the-signal-amplitude">
<h3>Exercise 1. What happens when we vary the signal amplitude?<a class="headerlink" href="#exercise-1-what-happens-when-we-vary-the-signal-amplitude" title="Permalink to this headline">¶</a></h3>
<p>Some signals will be very strong and others weaker. How does the model fit change when the signal amplitudes are stronger and weaker?</p>
<p>In this exercise, make a plot showing how the $r^2$ changes over 3 different levels of signal intensity.</p>
</div>
<div class="section" id="exercise-2-what-happens-when-we-vary-the-noise">
<h3>Exercise 2. What happens when we vary the noise?<a class="headerlink" href="#exercise-2-what-happens-when-we-vary-the-noise" title="Permalink to this headline">¶</a></h3>
<p>How does the amount of noise in the data impact our model fits?</p>
<p>In this exercise, make a plot showing the $r^2$ for 3 different levels of simulated noise.</p>
</div>
<div class="section" id="exercise-3-how-many-trials-do-we-need">
<h3>Exercise 3. How many trials do we need?<a class="headerlink" href="#exercise-3-how-many-trials-do-we-need" title="Permalink to this headline">¶</a></h3>
<p>A common question in experimental design is determining the optimal number of trials.</p>
<p>In this exercise, try evaluating how 3 different numbers of trials might impact the contrast efficiency.</p>
</div>
<div class="section" id="exercise-4-what-is-the-impact-of-the-stimulus-duration">
<h3>Exercise 4. What is the impact of the stimulus duration?<a class="headerlink" href="#exercise-4-what-is-the-impact-of-the-stimulus-duration" title="Permalink to this headline">¶</a></h3>
<p>What if one condition simply results in processes that systematically take longer than the other condition?</p>
<p>In this exercise, let’s try to answer this question by creating a simulation where the signal intensity between the two condition is identical, but one simply has a longer duration (i.e., the duration has more TRs than the other condition).</p>
<p>Make a plot showing what happens to the $\beta$ estimates.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="Preprocessing.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Preprocessing</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="GLM_Single_Subject_Model.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Modeling Single Subject Data</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Luke Chang<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            Supported by an NSF CAREER Award 1848370, <a href='https://rc.dartmouth.edu/'>Dartmouth Research Computing</a>, and the <a href='https://dcal.dartmouth.edu/about/impact/experiential-learning'>Dartmouth Center for the Advancement of Learning</a>.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-138270939-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>