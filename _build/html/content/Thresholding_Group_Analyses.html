
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Thresholding Group Analyses &#8212; DartBrains</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet" />
  <link href="../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.e2363ea40746bee74734a24ffefccd78.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="http://dartbrains.org/content/Thresholding_Group_Analyses.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Connectivity" href="Connectivity.html" />
    <link rel="prev" title="Group Analysis" href="Group_Analysis.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/dartbrains_logo_square_transparent.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DartBrains</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p class="caption">
 <span class="caption-text">
  Course Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Instructors.html">
   Instructors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Schedule.html">
   Schedule
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Computing Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_JupyterHub.html">
   Introduction to JupyterHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Download_Data.html">
   Download Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Programming.html">
   Introduction to programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Pandas.html">
   Introduction to Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Plotting.html">
   Introduction to Plotting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Glossary.html">
   Glossary
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Course Topics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_to_Neuroimaging.html">
   Introduction to Neuroimaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Measurement.html">
   Signal Generation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ICA.html">
   Separating Signal From Noise With ICA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Neuroimaging_Data.html">
   Introduction to Neuroimaging Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Processing.html">
   Signal Processing Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Preprocessing.html">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="GLM.html">
   Introduction to the General Linear Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="GLM_Single_Subject_Model.html">
   Modeling Single Subject Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Group_Analysis.html">
   Group Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Thresholding Group Analyses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Connectivity.html">
   Connectivity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multivariate_Prediction.html">
   Multivariate Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="RSA.html">
   Representational Similarity Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Resampling_Statistics.html">
   Resampling Statistics
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Additional Courses
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="http://naturalistic-data.org/">
   Naturalistic Data Analysis
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Project Gallery
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2019_Spring.html">
   Spring 2019
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Spring.html">
   Spring 2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Fall.html">
   Fall 2020
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ljchang/dartbrains">
   GitHub Repository
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Post questions to <a href='https://www.askpbs.org/c/dartbrains'>DartBrains Discourse</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/content/Thresholding_Group_Analyses.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/ljchang/dartbrains"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/ljchang/dartbrains/issues/new?title=Issue%20on%20page%20%2Fcontent/Thresholding_Group_Analyses.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/ljchang/dartbrains/edit/master/content/Thresholding_Group_Analyses.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/ljchang/dartbrains/master?urlpath=tree/content/Thresholding_Group_Analyses.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://jhub.dartmouth.edu//hub/user-redirect/git-pull?repo=https://github.com/ljchang/dartbrains&urlpath=tree/dartbrains/content/Thresholding_Group_Analyses.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/ljchang/dartbrains/blob/master/content/Thresholding_Group_Analyses.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulations">
   Simulations
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#family-wise-error-rate">
   Family Wise Error Rate
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cluster-extent">
     Cluster Extent
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#threshold-free-cluster-extent">
     Threshold Free Cluster Extent
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-simulations">
     Parametric simulations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nonparametric-approaches">
     Nonparametric approaches
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#false-discovery-rate-fdr">
   False Discovery Rate (FDR)
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thresholding-brain-maps">
     Thresholding Brain Maps
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1-bonferroni-correction-simulation">
     Exercise 1. Bonferroni Correction Simulation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-2-which-regions-are-more-involved-with-visual-compared-to-auditory-sensory-processing">
     Exercise 2. Which regions are more involved with visual compared to auditory sensory processing?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-3-which-regions-are-more-involved-in-processing-numbers-compared-to-words">
     Exercise 3. Which regions are more involved in processing numbers compared to words?
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="thresholding-group-analyses">
<h1>Thresholding Group Analyses<a class="headerlink" href="#thresholding-group-analyses" title="Permalink to this headline">¶</a></h1>
<p><em>Written by Luke Chang</em></p>
<p>Now that we have learned how to estimate a single-subject model, create contrasts, and run a group-level analysis, the next important topic to cover is how we can threshold these group maps. This is not as straightforward as it might seem as we need to be able to correct for multiple comparisons.</p>
<p>In this tutorial, we will cover how we go from modeling brain responses in each voxel for a single participant to making inferences about the group. We will cover the following topics:</p>
<ul class="simple">
<li><p>Issues with correcting for multiple comparisons</p></li>
<li><p>Family Wise Error Rate</p></li>
<li><p>Bonferroni Correction</p></li>
<li><p>False Discovery Rate</p></li>
</ul>
<p>Let’s get started by watching an overview of multiple comparisons by Martin Lindquist.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>

<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;AalIM9-5-Pk&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/AalIM9-5-Pk"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>The primary goal in fMRI data analysis is to make inferences about how the brain processes information. These inferences can be in the form of predictions, but most often we are testing hypotheses about whether a particular region of the brain is involved in a specific type of process. This requires rejecting a $H_0$ hypothesis (i.e., that there is no effect). Null hypothesis testing is traditionally performed by specifying contrasts between different conditions of an experimental design and assessing if these differences between conditions are reliably present across many participants. There are two main types of errors in null-hypothesis testing.</p>
<p><em>Type I error</em></p>
<ul class="simple">
<li><p>$H_0$ is true, but we mistakenly reject it (i.e., False Positive)</p></li>
<li><p>This is controlled by significance level $\alpha$.</p></li>
</ul>
<p><em>Type II error</em></p>
<ul class="simple">
<li><p>$H_0$ is false, but we fail to reject it (False Negative)</p></li>
</ul>
<p>The probability that a hypothesis test will correctly reject a false null hypothesis is described as the <em>power</em> of the test.</p>
<p>Hypothesis testing in fMRI is complicated by the fact that we are running many tests across each voxel in the brain (hundreds of thousands of tests). Selecting an appropriate threshold requires finding a balance between sensitivity (i.e., true positive rate) and specificity (i.e., false negative rate). There are two main approaches to correcting for multiple tests in fMRI data analysis.</p>
<p><strong>Familywise Error Rate</strong> (FWER) attempts to control the probability of finding <em>any</em> false positives. Mathematically, FWER can be defined as the probability $P$ of observing any false positive ${FWER} = P({False Positives}\geq 1)$.</p>
<p>While, <strong>False Discovery Rate</strong> (FDR) attempts to control the proportion of false positives among rejected tests. Formally, this is the expected proportion of false positive to the observed number of significant tests ${FDR} = E(\frac{False Positives}{Significant Tests})$.</p>
<p>This should probably be no surprise to anyone, but fMRI studies are expensive and inherently underpowered. Here is a simulation by Jeannette Mumford to show approximately how many participants you would need to achieve 80% power assuming a specific effect size in your contrast.</p>
<p><img alt="fmri_power.png" src="../_images/fmri_power.png" /></p>
<div class="section" id="simulations">
<h2>Simulations<a class="headerlink" href="#simulations" title="Permalink to this headline">¶</a></h2>
<p>Let’s explore the concept of false positives to get an intuition about what the overall goals and issues are in controlling for multiple tests.</p>
<p>Let’s load the modules we need for this tutorial. We will be using the SimulateGrid class which contains everything we need to run all of the simulations.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">nltools.data</span> <span class="kn">import</span> <span class="n">Brain_Data</span>
<span class="kn">from</span> <span class="nn">nltools.simulator</span> <span class="kn">import</span> <span class="n">SimulateGrid</span>
</pre></div>
</div>
</div>
</div>
<p>Okay, let’s get started and generate 100 x 100 voxels from $\mathcal{N}(0,1)$ distribution for 20 independent participants.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="n">f</span><span class="p">,</span><span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span><span class="mi">15</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">simulation</span><span class="o">.</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">counter</span><span class="p">],</span> <span class="n">ax</span><span class="o">=</span><span class="n">a</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">4</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">a</span><span class="p">[</span><span class="n">row</span><span class="p">,</span><span class="n">col</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Subject </span><span class="si">{</span><span class="n">counter</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
        <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Thresholding_Group_Analyses_6_0.png" src="../_images/Thresholding_Group_Analyses_6_0.png" />
</div>
</div>
<p>Each subject’s simulated data is on a 100 x 100 grid. Think of this as a slice from their brain, where each pixel corresponds to the same spatial location across all participants. We have generated random noise separately for each subject. We have not added any true signal in this simulation yet.</p>
<p>This figure is simply to highlight that we are working with 20 independent subjects. In the rest of the plots, we will be working with a single grid that aggregates the results across participants.</p>
<p>Now we are going to start running some simulations to get a sense of the number of false positives we might expect to observe with this data. We will now run an independent one-sample t-test on every pixel in the grid across all 20 participants.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulation</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">simulation</span><span class="o">.</span><span class="n">t_values</span><span class="p">,</span> <span class="n">square</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;RdBu_r&#39;</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=-</span><span class="mi">4</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;T Values&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;T Values&#39;)
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_8_1.png" src="../_images/Thresholding_Group_Analyses_8_1.png" />
</div>
</div>
<p>Even though there was no signal in this simulation, you can see that there are a number of pixels in the grid that exceed a t-value above 2 and below -2, which is the approximate cutoff for p &lt; 0.05. These are all false positives.</p>
<p>Now let’s apply a threshold. We can specify thresholds at a specific t-value using the <code class="docutils literal notranslate"><span class="pre">threshold_type='t'</span></code>. Alternatively, we can specify a specific p-value using the <code class="docutils literal notranslate"><span class="pre">threshold_type='p'</span></code>. To calculate the number of false positives, we can simply count the number of tests that exceed this threshold.</p>
<p>If we run this simulation again 100 times, we can estimate the false positive rate, which is the average number of false positives over all 100 simulations.</p>
<p>Let’s see what this looks like for a threshold of p &lt; 0.05.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Thresholding_Group_Analyses_10_0.png" src="../_images/Thresholding_Group_Analyses_10_0.png" />
</div>
</div>
<p>The left panel is the average over all of the participants. The middle panel show voxels that exceed the statistical threshold. The right panel is the overall false-positive rate across the 100 simulations.</p>
<p>In this simulation, a threshold of p &lt; 0.05 results in observing at least one voxels that is a false positive across every one of our 100 simulations.</p>
<p>What if we looked at a fewer number of voxels? How would this change our false positive rate?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Thresholding_Group_Analyses_12_0.png" src="../_images/Thresholding_Group_Analyses_12_0.png" />
</div>
</div>
<p>This simulation shows that examining fewer numbers of voxels will yield considerably less false positives. One common approach to controlling for multiple tests involves only looking for voxels within a specific region of interest (e.g., small volume correction), or looking at average activation within a larger region (e.g., ROI based analyses).</p>
<p>What about if we increase the threshold on our original 100 x 100 grid?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">0001</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Thresholding_Group_Analyses_14_0.png" src="../_images/Thresholding_Group_Analyses_14_0.png" />
</div>
</div>
<p>You can see that this dramatically decreases the number of false positives to the point that some of the simulations no longer contain any false positives.</p>
<p>What is the optimal threshold that will give us an $\alpha=0.05$?</p>
<p>To calculate this, we will run 100 simulations at different threshold levels to find the threshold that leads to a false positive rate that is lower than our alpha value.</p>
<p>We could search over t-values, or p-values. Let’s explore t-values first.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">n_simulations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="o">.</span><span class="mi">2</span><span class="p">)</span>

<span class="n">sim_all</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
    <span class="n">sim</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">sim</span><span class="o">.</span><span class="n">run_multiple_simulations</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="n">n_simulations</span><span class="p">)</span>
    <span class="n">sim_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sim</span><span class="o">.</span><span class="n">fpr</span><span class="p">)</span>

<span class="n">f</span><span class="p">,</span><span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">a</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sim_all</span><span class="p">))</span>
<span class="n">a</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;False Positive Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Threshold (t)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Simulations = </span><span class="si">{</span><span class="n">n_simulations</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.lines.Line2D at 0x7feb9fc76290&gt;
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_16_1.png" src="../_images/Thresholding_Group_Analyses_16_1.png" />
</div>
</div>
<p>As you can see, the false positive rate is close to our alpha starting at a threshold of about 6.2. This means that when we test a hypothesis over 10,000 independent voxels, we can be confident that we will only observe false positives in approximately 5 out of 100 experiments. This means that we are effectively controlling the family wise error rate (FWER).</p>
<p>Let’s use that threshold for our simulation again.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">6.2</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;t&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Thresholding_Group_Analyses_18_0.png" src="../_images/Thresholding_Group_Analyses_18_0.png" />
</div>
</div>
<p>Notice, that we are now observing a false positive rate of approximately .05, though this number will slightly change each time you run the simulation.</p>
<p>Another way to find the threshold that controls FWER is to divide the alpha by the number of independent tests across voxels. This is called the <strong>bonferroni correction</strong>.</p>
<p>${bonferroni} = \frac{\alpha}{M}$, where $M$ is the number of voxels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.05</span><span class="o">/</span><span class="p">(</span><span class="n">grid_width</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Thresholding_Group_Analyses_20_0.png" src="../_images/Thresholding_Group_Analyses_20_0.png" />
</div>
</div>
<p>This seems like a great way to ensure that we minimize our false positives.</p>
<p>Now what happens when start adding signal to our simulation?</p>
<p>We will represent signal in a smaller square in the middle of the simulation. The width of the square can be changed using the <code class="docutils literal notranslate"><span class="pre">signal_width</span></code> parameter. The amplitude of this signal is controlled by the <code class="docutils literal notranslate"><span class="pre">signal_amplitude</span></code> parameter.</p>
<p>Let’s see how well the bonferroni threshold performs when we add 100 voxels of signal.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span><span class="o">/</span><span class="p">(</span><span class="n">grid_width</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">signal_width</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">signal_amplitude</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">signal_amplitude</span><span class="o">=</span><span class="n">signal_amplitude</span><span class="p">,</span> <span class="n">signal_width</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Thresholding_Group_Analyses_22_0.png" src="../_images/Thresholding_Group_Analyses_22_0.png" />
</div>
</div>
<p>Here we show how many voxels were identified using the bonferroni correction.</p>
<p>In the left panel is the average data across all 20 participants. The second panel, shows the voxels that exceed the statistical threshold. The third panel shows the false positive rate, and the 4th panel furthest on the right shows the average signal recovery (how many voxels survived within the true signal square across all 100 simulations.</p>
<p>We can see that we have an effective false positive rate approximately equal to our alpha threshold. However, our threshold is so high, that we can barely detect any true signal with this amplitude. In fact, we are only recovering about 12% of the voxels that should have signal.</p>
<p>This simulation highlights the main issue with using bonferroni correction in practice. The threshold is so conservative that the magnitude of an effect needs to be unreasonably large to survive correction over hundreds of thousands of voxels.</p>
</div>
<div class="section" id="family-wise-error-rate">
<h2>Family Wise Error Rate<a class="headerlink" href="#family-wise-error-rate" title="Permalink to this headline">¶</a></h2>
<p>At this point you may be wondering if it even makes sense to assume that each test is independent. It seems reasonable to expect some degree of spatial correlation in our data. Our simulation is a good example of this as we have a square that contains signal across contiguous voxels. In practice, most of our functional neuroanatomy that we are investigating is larger than a single voxel and our spatial smoothing preprocessing step increase the spatial correlation.</p>
<p>It can be shown that the Bonferroni correction is overally conservative in the presence of spatial dependence and results in a decreased power to detect voxels that are truly active.</p>
<p>Let’s watch a video by Martin Lindquist to learn more about different ways to control for the Family Wise Error Rate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;MxQeEdVNihg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/MxQeEdVNihg"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<div class="section" id="cluster-extent">
<h3>Cluster Extent<a class="headerlink" href="#cluster-extent" title="Permalink to this headline">¶</a></h3>
<p>Another approach to controlling the FWER is called cluster correction, or cluster extent. In this approach, the goal is to identify a threshold such that the maximum statistic exceeds it at a specified alpha. The distribution of the maximum statistic can be approximated using Gaussian Random Field Theory (RFT), which attempts to account for the spatial dependence of the data.</p>
<p><img alt="fwer.png" src="../_images/fwer.png" /></p>
<p>This requires specifying an initial threshold to determine the <em>Euler Characteristic</em> or the number of blobs minus the number of holes in the thresholded image. The number of voxels in the blob and the overall smoothness can be used to calculate something called <em>resels</em> or resolution elements and can be effectively thought of as the spatial units that need to be controlled for using FWER. We won’t be going into too much detail with this approach as the mathematical details are somewhat complicated. In practice, if the image is smooth and the number of subjects is high enough (around 20), cluster correction seems to provide control closer to the true false positive rate than Bonferroni correction. Though we won’t be spending time simulating this today, I encourage you to check out this Python <a class="reference external" href="https://matthew-brett.github.io/teaching/random_fields.html">simulation</a> by Matthew Brett and this <a class="reference external" href="https://www.fil.ion.ucl.ac.uk/spm/doc/books/hbf2/pdfs/Ch14.pdf">chapter</a> for an introduction to random field theory.</p>
<p><img alt="grf.png" src="../_images/grf.png" /></p>
<p>Cluster extent thresholding has recently become somewhat controversial due to several high profile papers that have found that it appears to lead to an inflated false positive rate in practice (see <a class="reference external" href="https://www.pnas.org/content/113/28/7900">Ekland et al., 2017</a>). A recent paper by <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4214144/">Woo et al. 2014</a> has shown that a liberal initial threshold (i.e. higher than p &lt; 0.001) will inflate the number of false positives above the nominal level of 5%. There is no optimal way to select the initial threshold and often slight changes will give very different results. Furthermore, this approach does not appear to work equally well across all types of findings. For example, this approach can work well with some amounts of smoothing results that have a particular spatial extent, but not equally well for all types of signals. In other words, it seems potentially problematic to assume that spatial smoothness is constant over the brain and also that it is adequately represented using a Gaussian distribution. Finally, it is important to note that this approach only allows us to make inferences for the entire cluster. We can say that there is some voxel in the cluster that is significant, but we can’t really pinpoint which voxels within the cluster may be driving the effect.</p>
<p>This is one of the more popular ways to control for multiple comparisons as it is particularly sensitive when there is a weak, but spatially contiguous signal. However, in practice, we don’t recommend using this approach as it has a lot of assumptions that are rarely met and the spatial inference is fairly weak.</p>
<p>There are several other popular FWER approaches to correcting for multiple tests that try to address these issues.</p>
</div>
<div class="section" id="threshold-free-cluster-extent">
<h3>Threshold Free Cluster Extent<a class="headerlink" href="#threshold-free-cluster-extent" title="Permalink to this headline">¶</a></h3>
<p>One interesting solution to the issue of finding an initial threshold seems to be addressed by the threshold free cluster enhancement method presented in <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811908002978?via%3Dihub">Smith &amp; Nichols, 2009</a>. In this approach, the authors propose a way to combine cluster extent and voxel height into a single metric that does not require specifying a specific initial threshold. It essentially involves calculating the integral of the overall product of a signal intensity and spatial extent over multiple thresholds. It has been shown to perform particularly well when combined with non-parameteric resampling approaches such as <a class="reference external" href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide">randomise</a> in FSL. This method is implemented in FSL and also in <a class="reference external" href="https://github.com/markallenthornton/MatlabTFCE">Matlab</a> by Mark Thornton. For more details about this approach check out this <a class="reference external" href="http://markallenthornton.com/blog/matlab-tfce/">blog post</a> by Mark Thornton, this <a class="reference external" href="https://mumfordbrainstats.tumblr.com/post/130127249926/paper-overview-threshold-free-cluster-enhancement">video</a> by Jeanette Mumford, and the original <a class="reference external" href="https://www.fmrib.ox.ac.uk/datasets/techrep/tr08ss1/tr08ss1.pdf">technical report</a>.</p>
</div>
<div class="section" id="parametric-simulations">
<h3>Parametric simulations<a class="headerlink" href="#parametric-simulations" title="Permalink to this headline">¶</a></h3>
<p>One approach to estimating the inherent smoothness in the data, or it’s spatial autocorrelation, is using parametric simulations. This was the approach originally adopted in AFNI’s AlphaSim/3DClustSim. After it was <a class="reference external" href="https://www.pnas.org/content/113/28/7900">demonstrated</a> that real fMRI data was not adequately modeled by a standard Gaussian distribution, the AFNI group quickly updated their software and implemented a range of different algorithms in their <a class="reference external" href="https://afni.nimh.nih.gov/pub/dist/doc/program_help/3dClustSim.html">3DClustSim</a> tool. See this <a class="reference external" href="https://www.biorxiv.org/content/10.1101/065862v1">paper</a> for an overview of these changes.</p>
</div>
<div class="section" id="nonparametric-approaches">
<h3>Nonparametric approaches<a class="headerlink" href="#nonparametric-approaches" title="Permalink to this headline">¶</a></h3>
<p>As an alternative to RFT, nonparametric methods use the data themselves to find the appropriate distribution. These methods can provide substantial improvements in power and validity, particularly with small sample sizes, so we recommend these in general over cluster extent. These tests can verify the validity of the less computationally expensive parametric approaches. However, it is important to note that this is much more computationally expensive as 5-10k permutations need to be run at every voxel. The FSL tool <a class="reference external" href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Randomise/UserGuide">randomise</a> is probably the current gold standard and there are versions that run on GPUs, such as <a class="reference external" href="https://github.com/wanderine/BROCCOLI">BROCCOLI</a> to speed up the computation time.</p>
<p>Here we will run a simulation using a one-sample permutation test (i.e., sign test) on our data. We will make the grid much smaller to speed up the simulation and will decrease the number of simulations by an order of magnitude, but you will see that it is still very slow (5,000 permutations times 9 voxels times 10 simulations). This approach makes no distributional assumptions, but still requires correcting for multiple tests using either FWER or FDR approaches. Don’t worry about running this cell if it is taking too long.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">signal_amplitude</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">signal_amplitude</span><span class="o">=</span><span class="n">signal_amplitude</span><span class="p">,</span> <span class="n">signal_width</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">t_values</span><span class="p">,</span> <span class="n">simulation</span><span class="o">.</span><span class="n">p_values</span> <span class="o">=</span> <span class="n">simulation</span><span class="o">.</span><span class="n">_run_permutation</span><span class="p">(</span><span class="n">simulation</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">isfit</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">threshold_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="p">,</span> <span class="s1">&#39;p&#39;</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="false-discovery-rate-fdr">
<h2>False Discovery Rate (FDR)<a class="headerlink" href="#false-discovery-rate-fdr" title="Permalink to this headline">¶</a></h2>
<p>You may be wondering why we need to control for <em>any</em> false positive when testing across hundreds of thousands of voxels. Surely a few are okay as long as they don’t overwhelm the true signal.</p>
<p>Let’s learn about the False Discovery Rate (FDR) from another video by Martin Lindquist.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;W9ogBO4GEzA&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/W9ogBO4GEzA"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>The <em>false discovery rate</em> (FDR) is a more recent development in multiple testing correction originally described by <a class="reference external" href="https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1995.tb02031.x">Benjamini &amp; Hochberg, 1995</a>. While FWER is the probability of any false positives occurring in a family of tests, the FDR is the expected proportion of false positives among significant tests.</p>
<p>The FDR is fairly straightforward to calculate.</p>
<ol class="simple">
<li><p>We select a desired limit $q$ on FDR, which is the proportion of false positives we are okay with observing (e.g., 5/100 tests or 0.05).</p></li>
<li><p>We rank all of the p-values over all the voxels from the smallest to largest.</p></li>
<li><p>We find the threshold $r$ such that $p \leq i/m * q$</p></li>
<li><p>We reject any $H_0$ that is lower than $r$.</p></li>
</ol>
<p><img alt="image.png" src="../_images/fdr_calc.png" /></p>
<p>In a brain map, this means that we expect approximately 95% of the voxels reported at q &lt; .05 FDR-corrected to be true activations (note we use q instead of p). The FDR procedure adaptively identifies a threshold based on the overall signal across all voxels. Larger signals results in lower thresholds. Importantly, if all of the null hypotheses are true, then the FDR will be equivalent to the FWER. This means that any FWER procedure will <em>also</em> control the FDR. For these reasons, any procedure which controls the FDR is necessarily less stringent than a FWER controlling procedure, which leads to an overall increased power. Another nice feature of FDR, is that it operates on p-values instead of test statistics, which means it can be applied to most statistical tests.</p>
<p>This figure is taken from Poldrack, Mumford, &amp; Nichols (2011) and compares different procedures to control for multiple tests.
<img alt="image.png" src="../_images/fdr.png" /></p>
<p>For a more indepth overview of FDR, see this <a class="reference external" href="https://matthew-brett.github.io/teaching/fdr.html">tutorial</a> by Matthew Brett.</p>
<p>Let’s now try to apply FDR to our own simulations. All we need to do is add a <code class="docutils literal notranslate"><span class="pre">correction='fdr'</span></code> flag to our simulation plot. We need to make sure that the <code class="docutils literal notranslate"><span class="pre">threshold=0.05</span></code> to use the correct $q$.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_width</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="o">.</span><span class="mi">05</span>
<span class="n">signal_amplitude</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">simulation</span> <span class="o">=</span> <span class="n">SimulateGrid</span><span class="p">(</span><span class="n">signal_amplitude</span><span class="o">=</span><span class="n">signal_amplitude</span><span class="p">,</span> <span class="n">signal_width</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">grid_width</span><span class="o">=</span><span class="n">grid_width</span><span class="p">,</span> <span class="n">n_subjects</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">simulation</span><span class="o">.</span><span class="n">plot_grid_simulation</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold_type</span><span class="o">=</span><span class="s1">&#39;q&#39;</span><span class="p">,</span> <span class="n">n_simulations</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">correction</span><span class="o">=</span><span class="s1">&#39;fdr&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;FDR q &lt; 0.05 corresponds to p-value of </span><span class="si">{</span><span class="n">simulation</span><span class="o">.</span><span class="n">corrected_threshold</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>FDR q &lt; 0.05 corresponds to p-value of 0.00030256885357668906
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_31_1.png" src="../_images/Thresholding_Group_Analyses_31_1.png" />
</div>
</div>
<p>Okay, using FDR of q &lt; 0.05 for our simulation identifies a p-value threshold of p &lt; 0.00034. This is more liberal than the bonferroni threshold of p &lt; 0.000005 and allows us to recover much more signal as a consequence. You can see that at this threshold there are more false positives, which leads to a much higher overall false positive rate. Remember, this metric is only used for calculating the family wise error rate and indicates the presence of <em>any</em> false positive across each of our 100 simulations.</p>
<p>To calculate the empirical false discovery rate, we need to calculate the percent of any activated voxels that were false positives.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">simulation</span><span class="o">.</span><span class="n">multiple_fdr</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Discovery Rate&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;False Discovery Rate of Simulations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;False Discovery Rate of Simulations&#39;)
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_33_1.png" src="../_images/Thresholding_Group_Analyses_33_1.png" />
</div>
</div>
<p>In our 100 simulations, the majority had a false discovery rate below our q &lt; 0.05.</p>
<div class="section" id="thresholding-brain-maps">
<h3>Thresholding Brain Maps<a class="headerlink" href="#thresholding-brain-maps" title="Permalink to this headline">¶</a></h3>
<p>In the remainder of the tutorial, we will move from simulation to playing with real data.</p>
<p>Let’s watch another video by Tor Wager on how multiple comparison approaches are used in practice, highlighting some of the pitfalls with some of the different approaches.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;N7Iittt8HrU&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/N7Iittt8HrU"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>We will be exploring two simple and fast ways to threshold your group analyses.</p>
<p>First, we will simply threshold based on selecting an arbitrary statistical threshold. The values are completely arbitrary, but it is common to start with something like p &lt; .001. We call this <em>uncorrected</em> because this is simply the threshold for any voxel as we are not controlling for multiple tests.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">con1_name</span> <span class="o">=</span> <span class="s1">&#39;horizontal_checkerboard&#39;</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;../data/localizer&#39;</span>
<span class="n">con1_file_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;derivatives&#39;</span><span class="p">,</span><span class="s1">&#39;fmriprep&#39;</span><span class="p">,</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;sub*_</span><span class="si">{</span><span class="n">con1_name</span><span class="si">}</span><span class="s1">*nii.gz&#39;</span><span class="p">))</span>
<span class="n">con1_file_list</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">con1_dat</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">con1_file_list</span><span class="p">)</span>
<span class="n">con1_stats</span> <span class="o">=</span> <span class="n">con1_dat</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">threshold_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;unc&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">001</span><span class="p">})</span>

<span class="n">con1_stats</span><span class="p">[</span><span class="s1">&#39;thr_t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>threshold is ignored for simple axial plots
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_38_1.png" src="../_images/Thresholding_Group_Analyses_38_1.png" />
</div>
</div>
<p>We see some significant activations in visual cortex, but we also see strong t-tests in the auditory cortex.</p>
<p>Why do you think this is?</p>
<p>We can also easily run FDR correction by changing the inputs of the <code class="docutils literal notranslate"><span class="pre">threshold_dict</span></code>. We will be using a q value of 0.05 to control our false discovery rate.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">con1_stats</span> <span class="o">=</span> <span class="n">con1_dat</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">threshold_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fdr&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">05</span><span class="p">})</span>
<span class="n">con1_stats</span><span class="p">[</span><span class="s1">&#39;thr_t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>threshold is ignored for simple axial plots
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_41_1.png" src="../_images/Thresholding_Group_Analyses_41_1.png" />
</div>
</div>
<p>You can see that at least for this particular contrast, the FDR threshold appears to be more liberal than p &lt; 0.001 uncorrected.</p>
<p>Let’s look at another contrast between vertical and horizontal checkerboards.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">con2_name</span> <span class="o">=</span> <span class="s1">&#39;vertical_checkerboard&#39;</span>
<span class="n">con2_file_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;derivatives&#39;</span><span class="p">,</span><span class="s1">&#39;fmriprep&#39;</span><span class="p">,</span><span class="s1">&#39;*&#39;</span><span class="p">,</span> <span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;sub*_</span><span class="si">{</span><span class="n">con2_name</span><span class="si">}</span><span class="s1">*nii.gz&#39;</span><span class="p">))</span>
<span class="n">con2_file_list</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">con2_dat</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">con2_file_list</span><span class="p">)</span>

<span class="n">con1_v_con2</span> <span class="o">=</span> <span class="n">con1_dat</span><span class="o">-</span><span class="n">con2_dat</span>

<span class="n">con1_v_con2_stats</span> <span class="o">=</span> <span class="n">con1_v_con2</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">threshold_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;unc&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">001</span><span class="p">})</span>
<span class="n">con1_v_con2_stats</span><span class="p">[</span><span class="s1">&#39;thr_t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>threshold is ignored for simple axial plots
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_43_1.png" src="../_images/Thresholding_Group_Analyses_43_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">con1_v_con2_stats</span> <span class="o">=</span> <span class="n">con1_v_con2</span><span class="o">.</span><span class="n">ttest</span><span class="p">(</span><span class="n">threshold_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;fdr&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">05</span><span class="p">})</span>
<span class="n">con1_v_con2_stats</span><span class="p">[</span><span class="s1">&#39;thr_t&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>threshold is ignored for simple axial plots
</pre></div>
</div>
<img alt="../_images/Thresholding_Group_Analyses_44_1.png" src="../_images/Thresholding_Group_Analyses_44_1.png" />
</div>
</div>
<p>Looks like there are some significant differences that survive in early visual cortex and also in other regions of the brain.</p>
<p>This concludes are very quick overview to performing univariate analyses in fMRI data analysis.</p>
<p>We will continue to add more advanced tutorials to the dartbrains.org website. Stay tuned!</p>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<div class="section" id="exercise-1-bonferroni-correction-simulation">
<h3>Exercise 1. Bonferroni Correction Simulation<a class="headerlink" href="#exercise-1-bonferroni-correction-simulation" title="Permalink to this headline">¶</a></h3>
<p>Using the Grid Simulation code above, try to find how much larger the signal needs to be using a Bonferroni Correction until we can recover 100% of the true signal, while controlling a family wise error false-positive rate of p &lt; 0.05.</p>
</div>
<div class="section" id="exercise-2-which-regions-are-more-involved-with-visual-compared-to-auditory-sensory-processing">
<h3>Exercise 2. Which regions are more involved with visual compared to auditory sensory processing?<a class="headerlink" href="#exercise-2-which-regions-are-more-involved-with-visual-compared-to-auditory-sensory-processing" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>run a group level t-test and threshold using an uncorrected voxel-wise threshold of p &lt; 0.05, p &lt; 0.005, and p &lt; 0.001.</p></li>
<li><p>plot each of the results</p></li>
<li><p>write each file to your output folder.</p></li>
</ul>
</div>
<div class="section" id="exercise-3-which-regions-are-more-involved-in-processing-numbers-compared-to-words">
<h3>Exercise 3. Which regions are more involved in processing numbers compared to words?<a class="headerlink" href="#exercise-3-which-regions-are-more-involved-in-processing-numbers-compared-to-words" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>run a group level t-test, using a correcte FDR threshold of q &lt; 0.05.</p></li>
<li><p>plot the results</p></li>
<li><p>write the file to your output folder.</p></li>
</ul>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="Group_Analysis.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Group Analysis</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="Connectivity.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Connectivity</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Luke Chang<br/>
        
            &copy; Copyright 2021.<br/>
          <div class="extra_footer">
            Supported by an NSF CAREER Award 1848370, <a href='https://rc.dartmouth.edu/'>Dartmouth Research Computing</a>, and the <a href='https://dcal.dartmouth.edu/about/impact/experiential-learning'>Dartmouth Center for the Advancement of Learning</a>.
          </div>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-138270939-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </body>
</html>