
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Introduction to the General Linear Model &#8212; DartBrains</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="canonical" href="http://dartbrains.org/content/GLM.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Modeling Single Subject Data" href="GLM_Single_Subject_Model.html" />
    <link rel="prev" title="Preprocessing" href="Preprocessing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-138270939-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/dartbrains_logo_square_transparent.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DartBrains</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Instructors.html">
   Instructors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Schedule.html">
   Schedule
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Computing Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_JupyterHub.html">
   Introduction to JupyterHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Download_Data.html">
   Download Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Programming.html">
   Introduction to programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Pandas.html">
   Introduction to Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Plotting.html">
   Introduction to Plotting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Glossary.html">
   Glossary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Topics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_to_Neuroimaging.html">
   Introduction to Neuroimaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Measurement.html">
   Signal Generation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ICA.html">
   Separating Signal From Noise With ICA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Neuroimaging_Data.html">
   Introduction to Neuroimaging Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Processing.html">
   Signal Processing Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Preprocessing.html">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction to the General Linear Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="GLM_Single_Subject_Model.html">
   Modeling Single Subject Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Group_Analysis.html">
   Group Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Thresholding_Group_Analyses.html">
   Thresholding Group Analyses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_ICA.html">
   Introduction to Independent Components Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Connectivity.html">
   Connectivity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multivariate_Prediction.html">
   Multivariate Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="RSA.html">
   Representational Similarity Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Parcellations.html">
   Introduction to Parcellations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Resampling_Statistics.html">
   Resampling Statistics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Additional Courses
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="http://naturalistic-data.org/">
   Naturalistic Data Analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Project Gallery
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2019_Spring.html">
   Spring 2019
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Spring.html">
   Spring 2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Fall.html">
   Fall 2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021_Fall.html">
   Fall 2021
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2022_Fall.html">
   Fall 2022
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ljchang/dartbrains">
   GitHub Repository
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Post questions to <a href='https://www.askpbs.org/c/dartbrains'>DartBrains Discourse</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ljchang/dartbrains/master?urlpath=tree/content/GLM.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://jhub.dartmouth.edu/hub/user-redirect/git-pull?repo=https%3A//github.com/ljchang/dartbrains&urlpath=tree/dartbrains/content/GLM.ipynb&branch=master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ljchang/dartbrains/blob/master/content/GLM.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ljchang/dartbrains"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ljchang/dartbrains/issues/new?title=Issue%20on%20page%20%2Fcontent/GLM.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ljchang/dartbrains/edit/master/content/GLM.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/content/GLM.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#are-you-ready-for-this">
   Are you ready for this?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-a-voxel-time-course">
   Simulate a voxel time course
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-design-matrix">
   Construct Design Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimate-glm">
   Estimate GLM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-errors">
     Standard Errors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explained-variance">
     Explained Variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-error-of-beta-estimates">
     Standard Error of
     <span class="math notranslate nohighlight">
      \(\beta\)
     </span>
     estimates
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#statistical-significance">
     Statistical Significance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contrasts">
     Contrasts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#efficiency">
     Efficiency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#varying-the-inter-trial-interval-with-jittering">
     Varying the Inter-Trial Interval with Jittering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autocorrelation">
     Autocorrelation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1-what-happens-when-we-vary-the-signal-amplitude">
     Exercise 1. What happens when we vary the signal amplitude?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-2-what-happens-when-we-vary-the-noise">
     Exercise 2. What happens when we vary the noise?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-3-how-many-trials-do-we-need">
     Exercise 3. How many trials do we need?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-4-what-is-the-impact-of-the-stimulus-duration">
     Exercise 4. What is the impact of the stimulus duration?
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Introduction to the General Linear Model</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#are-you-ready-for-this">
   Are you ready for this?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#simulate-a-voxel-time-course">
   Simulate a voxel time course
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#construct-design-matrix">
   Construct Design Matrix
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimate-glm">
   Estimate GLM
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-errors">
     Standard Errors
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#explained-variance">
     Explained Variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#standard-error-of-beta-estimates">
     Standard Error of
     <span class="math notranslate nohighlight">
      \(\beta\)
     </span>
     estimates
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#statistical-significance">
     Statistical Significance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#contrasts">
     Contrasts
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#efficiency">
     Efficiency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#varying-the-inter-trial-interval-with-jittering">
     Varying the Inter-Trial Interval with Jittering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#autocorrelation">
     Autocorrelation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#exercises">
   Exercises
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-1-what-happens-when-we-vary-the-signal-amplitude">
     Exercise 1. What happens when we vary the signal amplitude?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-2-what-happens-when-we-vary-the-noise">
     Exercise 2. What happens when we vary the noise?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-3-how-many-trials-do-we-need">
     Exercise 3. How many trials do we need?
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exercise-4-what-is-the-impact-of-the-stimulus-duration">
     Exercise 4. What is the impact of the stimulus duration?
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-the-general-linear-model">
<h1>Introduction to the General Linear Model<a class="headerlink" href="#introduction-to-the-general-linear-model" title="Permalink to this headline">#</a></h1>
<p><em>Written by Luke Chang</em></p>
<p>This tutorial provides an introduction for how the general linear model (GLM) can be used to make inferences about brain responses in a single subject. We will explore the statistics in the context of a simple hypothetical experiment using simulated data.</p>
<p>In this lab we will cover:</p>
<ul class="simple">
<li><p>How to use a GLM to test psychological hypotheses.</p></li>
<li><p>Simulating brain data</p></li>
<li><p>Estimating GLM using ordinary least squares</p></li>
<li><p>Calculating Standard Errors</p></li>
<li><p>Contrast Basics</p></li>
</ul>
<p>Let’s start by watching two short videos introducing the general linear model by Tor Wager and how this can be applied to fMRI.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">YouTubeVideo</span>

<span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;GDkLQuV4he4&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/GDkLQuV4he4"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;OyLKMb9FNhg&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/OyLKMb9FNhg"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<section id="are-you-ready-for-this">
<h2>Are you ready for this?<a class="headerlink" href="#are-you-ready-for-this" title="Permalink to this headline">#</a></h2>
<p>This lab assumes that you have some basic background knowledge in statistics from an introductory course. If you are already feeling overwhelmed from Tor Wager’s videos and think you might need to slow down and refresh some basic concepts and lingo, I highly encourage you to watch Jeannette Mumford’s crash course in statistics. These are certainly not required, but she is a wonderful teacher and watching her videos will provide an additional explanation of the core concepts needed to understand the GLM. You could watch these in one sitting, or go back and forth with working through the notebooks. There is so much to know in statistics and people can often feel lost because the concepts are certainly not intuitive. For example, even though advanced statistics have been an important part of my own work, I still find it helpful to periodically revisit core concepts. In general, I find that learning neuroimaging is an iterative process. In the beginning, it is important to get a broad understanding of the key steps and how neuroimaging can be used to make inferences, but as you progress in your training you will have plenty of opportunities to zoom into specific steps to learn more about particular details and nuances that you may not have fully appreciated the first time around.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://youtu.be/apt8uAgtgdY">Basic statistics terminology</a> This video gently introduces some of the key concepts that provide the foundation for statistics.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=yLgPpmXVVbs">Simple Linear Regression</a> This video explains how a regression works using a single variable.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=fkZj8QoYjq8">Matrix Algebra Basics</a> This video provides the background linear algebra needed for understanding the GLM.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=qdOG7YMolmA">Multiple Linear Regression</a> This video explains how multiple regression works using linear algebra.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=ULeg3DH3g9w">Hypothesis Testing</a> This video covers the basics of hypothesis testing.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=yLgPpmXVVbs&amp;t=631s">Contrasts in Linear Models</a> This video provides an overview of how to test hypotheses using contrasts in the context of the GLM.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=uClfe4pLrCo">Intepreting Regression Parameters</a> This video covers how to interpret the results from a regression analysis.</p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=K4S576j90N8">Mean Centering Regressors</a> This video covers a more subtle detail of why you might consider mean centering your continuour regression variables.</p></li>
</ul>
<p>Ok, let’s get started. First, we will need to import all of the modules used in this tutorial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">nltools.stats</span> <span class="kn">import</span> <span class="n">regress</span>
<span class="kn">from</span> <span class="nn">nltools.external</span> <span class="kn">import</span> <span class="n">glover_hrf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/lukechang/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.
  warnings.warn(message, FutureWarning)
</pre></div>
</div>
</div>
</div>
</section>
<section id="simulate-a-voxel-time-course">
<h2>Simulate a voxel time course<a class="headerlink" href="#simulate-a-voxel-time-course" title="Permalink to this headline">#</a></h2>
<p>To generate an intuition for how we use the GLM to make inferences in fMRI data analysis, we will simulate a time series for a single voxel. A simulation means that we will be generating synthetic data that will resemble real data. However, because we know the ground truth of the signal, we can evaluate how well we can recover the true signal using a general linear model. Throughout this course, we frequently rely on simulations to gain an intuition for how a particular preprocessing step or statistic works. This is important because it reinforces the assumptions behind the operation (which are rarely met in real data), and also provides a method to learn how to answer your own questions by generating your own simulations.</p>
<p>Imagine that we are interested in identifying which region of the brain is involved in processing faces. To explore this question, we could show participants a bunch of different types of faces. Each presentation of a face will be a <em>trial</em>. Let’s simulate what a design might look like with 5 face trials.</p>
<p>First, we will need to specify the number of volumes in the time series. Then we need to specify the timepoint, in which a face is presented.</p>
<p><img alt="faces" src="../_images/faces.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">plot_timeseries</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&#39;&#39;&#39;Plot a timeseries</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        data: (np.ndarray) signal varying over time, where each column is a different signal.</span>
<span class="sd">        labels: (list) labels which need to correspond to the number of columns.</span>
<span class="sd">        linewidth: (int) thickness of line</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">linewidth</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Intensity&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">labels</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">!=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Need to have the same number of labels as columns in data.&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    
<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">face</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_7_0.png" src="../_images/GLM_7_0.png" />
</div>
</div>
<p>We now have 5 events where a face is shown for 2 seconds (i.e., one TR). If we scanned someone with this design, we might expect to see any region involved in processing faces increase in activation around the time of the face presentation. How would we know which of these regions, if any, <em>selectively</em> process faces? Many of the regions we would observe are likely involved in processing <em>any</em> visual stimulus, and not specifically faces.</p>
<p>To rule out this potential confound, we would need at least one other condition that would serve as a visual control. Something that might have similar properties to a face, but isn’t a face.</p>
<p>One possibility is to create a visual stimulus that has all of the same visual properties in terms of luminance and color, but no longer resembles a face. Here is an example of the same faces that have been Fourier transformed, phase-scrambled, and inverse Fourier transformed. These pictures have essentially identical low level visual properties, but are clearly not faces.</p>
<p><img alt="phase" src="../_images/phase_scrambled.png" /></p>
<p>However, one might argue that faces are a type of object, and regions that are involved in higher visual processing such as object recognition might not be selective to processing faces. To rule out this possibility, we would need to add an additional visual control such as objects.</p>
<p><img alt="objects" src="../_images/objects.png" /></p>
<p>Both of these conditions could serve as a different type of visual control. To keep things simple, let’s start with pictures of objects as it controls for low level visual features, but also more complex object processing.</p>
<p>To demonstrate that a region is processing faces and not simply lower level visual properties or objects more generally, we can search for regions that are selectively more activated in response to viewing faces relative to objects. This is called a <em>contrast</em> and is the basic principle of the subtraction method for controlling for potential experimental confounds. Because BOLD fMRI is a relative and not absolute measure of brain activity, the subtraction method is a key aspect of experimental design.</p>
<p>Figures are from Huettel, Song, &amp; McCarthy (2008)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">voxel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">face</span><span class="p">,</span><span class="n">obj</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_9_0.png" src="../_images/GLM_9_0.png" />
</div>
</div>
<p>Let’s imagine that in a voxel processing face specific information we might expect to see a larger activation in response to faces. Maybe two times bigger?</p>
<p>In our simulation, these two values are parameters we are specifying to generate the data. Specifically they refer to the amplitude of the response to Faces and Houses within a particular region of the brain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face_intensity</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">object_intensity</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="n">face_intensity</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="n">object_intensity</span>
<span class="n">voxel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">face</span><span class="p">,</span><span class="n">obj</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_11_0.png" src="../_images/GLM_11_0.png" />
</div>
</div>
<p>Ok, now we have two conditions that are alternating over time.</p>
<p>We know that the brain has a delayed hemodynamic response to events that has a particular shape, so we will need to convolve these events with an appropriate HRF function. Here, we will use the double-gamma HRF function.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tr</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">hrf</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">hrf</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Intensity&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Time&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_13_1.png" src="../_images/GLM_13_1.png" />
</div>
</div>
<p>We will use <code class="docutils literal notranslate"><span class="pre">np.convolve</span></code> from numpy to perform the convolution.  The length of the convolved data will be the length of the time series plus the length of the kernel minus 1. To make sure everything is the same length, we will chop off the extra time off the convolved time series using <code class="docutils literal notranslate"><span class="pre">mode='same'</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">face_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
<span class="n">obj_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
<span class="n">voxel_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">face_conv</span><span class="p">,</span> <span class="n">obj_conv</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel_conv</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_15_0.png" src="../_images/GLM_15_0.png" />
</div>
</div>
<p>While this might reflect the expected HRF response to a single event, real data is much noiser. It is easy to add different types of noise. For example, there might be a low frequency drift, autocorrelation, or possibly some aliased physiological artifacts.</p>
<p>For now, let’s start with something simple, like independent white noise drawn from a random Gaussian distribution</p>
<div class="math notranslate nohighlight">
\[\epsilon \sim \mathcal{N}(\mu,\,\sigma^{2})\]</div>
<p>where <span class="math notranslate nohighlight">\(\mu = 0\)</span> and <span class="math notranslate nohighlight">\(\sigma = 0.15\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_tr</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">voxel_conv_noise</span> <span class="o">=</span> <span class="n">voxel_conv</span> <span class="o">+</span> <span class="n">epsilon</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">voxel_conv_noise</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_17_0.png" src="../_images/GLM_17_0.png" />
</div>
</div>
<p>Now this is looking much more like real BOLD activity.</p>
<p>Remember, the goal of this exercise is to generate simulated activity from a voxel. If we were to extract signal from a specific voxel we wouldn’t know which condition was which, so let’s combine these two signals into a single simulated voxel timeseries by adding the two vectors together with the <code class="docutils literal notranslate"><span class="pre">.sum()</span></code> method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">voxel_conv_noise</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_19_0.png" src="../_images/GLM_19_0.png" />
</div>
</div>
</section>
<section id="construct-design-matrix">
<h2>Construct Design Matrix<a class="headerlink" href="#construct-design-matrix" title="Permalink to this headline">#</a></h2>
<p>Now that we have our simulated voxel timeseries, let’s try and see if we can recover the original signal using a general linear model in the form of:</p>
<div class="math notranslate nohighlight">
\[Y = X\beta + \epsilon\]</div>
<p>where <span class="math notranslate nohighlight">\(Y\)</span> is our observed voxel time series. <span class="math notranslate nohighlight">\(X\)</span> is our model or design matrix, and is where we will specify a predicted response to each condition. <span class="math notranslate nohighlight">\(\beta\)</span> is a vector of values that we will estimate to scale our model. <span class="math notranslate nohighlight">\(\epsilon\)</span> is independent gaussian noise. This model is linear because we can decompose <span class="math notranslate nohighlight">\(Y\)</span> into a set of features or independent variables that are scaled by an estimated <span class="math notranslate nohighlight">\(\beta\)</span> parameter and summed together. The <span class="math notranslate nohighlight">\(\epsilon\)</span> parameter is not usually known and can also be estimated.</p>
<p>You may be wondering how our model is distinct from our simulated data. Remember when we simulated the data we specified 3 parameters - face amplitude, object amplitude, and <span class="math notranslate nohighlight">\(\epsilon\)</span>, we could have also added a mean, but for now, let’s just assume that it is zero. When we fit our model to the simulated data, we should in theory be able to almost perfectly recover these three parameters.</p>
<p>Now let’s build a design matrix <span class="math notranslate nohighlight">\(X\)</span> using an intercept, and a regressor indicating the onset of each condition, convolved with the hemodynamic response function (HRF).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_tr</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">n_tr</span><span class="o">/</span><span class="n">n_trial</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">intercept</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_22_0.png" src="../_images/GLM_22_0.png" />
</div>
</div>
<p>We can write our model out so that it is very clear what we are doing.</p>
<div class="math notranslate nohighlight">
\[Voxel = \beta_0 \cdot Intercept + \beta_1 \cdot Faces + \beta_2 \cdot Objects + \epsilon\]</div>
<p>We can also make a plot and rotate the timeseries, to better reflect the equation.</p>
<p>It should be clear how each of these components relate to the regression equation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">2</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">)))</span>
<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Time&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Faces&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">a</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Objects&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">invert_yaxis</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/GLM_24_0.png" src="../_images/GLM_24_0.png" />
</div>
</div>
</section>
<section id="estimate-glm">
<h2>Estimate GLM<a class="headerlink" href="#estimate-glm" title="Permalink to this headline">#</a></h2>
<p>Now that have created our simulated voxel timeseries <span class="math notranslate nohighlight">\(Y\)</span> and our design matrix <span class="math notranslate nohighlight">\(X\)</span>, we need to fit our model to the data by estimating the three <span class="math notranslate nohighlight">\(\beta\)</span> parameters.</p>
<p>There are several ways to estimate the parameters for our general linear model. The Ordinary Least Squares (OLS) estimator finds the <span class="math notranslate nohighlight">\(\hat\beta\)</span> hyperplane that minimizes the error between the observed <span class="math notranslate nohighlight">\(Y\)</span> and predicted <span class="math notranslate nohighlight">\(\hat Y\)</span>.</p>
<p>This can be formulated using linear algebra as:</p>
<div class="math notranslate nohighlight">
\[\hat{\beta} = (X^T X)^{-1}X^TY\]</div>
<p>There is also maximum likelihood estimator, which should produce an almost identical result to the ordinary least squares estimator when the error terms are normally distributed.</p>
<div class="math notranslate nohighlight">
\[L(\beta, \sigma^2 | Y, X) = \displaystyle \prod_{i=1}^{n}\frac{1}{\sqrt(2\pi\sigma^2)} \cdot e^{-\frac{(Y_i - \beta X_i)^2}{2\sigma^2}}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[\mathcal{N}(0,\sigma^{2})\]</div>
<p>For this class, we will primarily be focusing on the Ordinary Least Squares Estimator. In fact, just to demonstrate that the math is actually relatively straightforward, we will write our own function for the estimator using the linear algebra formulation. In practice, we typically will use a premade function, which is usually slightly more computationally efficient and will also calculate standard errors, etc.</p>
<p>For a more in depth overview of GLM estimation, watch this <a class="reference external" href="https://www.youtube.com/watch?v=Ab-5AbJ8gAs">video</a> by Tor Wager and Martin Lindquist.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ols_estimator</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)),</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">),</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">beta</span> <span class="o">=</span> <span class="n">ols_estimator</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span><span class="s1">&#39;Faces&#39;</span><span class="p">,</span> <span class="s1">&#39;Objects&#39;</span><span class="p">],</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Regressor&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Beta Value&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;beta Faces - beta Objects: </span><span class="si">{</span><span class="n">beta</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">beta</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="si">:</span><span class="s1">.2</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>beta Faces - beta Objects: 0.95
</pre></div>
</div>
<img alt="../_images/GLM_26_1.png" src="../_images/GLM_26_1.png" />
</div>
</div>
<p>We can see that our model is working pretty well. We did not add a mean to the simulated timeseries, so our estimator correctly figures out that the intercept parameter should be zero. The model also correctly figured out that the scaling parameter for the faces regressor was 2, and 1 for the objects regressor, with the difference between them equal to approximately 1.</p>
<p>Another way to evaluate how well our model is working is to plot our predicted <span class="math notranslate nohighlight">\(\hat Y\)</span> on top of our simulated <span class="math notranslate nohighlight">\(Y\)</span>.</p>
<p>We can quantify the degree to which our model is accurately predicting the observed data by calculating the residual.</p>
<div class="math notranslate nohighlight">
\[residual = Y - \hat Y\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

<span class="n">predicted_ts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">predicted_ts</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Simulated Voxel&#39;</span><span class="p">,</span> <span class="s1">&#39;Predicted Voxel&#39;</span><span class="p">])</span>

<span class="n">residual</span> <span class="o">=</span> <span class="n">Y</span> <span class="o">-</span> <span class="n">predicted_y</span>

<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Residual&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Residual&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_28_1.png" src="../_images/GLM_28_1.png" />
<img alt="../_images/GLM_28_2.png" src="../_images/GLM_28_2.png" />
</div>
</div>
<section id="standard-errors">
<h3>Standard Errors<a class="headerlink" href="#standard-errors" title="Permalink to this headline">#</a></h3>
<p>As you can see, we are doing a reasonable job recovering the original signals.</p>
<p>You may recall that we specified 3 parameters in our simulation</p>
<ul class="simple">
<li><p>a <span class="math notranslate nohighlight">\(\beta\)</span> weight for faces</p></li>
<li><p>a <span class="math notranslate nohighlight">\(\beta\)</span> weight for objects</p></li>
<li><p>an <span class="math notranslate nohighlight">\(\epsilon\)</span> noise parameter.</p></li>
</ul>
<p>The <em>standard error of the estimate</em> refers to the standard deviation of the residual.</p>
<p>Formally, this can be described as:</p>
<div class="math notranslate nohighlight">
\[\hat \sigma = \sqrt{\frac{\displaystyle \sum_i^n(\hat Y_i - Y_i)^2}{n-k}}\]</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the number of observations and <span class="math notranslate nohighlight">\(k\)</span> is the total number of regressors.</p>
<p>This number is essentially an estimate of the overall amount of error in the model or <span class="math notranslate nohighlight">\(\epsilon\)</span>. This error is assumed to be independent and normally distributed. The smaller the residual variance <span class="math notranslate nohighlight">\(\hat\sigma\)</span> the better the fit of the model.</p>
<p>As you can see, the parameter is close, but slightly higher than the one we simulated.  This might be because we have relatively little data in our simulation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">standard_error_of_estimate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Standard Error of the Estimate: </span><span class="si">{</span><span class="n">standard_error_of_estimate</span><span class="si">:</span><span class="s2">.2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Distribution of Residual Error&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Prediction Error&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Standard Error of the Estimate: 0.2
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 0, &#39;Prediction Error&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_30_2.png" src="../_images/GLM_30_2.png" />
</div>
</div>
</section>
<section id="explained-variance">
<h3>Explained Variance<a class="headerlink" href="#explained-variance" title="Permalink to this headline">#</a></h3>
<p>Sometimes we want a single metric to quantify overall how well our model was able to explain variance in the data. There are many metrics that can provide a quantitative measure of <em>goodness of fit</em>.</p>
<p>Here we will calculate <span class="math notranslate nohighlight">\(R^2\)</span> using the following formula:</p>
<div class="math notranslate nohighlight">
\[R^2 = 1 - \frac{\displaystyle \sum_i^n(\hat y_i - y_i)^2}{\displaystyle \sum_i^n(y_i - \bar y)^2}\]</div>
<p>where <span class="math notranslate nohighlight">\(y_i\)</span> is the measured value of the voxel at timepoint <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(\hat y_i\)</span> is the predicted value for time point <span class="math notranslate nohighlight">\(i\)</span>, and <span class="math notranslate nohighlight">\(\bar y\)</span> is the mean of the measured voxel timeseries.</p>
<p><span class="math notranslate nohighlight">\(R^2\)</span> will lie on the interval between <span class="math notranslate nohighlight">\([0,1]\)</span> and can be interpreted as percentage of the total variance in <span class="math notranslate nohighlight">\(Y\)</span> explained by the model, <span class="math notranslate nohighlight">\(X\)</span>, where 1 is 100% and 0 is none.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">r_square</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">):</span>
    <span class="n">SS_total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">SS_residual</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">Y</span> <span class="o">-</span> <span class="n">predicted_y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">-</span><span class="p">(</span><span class="n">SS_residual</span><span class="o">/</span><span class="n">SS_total</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;R^2: </span><span class="si">{</span><span class="n">r_square</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span><span class="w"> </span><span class="n">predicted_y</span><span class="p">)</span><span class="si">:</span><span class="s2">.2</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R^2: 0.6
</pre></div>
</div>
</div>
</div>
</section>
<section id="standard-error-of-beta-estimates">
<h3>Standard Error of <span class="math notranslate nohighlight">\(\beta\)</span> estimates<a class="headerlink" href="#standard-error-of-beta-estimates" title="Permalink to this headline">#</a></h3>
<p>We can also estimate the uncertainty of regression coefficients. The uncertainty of the beta parameters is quantified as a standard error around each specific estimate.</p>
<div class="math notranslate nohighlight">
\[\sigma = \sqrt{diag((X^TX)^{-1})} \cdot \hat \sigma\]</div>
<p>This is essentially a confidence interval around the <span class="math notranslate nohighlight">\(\beta_j\)</span> estimate. One standard error, <span class="math notranslate nohighlight">\(1*\hat \sigma\)</span> is approximately equivalent to a 68% confidence interval, while <span class="math notranslate nohighlight">\(2*\hat\sigma\)</span> is approximately a 95% confidence interval.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">std_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">)))))</span> <span class="o">*</span> <span class="n">standard_error_of_estimate</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span><span class="s1">&#39;Faces&#39;</span><span class="p">,</span> <span class="s1">&#39;Objects&#39;</span><span class="p">],</span> <span class="n">beta</span><span class="p">,</span> <span class="n">yerr</span> <span class="o">=</span> <span class="n">std_error</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Regressor&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Beta Value&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Beta Value&#39;)
</pre></div>
</div>
<img alt="../_images/GLM_35_1.png" src="../_images/GLM_35_1.png" />
</div>
</div>
</section>
<section id="statistical-significance">
<h3>Statistical Significance<a class="headerlink" href="#statistical-significance" title="Permalink to this headline">#</a></h3>
<p>We could also perform a hypothesis test to evaluate if any of the regressors are statistically different from zero.</p>
<p>This exercise is simply meant to provide parallels to common statistical jargon. In practice, this is actually rarely done in neuroimaging analysis as we are typically more interested in making statistical inferences across the population rather than within a single participant.</p>
<p>The formula for calculating a t-statistic is very simple:</p>
<div class="math notranslate nohighlight">
\[t = \frac{\hat \beta_j}{\hat \sigma_j}\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta_j\)</span> refers to the estimated parameter for a regressor <span class="math notranslate nohighlight">\(j\)</span>, and <span class="math notranslate nohighlight">\(\sigma_j\)</span> refers to the standard error of regressor <span class="math notranslate nohighlight">\(j\)</span>.</p>
<p><span class="math notranslate nohighlight">\(t\)</span> values that are more than 2 standard errors away from zero are called <em>statistically significant</em>, which basically just means we are more confident that the estimate is stable and not just an artifact of small sample size. In general, we don’t recommend reading too much into significance for individual <span class="math notranslate nohighlight">\(\beta\)</span> estimates in single subject fMRI analysis.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="n">beta</span><span class="o">/</span><span class="n">std_error</span>
<span class="n">t</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.65716867, 15.83929013,  8.23580115])
</pre></div>
</div>
</div>
</div>
<p>Just like in intro statistics, we could find the p-value that corresponds to a particular t-statistic using the t-distribution. We will load the t distribution from <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> and calculate the corresponding p-values using the survival function or  <span class="math notranslate nohighlight">\(1- cdf\)</span>, which requires specifying the degrees of freedom (df), which is <span class="math notranslate nohighlight">\(n-1\)</span>. We multiply these values by 2 to calculated a two-tailed test.</p>
<p>You can see that the intercept <span class="math notranslate nohighlight">\(\beta\)</span> is not significant, but the face and object regressors are well below <code class="docutils literal notranslate"><span class="pre">p</span> <span class="pre">&lt;</span> <span class="pre">0.05</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>

<span class="n">p</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t</span><span class="p">),</span> <span class="n">n_tr</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span> <span class="s1">&#39;Face&#39;</span><span class="p">,</span> <span class="s1">&#39;Object&#39;</span><span class="p">],</span> <span class="n">p</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;p-values&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Regressor&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mf">0.05</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[5.11831798e-01 4.26134329e-37 2.33906074e-14]
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.collections.LineCollection at 0x7fe020f135d0&gt;
</pre></div>
</div>
<img alt="../_images/GLM_39_2.png" src="../_images/GLM_39_2.png" />
</div>
</div>
</section>
<section id="contrasts">
<h3>Contrasts<a class="headerlink" href="#contrasts" title="Permalink to this headline">#</a></h3>
<p>Contrasts are a very important concept in fMRI data analysis as they provide the statistical inference underlying the subtraction method of making inferences.</p>
<p>Let’s watch a short video by Tor Wager on contrasts. We will also spend much more time on contrasts in the group analysis tutorial. We also recommend watching Jeannette Mumford’s <a class="reference external" href="https://www.youtube.com/watch?v=yLgPpmXVVbs">overview</a> of contrasts for a more statistical perspective.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">YouTubeVideo</span><span class="p">(</span><span class="s1">&#39;7MibM1ATai4&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<iframe
    width="400"
    height="300"
    src="https://www.youtube.com/embed/7MibM1ATai4"
    frameborder="0"
    allowfullscreen
></iframe>
</div></div>
</div>
<p>Contrasts describe a linear combination of variables in a regression model whose coefficients add up to zero. This allows us to flexibly compare different experimental conditions.</p>
<p>For example, suppose we just wanted to know the magnitude of an effect for a single condition, such as the brain response to faces. We would create a contrast code that isolates the effect size (i.e., <span class="math notranslate nohighlight">\(\beta\)</span> estimate for the face regressor)</p>
<p>If our GLM, was:</p>
<div class="math notranslate nohighlight">
\[Y = \beta_0 \cdot Intercept + \beta_1 \cdot Faces + \beta_2 \cdot Objects\]</div>
<p>then, the corresponding contrast code or vector for faces would be:</p>
<p>[0, 1, 0]</p>
<p>The contrast code for the object condition would be:</p>
<p>[0, 0, 1]</p>
<p>and importantly the contrast <em>between</em> the face and object condition would be:</p>
<p>[0, 1, -1]</p>
<p>More simply, we are calculating the magnitude of the effect of the difference between viewing faces and objects in a single voxel.</p>
<p>To make this a little bit more clear, we will show a graphical representation of the design matrix to make it obvious what we are contrasting.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="n">c1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">c3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="p">{(</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">),</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">c</span><span class="p">))</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">]}</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{(&#39;[0, 0, 1]&#39;, 1.0721521304389894),
 (&#39;[0, 1, -1]&#39;, 0.8735019759362619),
 (&#39;[0, 1, 0]&#39;, 1.9456541063752513)}
</pre></div>
</div>
<img alt="../_images/GLM_43_1.png" src="../_images/GLM_43_1.png" />
</div>
</div>
</section>
<section id="efficiency">
<h3>Efficiency<a class="headerlink" href="#efficiency" title="Permalink to this headline">#</a></h3>
<p>We can estimate the efficiency, or the quality of an estimator for a specific experimental design or a hypothesis testing procedure. Efficiency is related to power, or the ability to detect an effect should one exist. However, unlike power, we can estimate efficiency from our design matrix and do not actually need to know the standard error for the model (unlike with power calculations). Specifically, efficiency is defined as the inverse of the sum of the estimator variances. For a more detailed explanation and general experimental design recommendations see this <a class="reference external" href="http://imaging.mrc-cbu.cam.ac.uk/imaging/DesignEfficiency">overview</a> by Rik Henson, or this <a class="reference external" href="https://theclevermachine.wordpress.com/tag/fmri-design-efficiency/">blog post</a> on efficiency in experimental designs.</p>
<div class="math notranslate nohighlight">
\[e(c\hat\beta) = \frac{1}{c(X^TX)^{-1}c^T}\]</div>
<p>Reducing collinearity or covariance between regressors can increase design efficiency</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">contrast_efficiency</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">contrast</span><span class="p">):</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">contrast</span><span class="p">)</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X</span><span class="p">))),</span> <span class="n">c</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>

<span class="n">c1</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">c2</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">c3</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="p">[</span><span class="n">contrast_efficiency</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.44032677542221, 2.5429401030547045, 1.3578767952519295]
</pre></div>
</div>
</div>
</div>
</section>
<section id="varying-the-inter-trial-interval-with-jittering">
<h3>Varying the Inter-Trial Interval with Jittering<a class="headerlink" href="#varying-the-inter-trial-interval-with-jittering" title="Permalink to this headline">#</a></h3>
<p>All of the examples so far have used a fixed inter-trial interval. However, in real experiments it is almost always a good idea to vary the inter-trial interval using jitter. This helps to decouple the slice acquisition with the experimental design to better sample the hemodynamic response over multiple trials. In addition, this can help reduce the temporal correlation between regressors modeling events that may be sequentially dependent. For example, there may be multiple parts of a trial. For example, imagine an associative learning experiment in which a cue predicts an outcome. As the cue epoch will always temporally precede the outcome epoch, it can be beneficial to temporally decouple these epochs to reduce collinearity in the design matrix, which will increase the efficiency of the experimental design. Finally, adding jitter to the inter-trial interval may help reduce participant’s ability to temporally predict when the next event will happen, which may be desireable depending on the psychological question of interest.</p>
<p>Here is an example for how to add jitter to our simulated experiment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set Simulation Parameters</span>
<span class="n">n_tr</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">n_trial</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">face_intensity</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">object_intensity</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.15</span>

<span class="c1"># Build Simulation</span>
<span class="n">face_trials</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="n">n_trial</span><span class="p">)</span>
<span class="n">obj_trials</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">180</span><span class="p">,</span> <span class="n">n_trial</span><span class="p">)</span>
<span class="n">face</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">face</span><span class="p">[</span><span class="n">face_trials</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">obj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_tr</span><span class="p">)</span>
<span class="n">obj</span><span class="p">[</span><span class="n">obj_trials</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">voxel_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="o">*</span><span class="n">face_intensity</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="o">*</span><span class="n">object_intensity</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
<span class="n">epsilon</span> <span class="o">=</span> <span class="n">sigma</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_tr</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">voxel_conv_noise</span> <span class="o">=</span> <span class="n">voxel_conv</span> <span class="o">+</span> <span class="n">epsilon</span>

<span class="c1"># Build Model</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">voxel_conv_noise</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">face</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">obj</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Estimate Model</span>
<span class="n">beta</span> <span class="o">=</span> <span class="n">ols_estimator</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">predicted_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
<span class="n">predicted_sigma</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">residual</span><span class="p">)</span>
<span class="n">predicted_ts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">Y</span><span class="p">,</span> <span class="n">predicted_y</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
<span class="n">plot_timeseries</span><span class="p">(</span><span class="n">predicted_ts</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Simulated Voxel&#39;</span><span class="p">,</span> <span class="s1">&#39;Predicted Voxel&#39;</span><span class="p">])</span>

<span class="c1"># Estimate Contrast Efficiency</span>
<span class="p">[</span><span class="n">contrast_efficiency</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="n">c1</span><span class="p">,</span> <span class="n">c2</span><span class="p">,</span> <span class="n">c3</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[2.5597167760964403, 2.066820546582558, 1.1233445684652128]
</pre></div>
</div>
<img alt="../_images/GLM_47_1.png" src="../_images/GLM_47_1.png" />
</div>
</div>
</section>
<section id="autocorrelation">
<h3>Autocorrelation<a class="headerlink" href="#autocorrelation" title="Permalink to this headline">#</a></h3>
<p>The BOLD signal has some intrinsic autocorrelation that varies with the length of the TR. Different software packages have provided varying solutions to this problem. For example, SPM implements an AR(1) model, which means that it trys to account for the fact that the signal is consistently correlated (i.e., autoregressive) with one lag. In practice, these will rarely change the beta estimates, but rather will adjust our standard errors around the estimates. As we will discuss soon, most group level analyses ignore these subject level, or first-level errors anyway. It is debatable if this is actually a good practice, but it reduces the importance of accounting for autocorrelation when looking at group level statistics in standard experimental design.</p>
<p>Another important thing to note is that there is some evidence that the AR(1) model can actually increase false positives, especially in shorter TRs.  See this <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811912003825">paper</a> by Anders Ekland and colleagues for more details. Also, this is a helpful <a class="reference external" href="https://mandymejia.com/2016/11/06/how-to-efficiently-prewhiten-fmri-timeseries-the-right-way/">blog post</a> discussing prewhitening.</p>
<p>For the scope of this course we will largely be ignoring this issue, but I will plan to add some examples and simulations in the future.  For now, I encourage you to watch this video on <a class="reference external" href="https://www.youtube.com/watch?v=Mb9LDzvhecY&amp;list=PLfXA4opIOVrGHncHRxI3Qa5GeCSudwmxM&amp;index=24">AR models</a> if you are interested in learning more about this topic.</p>
</section>
</section>
<section id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">#</a></h2>
<p>For our homework exercises, let’s use the simulation to answer questions we might have about experimental design.</p>
<section id="exercise-1-what-happens-when-we-vary-the-signal-amplitude">
<h3>Exercise 1. What happens when we vary the signal amplitude?<a class="headerlink" href="#exercise-1-what-happens-when-we-vary-the-signal-amplitude" title="Permalink to this headline">#</a></h3>
<p>Some signals will be very strong and others weaker. How does the model fit change when the signal amplitudes are stronger and weaker?</p>
<p>In this exercise, make a plot showing how the <span class="math notranslate nohighlight">\(r^2\)</span> changes over 3 different levels of signal intensity.</p>
</section>
<section id="exercise-2-what-happens-when-we-vary-the-noise">
<h3>Exercise 2. What happens when we vary the noise?<a class="headerlink" href="#exercise-2-what-happens-when-we-vary-the-noise" title="Permalink to this headline">#</a></h3>
<p>How does the amount of noise in the data impact our model fits?</p>
<p>In this exercise, make a plot showing the <span class="math notranslate nohighlight">\(r^2\)</span> for 3 different levels of simulated noise.</p>
</section>
<section id="exercise-3-how-many-trials-do-we-need">
<h3>Exercise 3. How many trials do we need?<a class="headerlink" href="#exercise-3-how-many-trials-do-we-need" title="Permalink to this headline">#</a></h3>
<p>A common question in experimental design is determining the optimal number of trials.</p>
<p>In this exercise, try evaluating how 3 different numbers of trials might impact the contrast efficiency.</p>
</section>
<section id="exercise-4-what-is-the-impact-of-the-stimulus-duration">
<h3>Exercise 4. What is the impact of the stimulus duration?<a class="headerlink" href="#exercise-4-what-is-the-impact-of-the-stimulus-duration" title="Permalink to this headline">#</a></h3>
<p>What if one condition simply results in processes that systematically take longer than the other condition?</p>
<p>In this exercise, let’s try to answer this question by creating a simulation where the signal intensity between the two condition is identical, but one simply has a longer duration (i.e., the duration has more TRs than the other condition).</p>
<p>Make a plot showing what happens to the <span class="math notranslate nohighlight">\(\beta\)</span> estimates.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Preprocessing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Preprocessing</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="GLM_Single_Subject_Model.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Modeling Single Subject Data</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Luke Chang<br/>
  
      &copy; Copyright 2021.<br/>
    <div class="extra_footer">
      Supported by an NSF CAREER Award 1848370, <a href='https://rc.dartmouth.edu/'>Dartmouth Research Computing</a>, and the <a href='https://dcal.dartmouth.edu/about/impact/experiential-learning'>Dartmouth Center for the Advancement of Learning</a>.
    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>