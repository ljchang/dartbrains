
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Introduction to Parcellations &#8212; DartBrains</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="canonical" href="http://dartbrains.org/content/Parcellations.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Resampling Statistics" href="Resampling_Statistics.html" />
    <link rel="prev" title="Representational Similarity Analysis" href="RSA.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<script>
                        window.ga = window.ga || function () {
                            (ga.q = ga.q || []).push(arguments) };
                        ga.l = +new Date;
                        ga('create', 'UA-138270939-1', 'auto');
                        ga('set', 'anonymizeIp', true);
                        ga('send', 'pageview');
                    </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/dartbrains_logo_square_transparent.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">DartBrains</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Overview
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Instructors.html">
   Instructors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Syllabus.html">
   Syllabus
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Schedule.html">
   Schedule
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Computing Resources
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_JupyterHub.html">
   Introduction to JupyterHub
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Download_Data.html">
   Download Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Programming.html">
   Introduction to programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Pandas.html">
   Introduction to Pandas
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Plotting.html">
   Introduction to Plotting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Glossary.html">
   Glossary
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Course Topics
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_to_Neuroimaging.html">
   Introduction to Neuroimaging
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Measurement.html">
   Signal Generation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ICA.html">
   Separating Signal From Noise With ICA
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Introduction_to_Neuroimaging_Data.html">
   Introduction to Neuroimaging Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Signal_Processing.html">
   Signal Processing Basics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Preprocessing.html">
   Preprocessing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="GLM.html">
   Introduction to the General Linear Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="GLM_Single_Subject_Model.html">
   Modeling Single Subject Data
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Group_Analysis.html">
   Group Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Thresholding_Group_Analyses.html">
   Thresholding Group Analyses
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Connectivity.html">
   Connectivity
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Multivariate_Prediction.html">
   Multivariate Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="RSA.html">
   Representational Similarity Analysis
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Introduction to Parcellations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Resampling_Statistics.html">
   Resampling Statistics
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Additional Courses
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="http://naturalistic-data.org/">
   Naturalistic Data Analysis
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Project Gallery
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="2019_Spring.html">
   Spring 2019
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Spring.html">
   Spring 2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2020_Fall.html">
   Fall 2020
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2021_Fall.html">
   Fall 2021
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2022_Fall.html">
   Fall 2022
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributing
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Contributing.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/ljchang/dartbrains">
   GitHub Repository
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Post questions to <a href='https://www.askpbs.org/c/dartbrains'>DartBrains Discourse</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/ljchang/dartbrains/master?urlpath=tree/content/Parcellations.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://jhub.dartmouth.edu/hub/user-redirect/git-pull?repo=https%3A//github.com/ljchang/dartbrains&urlpath=tree/dartbrains/content/Parcellations.ipynb&branch=master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/ljchang/dartbrains/blob/master/content/Parcellations.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/ljchang/dartbrains"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ljchang/dartbrains/issues/new?title=Issue%20on%20page%20%2Fcontent/Parcellations.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/ljchang/dartbrains/edit/master/content/Parcellations.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/content/Parcellations.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spatial-scales">
   Spatial Scales
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-quick-note-on-labeling">
   A quick note on labeling:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#accessing-parcellations-atlases">
   Accessing Parcellations/Atlases:
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nilearn">
     Nilearn:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neuroparc">
     Neuroparc
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parcellations-schemes">
   Parcellations Schemes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#anatomical-atlases">
     Anatomical Atlases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functional-parcellations">
     Functional parcellations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#structural-parcellations">
     Structural parcellations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary-of-differences-between-parcellations">
   Summary of differences between parcellations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-forms-of-parcellations-not-mentioned-here">
     Other forms of parcellations not mentioned here
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Introduction to Parcellations</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#spatial-scales">
   Spatial Scales
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-quick-note-on-labeling">
   A quick note on labeling:
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#accessing-parcellations-atlases">
   Accessing Parcellations/Atlases:
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#nilearn">
     Nilearn:
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#neuroparc">
     Neuroparc
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#parcellations-schemes">
   Parcellations Schemes
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#anatomical-atlases">
     Anatomical Atlases
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#functional-parcellations">
     Functional parcellations
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#structural-parcellations">
     Structural parcellations
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#summary-of-differences-between-parcellations">
   Summary of differences between parcellations
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-forms-of-parcellations-not-mentioned-here">
     Other forms of parcellations not mentioned here
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-parcellations">
<h1>Introduction to Parcellations<a class="headerlink" href="#introduction-to-parcellations" title="Permalink to this headline">#</a></h1>
<p><em>Written By: Clara Sava-Segal &amp; Thomas L. Botch (edited by Luke Chang)</em></p>
<p>What spatial scale should we use to analyze neuroimaging data? Traditional univariate approaches have focused on analyzing data at the voxel level or averaging activity within a region of interest (ROI). However, multivariate approaches tend to work with larger spatial scales (e.g., searchlights, ROIs, resting state networks, &amp; parcellations). The goal of this tutorial is to provide an introduction to parcellation schemes. We will cover the types of atlases that are available, when to use them, and how to work with them in python.</p>
<section id="spatial-scales">
<h2>Spatial Scales<a class="headerlink" href="#spatial-scales" title="Permalink to this headline">#</a></h2>
<p>There is vast diversity in the spatial scales at which different psychological and neurological processes are organized. To study these different mechanisms most effectively, the scale of our methods should be consistent with the scale of this organization (for more detail see: <a class="reference external" href="https://academic.oup.com/scan/article/16/8/795/6121195?login=true">Jolly &amp; Chang, 2021</a>).</p>
<p>Parcellations provide a way to examine the brain at different spatial scales by restricting the number of regions of interest to variable scales as determined by anatomical or functional divisions. We provide extensive detail on anatomical, functional and structural approaches to building parcellations. In general, the goal is to use group together voxels based on either one of these methodological divisions. This grouping of voxels can be either contiguous (voxels that are spatially next to one another in a particular region of the brain) or non-contiguous (voxels that are spatially disjoint, but functionally connected (e.g., resting state networks).</p>
<p>The table below is a useful discussion comparing ROI (parcellation) approaches to searchlights and whole brain approaches. (From: <a class="reference external" href="https://academic.oup.com/scan/article/16/8/795/6121195?login=true">Jolly &amp; Chang, 2021</a>). The goal of this notebook is to provide extensive detail on how the publicly available parcellations have been generated to give you more insight as to which ones would be better suited for your own research questions.</p>
<p><img alt="" src="../_images/spatial_feature_selection_table.png" /></p>
</section>
<section id="a-quick-note-on-labeling">
<h2>A quick note on labeling:<a class="headerlink" href="#a-quick-note-on-labeling" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>The terms parcellation, atlas, and template are often used interchangeably, as noted in <a class="reference external" href="https://arxiv.org/pdf/2107.03475.pdf">Moghimi <em>et al</em> 2021</a>. We use their labeling strategy below to describe the three strategies that have been used to generate parcellations:</p></li>
<li><p><strong>Parcellation</strong>: a division of the gray matter that enumerates what region each gray matter voxel is a part of</p></li>
<li><p><strong>Atlas</strong>: could be used to refer to anatomical parcellations</p></li>
<li><p><strong>Template</strong>: the use of a T1-weighted MRI image as the reference for other T1-weighted images</p></li>
</ul>
</section>
<section id="accessing-parcellations-atlases">
<h2>Accessing Parcellations/Atlases:<a class="headerlink" href="#accessing-parcellations-atlases" title="Permalink to this headline">#</a></h2>
<p>There are two main repositories of anatomical and functional atlases that can programmatically accessed via python packages (e.g., Nilearn and Neuroparc). We briefly detail these below and then will provide code-snippets and plotting suggestions for using these packages as we introduce parcellations below.</p>
<section id="nilearn">
<h3>Nilearn:<a class="headerlink" href="#nilearn" title="Permalink to this headline">#</a></h3>
<p><a class="reference external" href="https://nilearn.github.io/stable/index.html">Nilearn</a> (Abraham <em>et al</em>, 2014) is a python package that combines tools for neuroimaging and provides command line functions to fetch atlases that make using parcellations easy. Nilearn includes <strong>12</strong> anatomically and functionally defined atlases, including Harvard-Oxford, Schaefer, Yeo and Anatomated Anatomical Labeling (AAL).</p>
<p>Here is how each of the atlases can be downloaded using python.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span>

<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_harvard_oxford</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_difumo</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_msdl</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_schaefer_2018</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_aal</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_smith_2009</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_surf_destrieux</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_craddock_2012</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_talairach</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_yeo_2011</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_juelich</span>
<span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_basc_multiscale_2015</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function nilearn.datasets.atlas.fetch_atlas_basc_multiscale_2015(version=&#39;sym&#39;, data_dir=None, url=None, resume=True, verbose=1)&gt;
</pre></div>
</div>
</div>
</div>
</section>
<section id="neuroparc">
<h3>Neuroparc<a class="headerlink" href="#neuroparc" title="Permalink to this headline">#</a></h3>
<p>Alternatively, there is also the <a class="reference external" href="https://github.com/neurodata/neuroparc">Neuroparc</a> package, which provides a large repository of standardized atlases (currently <strong>46</strong>; see Table below), which can be used interchangeably. Neuroparc includes details to make <strong>the comparison between atlases</strong> in MNI space easily <a class="reference external" href="https://www.nature.com/articles/s41597-021-00849-3">(Lawrence <em>et al.</em>, 2021)</a>. Importantly, their Github page <a class="reference external" href="https://github.com/neurodata/neuroparc/blob/master/README.md#atlas-info-summary">README file</a> provides an excellent summary of how the parcellations where created, their description, and their native space.</p>
<p>The table below <a class="reference external" href="https://www.nature.com/articles/s41597-021-00849-3">(Lawrence <em>et al.</em>, 2021)</a> includes a list of the parcellations available, the number of ROIs in each depending on the resolution, and whether a anatomical labels are available. Again, if you want further information on these parcellations, we recommend checking out the aforementioned <a class="reference external" href="https://github.com/neurodata/neuroparc/blob/master/README.md#atlas-info-summary">README file</a>.</p>
<p><img alt="" src="../_images/neuroparc_atlas_table.png" /></p>
<p><img alt="" src="../_images/brainAtlases_color_wRegions.png" /></p>
</section>
</section>
<section id="parcellations-schemes">
<h2>Parcellations Schemes<a class="headerlink" href="#parcellations-schemes" title="Permalink to this headline">#</a></h2>
<section id="anatomical-atlases">
<h3>Anatomical Atlases<a class="headerlink" href="#anatomical-atlases" title="Permalink to this headline">#</a></h3>
<p>With the advent of MRI, atlases have started to rely on neural macrostructures such as sulci or gyri to distinguish regions, with the expectation that this would result in brain regions with voxels that have a shared cytoarchitecture. <strong>The labels in these atlases reflect the spatial location of an anatomical region.</strong></p>
<p>There are different approaches (Direct vs. Mirroring) to set up and generate an anatomical atlas that are well described in <a class="reference external" href="https://arxiv.org/pdf/2107.03475.pdf">Moghimi <em>et al.</em> 2021</a> if you are interested in reading more. The mirroring approach has become standard practice in most modern fMRI research programs. It entails registering an image that needs to be parcellated to an existent template image that has already been labeled. Each voxel gets the corresponding voxel’s label in the reference image.</p>
<p>Commonly used and referenced template/reference images include the <a class="reference external" href="http://www.talairach.org/about.html">Talairach template</a> (Talairach and Tournoux, 1988) and the <a class="reference external" href="https://github.com/Jfortin1/MNITemplate">MNI 152 template</a>.</p>
<p>Two single-subject attempts to automate these procedures were the AAL atlas and the Talairach atlas (described below). “Single-subject” here means that <strong>one individual’s</strong> brain was used as the reference point. Unsurprisingly, this means that the anatomical idiosyncrasies of these individuals are reflected in these template images, but these are still commonly used as you will see below.</p>
<ol class="simple">
<li><p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/11771995/">AAL-Automatic Anatomical Labeling</a> [Tzourio-Mazoyer <em>et al</em>, 2002]</p></li>
</ol>
<ul class="simple">
<li><p>This <strong>anatomical</strong> atlas provides anatomical landmarks following the sulci in the brain.</p></li>
<li><p>This is available in both Neuroparc and in Nilearn for easy access (see code below)</p></li>
<li><p>116 regions</p></li>
<li><p>Generated from 1 subject</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">plotting</span>

<span class="n">aal</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_aal</span><span class="p">(</span><span class="n">version</span><span class="o">=</span><span class="s1">&#39;SPM12&#39;</span><span class="p">)</span>
<span class="n">aal</span><span class="o">.</span><span class="n">maps</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">aal</span><span class="o">.</span><span class="n">maps</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s2">&quot;AAL&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._slicers.OrthoSlicer at 0x179bd93a0&gt;
</pre></div>
</div>
<img alt="../_images/Parcellations_5_1.png" src="../_images/Parcellations_5_1.png" />
</div>
</div>
<ol class="simple">
<li><p><a class="reference external" href="http://www.talairach.org/">Talairach Atlas</a> (Talairach and Tournoux, 1988)</p></li>
</ol>
<ul class="simple">
<li><p>This <strong>anatomical</strong> atlas includes the Hemisphere, Lobe, Gyrus, Tissue Type, and Cell Type.</p></li>
<li><p>This is available in both Neuroparc and in Nilearn for easy access (see below). As you can see in the code snippet below, to specify the level at which you want this anatomical atlas, you can feed that as input into the code.
“level_name” should be one of [‘hemisphere’, ‘lobe’, ‘gyrus’, ‘tissue’, ‘ba’]</p></li>
<li><p>110 regions</p></li>
<li><p>Generated from 1 alcoholic subject post-mortem at age 60</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">level</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;hemisphere&#39;</span><span class="p">,</span> <span class="s1">&#39;lobe&#39;</span><span class="p">,</span> <span class="s1">&#39;gyrus&#39;</span><span class="p">,</span> <span class="s1">&#39;tissue&#39;</span><span class="p">,</span> <span class="s1">&#39;ba&#39;</span><span class="p">]:</span>
  <span class="n">talairach</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_talairach</span><span class="p">(</span><span class="n">level_name</span><span class="o">=</span><span class="n">level</span><span class="p">)</span>

  <span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">talairach</span><span class="o">.</span><span class="n">maps</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Talairach - </span><span class="si">{</span><span class="n">level</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Parcellations_7_0.png" src="../_images/Parcellations_7_0.png" />
<img alt="../_images/Parcellations_7_1.png" src="../_images/Parcellations_7_1.png" />
<img alt="../_images/Parcellations_7_2.png" src="../_images/Parcellations_7_2.png" />
<img alt="../_images/Parcellations_7_3.png" src="../_images/Parcellations_7_3.png" />
<img alt="../_images/Parcellations_7_4.png" src="../_images/Parcellations_7_4.png" />
</div>
</div>
<p><strong>Multiple-subject atlases</strong> use the combination of multiple subjects’ T1 scans as the reference image for mirroring in generating anatomical atlases. Multiple-subject parcelations are thought to be more accurate than single subject parcellations and tend to be <strong>probabilistic</strong> in that they describe the probability of a voxel belonging to a specific region of the brain based on multiple subjects.</p>
<p>There are numerous ways to assign a subject’s data that you want to be parcellated to a probabilistic atlas. One method is to <strong>generate a single reference atlas</strong> in which there is one image registration between the reference image and the to-be-parcellated image. Evidently, this is prone to errors of image registration. In this method, the probability that each voxel in your data belongs to a region in the reference atlas is calculated while also taking into account the surface geometry and image intensity, as reviewed in Moghimi <em>et al.</em> 2021 and posited in Fischl <em>et al.</em> 2002/2004. Importantly, this method has been implemented into <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/">FreeSurfer</a> and the <a class="reference external" href="http://www.humanconnectomeproject.org/">Human Connectome Project</a> imaging pipeline. The alternative is a <strong>multiple-reference atlases</strong> approach in which each atlas is assigned to the new brain image separately such that the voxel is assigned to its corresponding image based on its assignment across multiple reference atlases.</p>
<p>To further emphasize, a major obstacle when it comes to anatomical atlases is the degree of idiosyncracy in neuroanatomy as well as the subjective nature of human manual atlases. Importantly, automated algorithms have been generated to bypass the latter and guidelines have been put forth to aid in keeping manual atlases consistent. Likewise, reference atlases exist based on <em>age</em> to deal with changes in neural morphology. We do not include those here.</p>
<p>Numerous multi-subject atlases have been generated and made publicly available. We describe three of the most commonly used ones below:</p>
<ol class="simple">
<li><p><a class="reference external" href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Atlases">Harvard-Oxford </a></p></li>
</ol>
<ul class="simple">
<li><p>These are a series of <strong>probabilistic</strong> atlases that cover 48 cortical and 21 subcortical structures using T1-weighted images from 21 male and 16 females that were all healthy. Importantly, these have all been registered into <strong>MNI-152</strong> space making their usage quite simple.</p></li>
<li><p>These are available in both Nilearn and Neuroparc (see code below).</p></li>
<li><p>The nilearn function <a class="reference external" href="https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_atlas_harvard_oxford.html"><code class="docutils literal notranslate"><span class="pre">fetch_atlas-&lt;name&gt;</span></code></a> requires that you load in the ‘name of the atlas’ that you wish to load as ‘atlas-name’.</p></li>
<li><p>There are numerous Harvard-Oxford atlases available that can be called through this function. For ease of viewing and deciding which one you are interested in, we recommend looking here: https://neurovault.org/collections/262/. We provide code to load in two sample atlases below - one cortical and one subcortical:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">atlas_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;cort-maxprob-thr0-2mm&#39;</span><span class="p">,</span> <span class="s1">&#39;sub-maxprob-thr0-1mm&#39;</span><span class="p">]:</span>

  <span class="n">harvard_oxford</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_harvard_oxford</span><span class="p">(</span><span class="n">atlas_name</span> <span class="p">)</span>

  <span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">harvard_oxford</span><span class="o">.</span><span class="n">maps</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Harvard-Oxford-</span><span class="si">{</span><span class="n">atlas_name</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/Parcellations_9_0.png" src="../_images/Parcellations_9_0.png" />
<img alt="../_images/Parcellations_9_1.png" src="../_images/Parcellations_9_1.png" />
</div>
</div>
<ol class="simple">
<li><p>Desikan-Killiany (Desikan, 2006)</p></li>
</ol>
<ul class="simple">
<li><p>This is a multi-subject, single reference atlas that is part of the <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation">Freesurfer software package</a>.</p></li>
<li><p>It was generated using 30 healthy subjects and 10 subjects with Alzheimer’s (ranging from 19-87 years old) making it apt for use with people of different ages and different degrees of neural atrophy. Due to this, it has also been used beyond fMRI research to localize and visualize electrodes implanted into patients with medically-refractory epilepsy for intracranial recordings (iELVis package <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0165027017300365">link text</a>).</p></li>
<li><p>Defined by gyri</p></li>
<li><p>Regions: 68, only cortical</p></li>
<li><p>Unfortunately, this atlas is not currently available in nilearn, but is a part of Neuroparc in MNI 152 space which we load in below. Notably, there are different options in Neuroparc based on the resolution you are interested in. We load in 1x1x1.</p></li>
<li><p>Notably, there is also the updated Desikan-Killiany-Tourville (DKT) atlas where regions that were not clearly defined were merged into other regions (total: 62, still only cortical)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltools</span> <span class="kn">import</span> <span class="n">Brain_Data</span>

<span class="n">desikan_killiany</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="s1">&#39;https://github.com/neurodata/neuroparc/raw/master/atlases/label/Human/Desikan_space-MNI152NLin6_res-1x1x1.nii.gz&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_nifti</span><span class="p">()</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">desikan_killiany</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Desikan-Killiany&#39;</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Paired&#39;</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._slicers.OrthoSlicer at 0x2a0914730&gt;
</pre></div>
</div>
<img alt="../_images/Parcellations_11_1.png" src="../_images/Parcellations_11_1.png" />
</div>
</div>
<ol class="simple">
<li><p>Destrieux Atlas <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811910008542">(Destrieux <em>et al.</em> 2010)</a></p></li>
</ol>
<ul class="simple">
<li><p>Defined by gyri and sulci</p></li>
<li><p>One of the first anatomical atlases to divide the cortex into either sulci or gyri as opposed to just labeling regions based on the gyri with boundaries running between the bottoms of the two neighboring sulci.</p></li>
<li><p>This atlas is also found in the <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation">Freesurfer software package</a> and is readily available in nilearn (see below) in fsaverage5 space</p></li>
<li><p>Regions: 74 per hemisphere, only cortical</p></li>
<li><p>24 healthy subjects</p></li>
<li><p>This atlas is found in both <a class="reference external" href="https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_atlas_surf_destrieux.html">nilearn</a> and Neuroparc</p>
<ul>
<li><p>Unlike the examples above, this nilearn function returns a dictionary with the labels for each region and a numpy array for the left and right hemisphere labels (‘map_left’, ‘map_right’), and a description of the dataset</p></li>
<li><p>Since, this nilearn function does not return a .nii file like the other examples above did, we need to take the surface space (fsaverage) and overlay it with the labels. The code snippet below details how to do this and more information can be found <a class="reference external" href="https://nilearn.github.io/dev/auto_examples/01_plotting/plot_surf_atlas.html">here</a>.</p></li>
</ul>
</li>
</ul>
<p>Atlas image from Freesurfer. You can note the differences from the DK atlas above visually:</p>
<p><img alt="" src="../_images/freesurfer_atlas.png" /></p>
<p><img alt="" src="../_images/destrieux.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">destrieux</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_surf_destrieux</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39; See outputs of the dataset &#39;&#39;&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">destrieux</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="n">atlas</span> <span class="o">=</span> <span class="n">destrieux</span><span class="p">[</span><span class="s1">&#39;map_left&#39;</span><span class="p">]</span>
<span class="n">fsaverage</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_surf_fsaverage</span><span class="p">()</span>
<span class="n">plot</span> <span class="o">=</span> <span class="n">plotting</span><span class="o">.</span><span class="n">plot_surf_roi</span><span class="p">(</span><span class="n">fsaverage</span><span class="p">[</span><span class="s1">&#39;infl_left&#39;</span><span class="p">],</span> <span class="n">roi_map</span><span class="o">=</span><span class="n">atlas</span><span class="p">,</span>
                       <span class="n">hemi</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">,</span> <span class="n">view</span><span class="o">=</span><span class="s1">&#39;lateral&#39;</span><span class="p">,</span>
                       <span class="n">bg_map</span><span class="o">=</span><span class="n">fsaverage</span><span class="p">[</span><span class="s1">&#39;sulc_left&#39;</span><span class="p">],</span> <span class="n">bg_on_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                       <span class="n">darkness</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="n">ba</span>  <span class="p">)</span>
<span class="sd">&#39;&#39;&#39; Note: we chose &#39;infl_left&#39; here to match the image above, but the same image could be plotted on pial surface or at different angles using this plot_surf_roi function&#39;&#39;&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;labels&#39;, &#39;map_left&#39;, &#39;map_right&#39;, &#39;description&#39;])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot; Note: we chose &#39;infl_left&#39; here to match the image above, but the same image could be plotted on pial surface or at different angles using this plot_surf_roi function&quot;
</pre></div>
</div>
<img alt="../_images/Parcellations_13_2.png" src="../_images/Parcellations_13_2.png" />
</div>
</div>
</section>
<section id="functional-parcellations">
<h3>Functional parcellations<a class="headerlink" href="#functional-parcellations" title="Permalink to this headline">#</a></h3>
<p>The goal of functional parcellations is to group voxels based on similar function, using either functional activity or functional connectivity as similarity measures. Again, a nice review can be found in <a class="reference external" href="https://arxiv.org/pdf/2107.03475.pdf">Moghimi <em>et al.</em> 2021</a>. The assumption is that functionally distinct brain regions have voxels with shared functional activity and connectivity. For a great discussion of how cortical regions have a ‘connectional fingerprint’ reflecting both observed cell-firing differences and functional imaging activity, see: <a class="reference external" href="https://www.nature.com/articles/nrn893">Passingham, Stephan &amp; Kötter (2002)</a>. A combination of resting state fMRI and task-based fMRI have been used to generate these parcellations. Before discussing the implementation and generation of functional parcellations, we wish to acknowledge a couple of ongoing fields of research:</p>
<p>Although there is more to determine, it may be that functional activity (as compared to connectivity) would result in parcellations that have higher inter-subject consistency considering that it has been shown that subjects have idiosyncratic connectivity patterns (<a class="reference external" href="https://www.nature.com/articles/nn.4135">Finn <em>et al.</em> 2015</a>). Craddock <em>et al.</em> (2012) conducted a detailed analysis using anatomical atlases (included the Talairach, Harvard-Oxford, and AAL detailed above) to evaluate how well they can reproduce functional connectivity patterns. They identified that the use of many regions in an anatomical atlas (600 or more) more accurately reflects functional connectivity patterns, while using atlases with fewer regions is substandard and less suited if the goal is to understand functional connectivity. For reference, see <a class="reference external" href="https://onlinelibrary.wiley.com/doi/10.1002/hbm.21333">here</a>.</p>
<p>Likewise, recent work has explored whether functional parcellations derived from resting-state versus from task-evoked fMRI might differ. Specifically, it has been shown (unsurprisingly) that the functional organization of the brain depends on the task such that a parcellation generated from one task will differ from a parcellation generated from another task (<a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/31740342/">Salehi <em>et al.</em> 2019</a>).</p>
<p>Signal-to-noise ratio (SNR) varies across the brain, suggesting that the reliability of parcellation results will vary across the brain, as well (Yeo <em>et al.</em> 2011; reviewed in Moghimi <em>et al.</em> 2021). In light of SNR variability, Yeo <em>et al.</em> 2011 proposes that similarity in functional connectivity profiles is superior to functional activity on its own.</p>
<p>Individual versus group-level parcellations. Individual-level parcellations apply parcellations to an individual’s dataset (typically multi-sessions scans) <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/28728026/">Ex: Braga &amp; Buckner, 2017</a>. Group-level parcellations combine datasets across people. Group-level parcellations capture the common “average brain” and absolve the <a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/19787067/">concordance problem</a>. At the same time individual-level parcellations capture idiosyncrasies unique to individual brains and have higher SNR, making it possible to capture inter-individual variability in networks/locations on a smaller, more localized scale (Braga &amp; Buckner, 2017), to predict certain features about the individual (ex: sex - <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811917307139">Salehi *et al.*2018</a>) and to link individual differences in neural activity to behavior (Finn <em>et al.,</em> 2015). Notably, <strong>the choice between using a individual-level parcellation or a group-level parcellation depends on the data available and the level of analysis one is interested in.</strong> The construction of a group-level parcellation requires registering the scan of each individual subject into a common space template to look at the one-to-one correspondence between voxels across subjects.</p>
<p>There are two algorithms (among others) used to generate functional parcelltions: (1) cluster-based, (2) graph-based.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>- Cluster-based algorithms divide voxels into groups that have higher within-group similarity as compared to across-group similarity. Common clustering algorithms include K-means or hierarchical clustering. 
- Graph-based algorithms treat voxels as &quot;nodes&quot; (vertices) and treat the similarity between voxels as &quot;edges&quot; (links). Once these graphs are generated, edges are binarized such that if the strength (similarity) is above a certain pre-determined threshold then it is given a 1, and otherwise a 0. 
</pre></div>
</div>
<p>Below, we introduce a series of widely used functional parcellations and note which features were used to generate them.</p>
<ol class="simple">
<li><p><a class="reference external" href="https://https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3174820/">Yeo parcellation</a></p></li>
</ol>
<ul class="simple">
<li><p>This parcellation divides the cortex based on resting state networks (either 7 or 17) using data from 1000, healthy subjects.</p></li>
<li><p>It employs a clustering approach</p></li>
<li><p>Notably, it shows not only localized networks (ex: motor), but also distributed networks that operate across the cortex (ex: Default Mode).</p></li>
<li><p>This network is also available in the <a class="reference external" href="https://surfer.nmr.mgh.harvard.edu/fswiki/CorticalParcellation_Yeo2011">Freesurfer package</a></p></li>
<li><p>This is available in MNI152 space through Nilearn and in Freesurfer space through Neuroparc. We include the <a class="reference external" href="https://nilearn.github.io/modules/generated/nilearn.datasets.fetch_atlas_yeo_2011.html">Nilearn function</a> below and show how both the 17 and 7 Network labels can be included.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">yeo</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_yeo_2011</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39; See outputs of the dataset &#39;&#39;&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">yeo</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;thick_7&#39;</span><span class="p">,</span><span class="s1">&#39;thick_17&#39;</span><span class="p">]:</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;thick_&quot;</span><span class="p">,</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
  <span class="n">atlas</span> <span class="o">=</span> <span class="n">yeo</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="c1">#this loads in a .nii file</span>
  <span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">atlas</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Yeo - </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1"> Network&#39;</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Paired&#39;</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;Note: if you want to keep the canonical Yeo colors for your plotting, there is a &#39;colors_7&#39; txt file available in the nilearn function&#39;&#39;&#39;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;description&#39;, &#39;thin_7&#39;, &#39;thick_7&#39;, &#39;thin_17&#39;, &#39;thick_17&#39;, &#39;colors_7&#39;, &#39;colors_17&#39;, &#39;anat&#39;])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&quot;Note: if you want to keep the canonical Yeo colors for your plotting, there is a &#39;colors_7&#39; txt file available in the nilearn function&quot;
</pre></div>
</div>
<img alt="../_images/Parcellations_16_2.png" src="../_images/Parcellations_16_2.png" />
<img alt="../_images/Parcellations_16_3.png" src="../_images/Parcellations_16_3.png" />
</div>
</div>
<p>The image above plots the network colors so that networks in different hemisphere have the same colors. If you want to split up the networks into 49 ROIs, nilearn includes a useful <code class="docutils literal notranslate"><span class="pre">connected_labels_regions</span></code> function. Further information using the Yeo network in nilearn is detailed <a class="reference external" href="https://nilearn.github.io/auto_examples/06_manipulating_images/plot_extract_regions_labels_image.html">here</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.regions</span> <span class="kn">import</span> <span class="n">connected_label_regions</span>

<span class="n">region_labels</span> <span class="o">=</span> <span class="n">connected_label_regions</span><span class="p">(</span><span class="n">atlas</span><span class="p">)</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">region_labels</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Yeo&#39;</span><span class="p">,</span>
                  <span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Paired&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/Users/lukechang/opt/anaconda3/lib/python3.9/site-packages/nilearn/image/image.py:756: FutureWarning: Image data has type int64, which may cause incompatibilities with other tools. This will error in NiBabel 5.0. This warning can be silenced by passing the dtype argument to Nifti1Image().
  return klass(data, affine, header=header)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._slicers.OrthoSlicer at 0x28eaa0df0&gt;
</pre></div>
</div>
<img alt="../_images/Parcellations_18_2.png" src="../_images/Parcellations_18_2.png" />
</div>
</div>
<ol class="simple">
<li><p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/28981612/">Schaefer parcellation</a></p></li>
</ol>
<ul class="simple">
<li><p>This parcellation aims to combine (1) local gradient and (2) global similarity approaches by using both <strong>task-based fMRI and resting-state fMRI</strong>. They develop a gradient-weighted Markov Random Field (gwMRF) model.</p></li>
<li><p>Local gradient approaches look at brusque changes in the functional connectivity patterns, while global similarity approaches cluster based on similar functional connectivity more broadly (such as Yeo).</p></li>
<li><p>Importantly, the <a class="reference external" href="https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal">Github page</a> for this parcellation is consistently updated and provides the parcellation in Freesurfer space, HCP space, and MNI space.</p></li>
<li><p>The parcellation also comes with labels from the Yeo 7 resting state network or 17 Network parcellation and can be split into 100, 200, 300, 400, 500, 600, 700, 800, 900, and 1000 parcels depending on user preference. A detailed anatomical description of the functional and structural features of these nodes is included in the publication.</p></li>
<li><p>It is available both through Nilearn and Neuroparc and we provide example code for how to use the <a class="reference external" href="https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/brain_parcellation/Schaefer2018_LocalGlobal">Nilearn function</a> below. In Nilearn, the reference space is MNI152.</p></li>
<li><p>In this case, the number of ROIs (parcels), the network number (7 or 17) and the resolution (1 or 2 mm) needs to be specified.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">schaefer</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_schaefer_2018</span><span class="p">()</span>

<span class="sd">&#39;&#39;&#39; See outputs of the dataset &#39;&#39;&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">schaefer</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

<span class="sd">&#39;&#39;&#39; Change here if you want a different number of rois, networks, or resolution&#39;&#39;&#39;</span>
<span class="n">n_rois</span><span class="o">=</span><span class="mi">200</span>
<span class="n">yeo_networks</span><span class="o">=</span><span class="mi">7</span>
<span class="n">resolution_mm</span><span class="o">=</span><span class="mi">1</span>

<span class="n">dataset_s</span><span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_schaefer_2018</span><span class="p">(</span><span class="n">n_rois</span><span class="p">,</span><span class="n">yeo_networks</span><span class="p">,</span><span class="n">resolution_mm</span><span class="p">)</span>
<span class="n">atlas</span> <span class="o">=</span> <span class="n">schaefer</span><span class="p">[</span><span class="s1">&#39;maps&#39;</span><span class="p">]</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">atlas</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Schaefer - </span><span class="si">{</span><span class="n">n_rois</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span>
                  <span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Paired&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dict_keys([&#39;maps&#39;, &#39;labels&#39;, &#39;description&#39;])
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._slicers.OrthoSlicer at 0x2a2b9a5e0&gt;
</pre></div>
</div>
<img alt="../_images/Parcellations_20_2.png" src="../_images/Parcellations_20_2.png" />
</div>
</div>
<ol class="simple">
<li><p><a class="reference external" href="https://pubmed.ncbi.nlm.nih.gov/23747961/">Shen Parcellation</a></p></li>
</ol>
<ul class="simple">
<li><p>The Shen parcellation is a groupwise <strong>graph-theory-based</strong> parcellation. It is also based on <strong>resting state</strong> functional connectivity</p></li>
<li><p>The parcellation comes with 268 nodes (including subcortical nodes)</p></li>
<li><p>Unfortunately, it is not found in nilearn or in Neuroparc, but we can find the parcellation on <a class="reference external" href="https://neurovault.org/images/395091/">Neurovault</a>. We use this link in the code snippet below.</p></li>
<li><p>We highly recommend that users of the Shen parcellation use this <a class="reference external" href="https://bioimagesuiteweb.github.io/bisweb-manual/tools/conncontrol.html">BioImage Suite tool</a> that provides information about how to label each ROI and its network identity.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">shen</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="s1">&#39;https://neurovault.org/media/images/8423/shen_2mm_268_parcellation.nii.gz&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_nifti</span><span class="p">()</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">shen</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Shen&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Paired&#39;</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._slicers.OrthoSlicer at 0x2a087f1c0&gt;
</pre></div>
</div>
<img alt="../_images/Parcellations_22_1.png" src="../_images/Parcellations_22_1.png" />
</div>
</div>
<p>Something of note is that while we usually think of voxels as belonging to one single region (<strong>hard assignment</strong>), but it also possible that a voxel can belong to multiple regions (<strong>soft assignment</strong>). Consider parcellations based on network - (association cortex) regions may be “part of” different networks depending on task. Below, we introduce the idea of multimodal parcellations.</p>
</section>
<section id="structural-parcellations">
<h3>Structural parcellations<a class="headerlink" href="#structural-parcellations" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Structural parcellations reflect the <strong>structural connectivity profile</strong> and rely on diffusion-weighted MR. The connectivity profile of a voxels reflects the probability of that voxel being connected to other voxels via a white matter fiber. They estimate where white matter tracks start and end and their pathways. The premise is that connections reflect functional organization, so cortical regions that are functionally distinct from one another should have different connectivity patterns. However, given that structural parcellations rely on accurate white matter fiber estimation, the limiting factor is the fidelity of the tractography process. There are two main topographic approaches for mapping fibers: (1) deterministic and (2) probabilistic, but the majority use <strong>probabilistic tractography</strong>. Similar methods of clustering (as described under Functional Parcellations) are used to assign boundaries based on connectivity. Importantly, tractography algorithms are biased towards tracts ended on the gyral surface such that parcellations are biased to align with the sulci.</p></li>
<li><p>For an excellent discussion of how tractography connections compare to retrograde tracer injections in the macaque neocortex, we recommend this excellent publication by <a class="reference external" href="https://www.jneurosci.org/content/36/25/6758">Donahue and colleagues (2016)</a>. They show that tractography confirms the white matter pathways identified with the invasive tracing with high sensitivity, but also discuss limitations in specificity.</p></li>
<li><p>Below, we present the widely-available and used Glasser parcellation which is multimodal.</p></li>
</ul>
<ol class="simple">
<li><p><a class="reference external" href="https://www.nature.com/articles/nature18933">Glasser parcellation</a></p></li>
</ol>
<ul class="simple">
<li><p>This parcellation splits up the cortical surface in 360 nodes (180 per hemisphere).</p>
<ul>
<li><p>A key feature of this parcellation is that they identified new brain areas (97) and 83 known-areas.</p></li>
</ul>
</li>
<li><p>Data from 210 subjects</p></li>
<li><p>The Glasser parcellation is <strong>multimodal</strong> because as compared to using only (1) anatomy, (2) function, (3)connectivity and (4) topography, it combines complementary information from across these methods, increasing the confidence in the labeling of regions as distinct. The authors combined all four properties using Human Connectome Project MRI data, taking into consideration myelin content and cortical thickness for anatomy, task MRI across 7 tasks for function, and resting state MRI for functional connectivity. The combination of these approaches also led to the use of cortical folding, myelin and resting state fMRI to generate a parcellation with high intersubject cortical alignment.</p></li>
<li><p>Unsurprisingly, there can be discrepancies between imaging modalities (i.e. the same voxel can be assigned to different regions depending on whether structural or functional connectivity are used). Glasser <em>et al.</em> required that at least two converging modalities were used to assign voxels to regions.</p></li>
<li><p>We recommend this <a class="reference external" href="https://github.com/brainspaces/glasser360">Github page</a> to access the parcellation</p></li>
<li><p>Unfortunately, the parcellation is not found in Nilearn, but is in Neuroparc. We load in the parcellation below from Neuroparc.</p></li>
<li><p>It is notable that the parcellation can be found through the <a class="reference external" href="https://rmldj.github.io/hcp-utils/">Human Connectome Project (HCP) package</a>. The <code class="docutils literal notranslate"><span class="pre">hcp.mmp</span></code> refers to the Glasser (multi-modal parcellation).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">atlas_glasser</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="s1">&#39;https://github.com/neurodata/neuroparc/raw/master/atlases/label/Human/Glasser_space-MNI152NLin6_res-4x4x4.nii.gz&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_nifti</span><span class="p">()</span>

<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">atlas_glasser</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Glasser&#39;</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Paired&#39;</span><span class="p">,</span> <span class="n">colorbar</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._slicers.OrthoSlicer at 0x28eedb460&gt;
</pre></div>
</div>
<img alt="../_images/Parcellations_25_1.png" src="../_images/Parcellations_25_1.png" />
</div>
</div>
<ul class="simple">
<li><p>Rosen &amp; Halgren: https://pubmed.ncbi.nlm.nih.gov/33483325/</p></li>
</ul>
</section>
</section>
<section id="summary-of-differences-between-parcellations">
<h2>Summary of differences between parcellations<a class="headerlink" href="#summary-of-differences-between-parcellations" title="Permalink to this headline">#</a></h2>
<p>Here, we summarize the information above and note a few additional tools which may be of interest. The choice of parcellation deeply relates to the scale of the researcher’s question of interest (e.g., region vs. network).</p>
<ul class="simple">
<li><p>Anatomical parcellations:</p>
<ul>
<li><p>Defined based on anatomical landmark (sulci/gyri)</p></li>
<li><p>Intended to relate to macroscale cytoarchitectural properties</p></li>
<li><p>Reflects the spatial location of a region</p></li>
<li><p>Disregards idioisyncracies in brain anatomy and functional-anatomical differences across subjects</p></li>
</ul>
</li>
<li><p>Functional parcellations:</p>
<ul>
<li><p>Defined with functional activity/connectivity measures</p></li>
<li><p>Uses resting-state and/or task-based fMRI</p></li>
<li><p>Groups regions based on similarity of function based on clustering or graph metrics</p></li>
<li><p>Can be well-defined at the individual-subject and group level</p></li>
<li><p>Varying degrees of granularity (anywhere from 100 to 1000 regions)</p></li>
</ul>
</li>
<li><p>Multimodal parcellations:</p>
<ul>
<li><p>Combines anatomical, functional, and topographic methods to define parcels</p></li>
<li><p>Defined at the group-level</p></li>
</ul>
</li>
</ul>
<section id="other-forms-of-parcellations-not-mentioned-here">
<h3>Other forms of parcellations not mentioned here<a class="headerlink" href="#other-forms-of-parcellations-not-mentioned-here" title="Permalink to this headline">#</a></h3>
<p>Other parcellations exist as well:</p>
<ul class="simple">
<li><p>Transcriptomics - divide the cortex based on gene-expression</p></li>
<li><p>Local cytoarchitectures (e.g., agranular, granular, etc)</p></li>
<li><p>Structural properties (e.g., pial thickness)</p></li>
</ul>
<p>For these atlases, we recommend <a class="reference external" href="https://enigma-toolbox.readthedocs.io/en/latest/index.html">the ENIGMA Toolbox</a> - an opensource meta-analysis package including genetic, disease, and structural metrics. For more information, check out (<a class="reference external" href="https://www.nature.com/articles/s41592-021-01186-4">Lariviere et al., 2022</a>).</p>
<p>Also, there are parcellations derived from meta-analyses of task data such as Neurosynth. A few of these atlases are available on <a class="reference external" href="https://neurovault.org/collections/2099/">Neurovault</a></p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="RSA.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Representational Similarity Analysis</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Resampling_Statistics.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Resampling Statistics</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Luke Chang<br/>
  
      &copy; Copyright 2021.<br/>
    <div class="extra_footer">
      Supported by an NSF CAREER Award 1848370, <a href='https://rc.dartmouth.edu/'>Dartmouth Research Computing</a>, and the <a href='https://dcal.dartmouth.edu/about/impact/experiential-learning'>Dartmouth Center for the Advancement of Learning</a>.
    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>