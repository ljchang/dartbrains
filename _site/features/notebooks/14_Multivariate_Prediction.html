<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width,minimum-scale=1">

  <title>Multivariate Prediction</title>
  <meta name="description" content="        Multivariate Prediction    Multivariate Prediction Written by Luke ChangThe statistical methods we have discussed in this course so far have primaril...">

  <link rel="canonical" href="http://dartbrains.org//features/notebooks/14_Multivariate_Prediction.html">
  <link rel="alternate" type="application/rss+xml" title="DartBrains" href="http://dartbrains.org//feed.xml">

  <meta property="og:url"         content="http://dartbrains.org//features/notebooks/14_Multivariate_Prediction.html" />
<meta property="og:type"        content="article" />
<meta property="og:title"       content="Multivariate Prediction" />
<meta property="og:description" content="        Multivariate Prediction    Multivariate Prediction Written by Luke ChangThe statistical methods we have discussed in this course so far have primaril..." />
<meta property="og:image"       content="http://dartbrains.org/images/logo/dartbrains_logo_square_transparent.png" />

<meta name="twitter:card" content="summary">


  <script type="application/ld+json">
  {
  "@context": "http://schema.org",
  "@type": "NewsArticle",
  "mainEntityOfPage": "http://dartbrains.org//features/notebooks/14_Multivariate_Prediction.html",
  "headline": "Multivariate Prediction",
  "datePublished": "2019-12-27T11:24:15-08:00",
  "dateModified": "2019-12-27T11:24:15-08:00",
  "description": "        Multivariate Prediction    Multivariate Prediction Written by Luke ChangThe statistical methods we have discussed in this course so far have primaril...",
  "author": {
    "@type": "Person",
    "name": "Luke Chang"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Data 100 at UC Berkeley",
    "logo": {
      "@type": "ImageObject",
      "url": "http://dartbrains.org/",
      "width": 60,
      "height": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "http://dartbrains.org/",
    "height": 60,
    "width": 60
  }
}

  </script>
  <link rel="stylesheet" href="/assets/css/styles.css">

  <!-- <link rel="manifest" href="/manifest.json"> -->
  <!-- <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#efae0a"> -->
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="msapplication-TileImage" content="/mstile-144x144.png">
  <meta name="theme-color" content="#233947">

  <!-- Favicon -->
  <link rel="shortcut icon" type="image/x-icon" href="/images/logo/favicon.ico">

  <!-- MathJax Config -->
  <!-- Allow inline math using $ and automatically break long math lines -->
<!-- (mostly) copied from nbconvert configuration -->
<!-- https://github.com/jupyter/nbconvert/blob/master/nbconvert/templates/html/mathjax.tpl -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true
    },
    // Center justify equations in code and markdown cells. Elsewhere
    // we use CSS to left justify single line equations in code cells.
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        linebreaks: { automatic: true },
    },
    
});
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML' async></script>


  <!-- DOM updating function -->
  <script src="/assets/js/page/dom-update.js"></script>

  <!-- Selectors for elements on the page -->
  <script src="/assets/js/page/documentSelectors.js"></script>

  <!-- Define some javascript variables that will be useful in other javascript -->
  <script>
    const site_basename = '/';
  </script>

  <!-- Add AnchorJS to let headers be linked -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.2.0/anchor.min.js" async></script>
  <script src="/assets/js/page/anchors.js" async></script>

  <!-- Include Turbolinks to make page loads fast -->
  <!-- https://github.com/turbolinks/turbolinks -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/turbolinks/5.2.0/turbolinks.js" async></script>
  <meta name="turbolinks-cache-control" content="no-cache">

  <!-- Load nbinteract for widgets -->
  

  <!-- Load Thebelab for interactive widgets -->
  <!-- Include Thebelab for interactive code if it's enabled -->



  <!-- Load the auto-generating TOC (non-async otherwise the TOC won't load w/ turbolinks) -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.8.1/tocbot.min.js" async></script>
  <script src="/assets/js/page/tocbot.js"></script>

  <!-- Google analytics -->
  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-138270939-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-138270939-1');
</script>



  <!-- Clipboard copy button -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script>

  <!-- Load custom website scripts -->
  <script src="/assets/js/scripts.js" async></script>

  <!-- Load custom user CSS and JS  -->
  <script src="/assets/custom/custom.js" async></script>
  <link rel="stylesheet" href="/assets/custom/custom.css">

  <!-- Update interact links w/ REST param, is defined in includes so we can use templates -->
  
<script>
/**
  * To auto-embed hub URLs in interact links if given in a RESTful fashion
 */

function getJsonFromUrl(url) {
  var query = url.split('?');
  if (query.length < 2) {
    // No queries so just return false
    return false;
  }
  query = query[1];
  // Collect REST params into a dictionary
  var result = {};
  query.split("&").forEach(function(part) {
    var item = part.split("=");
    result[item[0]] = decodeURIComponent(item[1]);
  });
  return result;
}
    
function dict2param(dict) {
    params = Object.keys(dict).map(function(k) {
        return encodeURIComponent(k) + '=' + encodeURIComponent(dict[k])
    });
    return params.join('&')
}

// Parse a Binder URL, converting it to the string needed for JupyterHub
function binder2Jupyterhub(url) {
  newUrl = {};
  parts = url.split('v2/gh/')[1];
  // Grab the base repo information
  repoinfo = parts.split('?')[0];
  var [org, repo, ref] = repoinfo.split('/');
  newUrl['repo'] = ['https://github.com', org, repo].join('/');
  newUrl['branch'] = ref
  // Grab extra parameters passed
  params = getJsonFromUrl(url);
  if (params['filepath'] !== undefined) {
    newUrl['subPath'] = params['filepath']
  }
  return dict2param(newUrl);
}

// Filter out potentially unsafe characters to prevent xss
function safeUrl(url)
{
   return String(encodeURIComponent(url))
            .replace(/&/g, '&amp;')
            .replace(/"/g, '&quot;')
            .replace(/'/g, '&#39;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
}

function addParamToInternalLinks(hub) {
  var links = document.querySelectorAll("a").forEach(function(link) {
    var href = link.href;
    // If the link is an internal link...
    if (href.search("http://dartbrains.org") !== -1 || href.startsWith('/') || href.search("127.0.0.1:") !== -1) {
      // Assume we're an internal link, add the hub param to it
      var params = getJsonFromUrl(href);
      if (params !== false) {
        // We have REST params, so append a new one
        params['jupyterhub'] = hub;
      } else {
        // Create the REST params
        params = {'jupyterhub': hub};
      }
      // Update the link
      var newHref = href.split('?')[0] + '?' + dict2param(params);
      link.setAttribute('href', decodeURIComponent(newHref));
    }
  });
  return false;
}


// Update interact links
function updateInteractLink() {
    // hack to make this work since it expects a ? in the URL
    rest = getJsonFromUrl("?" + location.search.substr(1));
    jupyterHubUrl = rest['jupyterhub'];
    var hubType = null;
    var hubUrl = null;
    if (jupyterHubUrl !== undefined) {
      hubType = 'jupyterhub';
      hubUrl = jupyterHubUrl;
    }

    if (hubType !== null) {
      // Sanitize the hubUrl
      hubUrl = safeUrl(hubUrl);

      // Add HTTP text if omitted
      if (hubUrl.indexOf('http') < 0) {hubUrl = 'http://' + hubUrl;}
      var interactButtons = document.querySelectorAll("button.interact-button")
      var lastButton = interactButtons[interactButtons.length-1];
      var link = lastButton.parentElement;

      // If we've already run this, skip the link updating
      if (link.nextElementSibling !== null) {
        return;
      }

      // Update the link and add context div
      var href = link.getAttribute('href');
      if (lastButton.id === 'interact-button-binder') {
        // If binder links exist, we need to re-work them for jupyterhub
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // If localhost, assume we're working from a local Jupyter server and remove `/hub`
          first = [hubUrl, 'git-sync'].join('/')
        } else {
          first = [hubUrl, 'hub', 'user-redirect', 'git-sync'].join('/')
        }
        href = first + '?' + binder2Jupyterhub(href);
      } else {
        // If interact button isn't binderhub, assume it's jupyterhub
        // If JupyterHub links, we only need to replace the hub url
        href = href.replace("https://jupyterhub.dartmouth.edu", hubUrl);
        if (hubUrl.indexOf('http%3A%2F%2Flocalhost') > -1) {
          // Assume we're working from a local Jupyter server and remove `/hub`
          href = href.replace("/hub/user-redirect", "");
        }
      }
      link.setAttribute('href', decodeURIComponent(href));

      // Add text after interact link saying where we're launching
      hubUrlNoHttp = decodeURIComponent(hubUrl).replace('http://', '').replace('https://', '');
      link.insertAdjacentHTML('afterend', '<div class="interact-context">on ' + hubUrlNoHttp + '</div>');

      // Update internal links so we retain the hub url
      addParamToInternalLinks(hubUrl);
    }
}

runWhenDOMLoaded(updateInteractLink)
document.addEventListener('turbolinks:load', updateInteractLink)
</script>


  <!-- Lunr search code - will only be executed on the /search page -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js" async></script>
  <script>var initQuery = function() {
  // See if we have a search box
  var searchInput = document.querySelector('input#lunr_search');
  if (searchInput === null) {
    return;
  }

  // Function to parse our lunr cache
  var idx = lunr(function () {
    this.field('title')
    this.field('excerpt')
    this.field('categories')
    this.field('tags')
    this.ref('id')

    this.pipeline.remove(lunr.trimmer)

    for (var item in store) {
      this.add({
        title: store[item].title,
        excerpt: store[item].excerpt,
        categories: store[item].categories,
        tags: store[item].tags,
        id: item
      })
    }
  });

  // Run search upon keyup
  searchInput.addEventListener('keyup', function () {
    var resultdiv = document.querySelector('#results');
    var query = document.querySelector("input#lunr_search").value.toLowerCase();
    var result =
      idx.query(function (q) {
        query.split(lunr.tokenizer.separator).forEach(function (term) {
          q.term(term, { boost: 100 })
          if(query.lastIndexOf(" ") != query.length-1){
            q.term(term, {  usePipeline: false, wildcard: lunr.Query.wildcard.TRAILING, boost: 10 })
          }
          if (term != ""){
            q.term(term, {  usePipeline: false, editDistance: 1, boost: 1 })
          }
        })
      });

      // Empty the results div
      while (resultdiv.firstChild) {
        resultdiv.removeChild(resultdiv.firstChild);
      }

    resultdiv.insertAdjacentHTML('afterbegin', '<p class="results__found">'+result.length+' Result(s) found</p>');
    for (var item in result) {
      var ref = result[item].ref;
      if(store[ref].teaser){
        var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<div class="archive__item-teaser">'+
                '<img src="'+store[ref].teaser+'" alt="">'+
              '</div>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      else{
    	  var searchitem =
          '<div class="list__item">'+
            '<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">'+
              '<h2 class="archive__item-title" itemprop="headline">'+
                '<a href="'+store[ref].url+'" rel="permalink">'+store[ref].title+'</a>'+
              '</h2>'+
              '<p class="archive__item-excerpt" itemprop="description">'+store[ref].excerpt.split(" ").splice(0,20).join(" ")+'...</p>'+
            '</article>'+
          '</div>';
      }
      resultdiv.insertAdjacentHTML('beforeend', searchitem);
    }
  });
};

initFunction(initQuery);
</script>

  <!-- Load JS that depends on site variables -->
  <script src="/assets/js/page/copy-button.js" async></script>

  <!-- Hide cell code -->
  <script src="/assets/js/page/hide-cell.js" async></script>

  <!-- Printing the screen -->
  <!-- Include nbinteract for interactive widgets -->
<script src="https://printjs-4de6.kxcdn.com/print.min.js" async></script>
<script>
printContent = () => {
    // MathJax displays a second version of any math for assistive devices etc.
    // This prevents double-rendering in the PDF output.
    var ignoreAssistList = [];
    assistives = document.querySelectorAll('.MathJax_Display span.MJX_Assistive_MathML').forEach((element, index) => {
        var thisId = 'MathJax-assistive-' + index.toString();
        element.setAttribute('id', thisId);
        ignoreAssistList.push(thisId)
    });

    // Print the actual content object
    printJS({
        printable: 'textbook_content',
        type: 'html',
        css: "/assets/css/styles.css",
        style: "#textbook_content {padding-top: 40px};",
        scanStyles: false,
        targetStyles: ["*"],
        ignoreElements: ignoreAssistList,
        documentTitle: "Made with Jupyter Book"
    })
};

initPrint = () => {
    document.querySelector('#interact-button-print').addEventListener('click', printContent)
}

initFunction(initPrint)
</script>

</head>

  <body>
    <!-- Include the ThebeLab config so it gets reloaded on each page -->
    <script type="text/x-thebe-config">{
    requestKernel: true,
    binderOptions: {
    repo: "ljchang/dartbrains",
    ref: "master",
    },
    codeMirrorConfig: {
    theme: "abcdef",
    mode: ""
    },
    kernelOptions: {
    kernelName: "conda-env-py36-py",
    path: "content/features/notebooks"
    }
}
</script>

    <!-- .js-show-sidebar shows sidebar by default -->
    <div id="js-textbook" class="c-textbook js-show-sidebar">
      



<nav id="js-sidebar" class="c-textbook__sidebar">
  <a href="https://dartbrains.org"><img src="/images/logo/dartbrains_logo_square_transparent.png" class="textbook_logo" id="sidebar-logo" alt="textbook logo" data-turbolinks-permanent/></a>
  <h2 class="c-sidebar__title">DartBrains</h2>
  <ul class="c-sidebar__chapters">
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/intro">
        <a class="c-sidebar__entry"
          href="/intro.html"
        >
          
          Home
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Contributing">
        <a class="c-sidebar__entry"
          href="/features/markdown/Contributing.html"
        >
          
          Contributing
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="https://github.com/ljchang/dartbrains">
        <a class="c-sidebar__entry"
          href="https://github.com/ljchang/dartbrains"
        >
          
          GitHub repository
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      
        <li><h2 class="c-sidebar__title">Course Overview</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Instructors">
        <a class="c-sidebar__entry"
          href="/features/markdown/Instructors.html"
        >
          
          Instructors
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Syllabus">
        <a class="c-sidebar__entry"
          href="/features/markdown/Syllabus.html"
        >
          
          Syllabus
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Schedule">
        <a class="c-sidebar__entry"
          href="/features/markdown/Schedule.html"
        >
          
          Schedule
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      
        <li><h2 class="c-sidebar__title">Computing Resources</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/0_Introduction_to_JupyterHub">
        <a class="c-sidebar__entry"
          href="/features/notebooks/0_Introduction_to_JupyterHub.html"
        >
          
          Getting Started with JupyterHub
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/1_Introduction_to_Programming">
        <a class="c-sidebar__entry"
          href="/features/notebooks/1_Introduction_to_Programming.html"
        >
          
          Introduction to Python
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/2_Introduction_to_Dataframes_Plotting">
        <a class="c-sidebar__entry"
          href="/features/notebooks/2_Introduction_to_Dataframes_Plotting.html"
        >
          
          Introduction to Dataframes and Plotting
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/Download_Data">
        <a class="c-sidebar__entry"
          href="/features/notebooks/Download_Data.html"
        >
          
          Download Localizer Data
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/Glossary">
        <a class="c-sidebar__entry"
          href="/features/notebooks/Glossary.html"
        >
          
          Glossary of Python Functions
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      
        <li><h2 class="c-sidebar__title">Topics</li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Intro_to_Neuroimaging">
        <a class="c-sidebar__entry"
          href="/features/markdown/Intro_to_Neuroimaging.html"
        >
          
            1.
          
          Introduction to Neuroimaging
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Signal_Measurement">
        <a class="c-sidebar__entry"
          href="/features/markdown/Signal_Measurement.html"
        >
          
            2.
          
          Measurement and Signal
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/3_Introduction_to_NeuroimagingData_in_Python">
        <a class="c-sidebar__entry"
          href="/features/notebooks/3_Introduction_to_NeuroimagingData_in_Python.html"
        >
          
            3.
          
          Introduction to Neuroimaging Data
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/5_Signal_Processing">
        <a class="c-sidebar__entry"
          href="/features/notebooks/5_Signal_Processing.html"
        >
          
            4.
          
          Signal Processing Basics
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Preprocessing">
        <a class="c-sidebar__entry"
          href="/features/markdown/Preprocessing.html"
        >
          
            5.
          
          Preprocessing
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/features/notebooks/6_Nipype_Quickstart">
              <a class="c-sidebar__entry"
                href="/features/notebooks/6_Nipype_Quickstart.html"
              >
                
                Preprocessing with Nipype Quickstart
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/features/notebooks/7_Nipype_Preprocessing">
              <a class="c-sidebar__entry"
                href="/features/notebooks/7_Nipype_Preprocessing.html"
              >
                
                Building Preprocessing Workflows with Nipype
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/features/notebooks/8_fmriprep_tutorial">
              <a class="c-sidebar__entry"
                href="/features/notebooks/8_fmriprep_tutorial.html"
              >
                
                Introduction to Automated Preprocessing with fmriprep
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/9_GLM">
        <a class="c-sidebar__entry"
          href="/features/notebooks/9_GLM.html"
        >
          
            6.
          
          Introduction to the General Linear Model
        </a>
      </li>

      
      

      

      
      

      
        

        

        <ul class="c-sidebar__sections">
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/features/notebooks/10_GLM_Single_Subject_Model">
              <a class="c-sidebar__entry"
                href="/features/notebooks/10_GLM_Single_Subject_Model.html"
              >
                
                Modeling Single Subject Data
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/features/notebooks/11_Group_Analysis">
              <a class="c-sidebar__entry"
                href="/features/notebooks/11_Group_Analysis.html"
              >
                
                Group Analysis
              </a>
            </li>
            
            
          
            
            

            
            
            
            

            <li class="c-sidebar__section" data-url="/features/notebooks/12_Thresholding_Group_Analyses">
              <a class="c-sidebar__entry"
                href="/features/notebooks/12_Thresholding_Group_Analyses.html"
              >
                
                Thresholding Group Analyses
              </a>
            </li>
            
            
          
        </ul>
      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/13_Connectivity">
        <a class="c-sidebar__entry"
          href="/features/notebooks/13_Connectivity.html"
        >
          
            7.
          
          Connectivity
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/14_Multivariate_Prediction">
        <a class="c-sidebar__entry"
          href="/features/notebooks/14_Multivariate_Prediction.html"
        >
          
            8.
          
          Multivariate Prediction
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/notebooks/15_RSA">
        <a class="c-sidebar__entry"
          href="/features/notebooks/15_RSA.html"
        >
          
            9.
          
          Representational Similarity Analysis
        </a>
      </li>

      
      

      

      
      

      

      
    
      
      
        <li class="c-sidebar__divider"></li>
        
      
      

      
      
      
      

      
      
      <li class="c-sidebar__chapter" data-url="/features/markdown/Project_Gallery">
        <a class="c-sidebar__entry"
          href="/features/markdown/Project_Gallery.html"
        >
          
          Project Gallery
        </a>
      </li>

      
      

      

      
      

      

      
    
  </ul>
  <p class="sidebar_footer">Powered by <a href="https://github.com/jupyter/jupyter-book">Jupyter Book</a></p>
</nav>

      
      <div class="c-topbar" id="top-navbar">
  <!-- We show the sidebar by default so we use .is-active -->
  <div class="c-topbar__buttons">
    <button
      id="js-sidebar-toggle"
      class="hamburger hamburger--arrowalt is-active"
    >
      <span class="hamburger-box">
        <span class="hamburger-inner"></span>
      </span>
    </button>
    <div class="buttons">
<div class="download-buttons-dropdown">
    <button id="dropdown-button-trigger" class="interact-button"><img src="/assets/images/download-solid.svg" alt="Download" /></button>
    <div class="download-buttons">
        <a href="/content/features/notebooks/14_Multivariate_Prediction.ipynb" download>
        <button id="interact-button-download" class="interact-button">.ipynb</button>
        </a>
        
        <a id="interact-button-print"><button id="interact-button-download" class="interact-button">.pdf</button></a>
    </div>
</div>


  
  
  






<a href="https://mybinder.org/v2/gh/ljchang/dartbrains/master?filepath=content%2Ffeatures%2Fnotebooks%2F14_Multivariate_Prediction.ipynb"><button class="interact-button" id="interact-button-binder"><img class="interact-button-logo" src="/assets/images/logo_binder.svg" alt="Interact" />Interact</button></a>
  





<a href="https://jupyterhub.dartmouth.edu/hub/user-redirect/git-pull?repo=https://github.com/ljchang/dartbrains/ljchang/dartbrains&amp;branch=master&amp;subPath=content%2Ffeatures%2Fnotebooks%2F14_Multivariate_Prediction.ipynb&amp;app=notebook"><button class="interact-button" id="interact-button-jupyterhub"><img class="interact-button-logo" src="/assets/images/logo_jupyterhub.svg" alt="Interact" />Interact</button></a>




</div>

  </div>
  <!-- Empty sidebar placeholder that we'll auto-fill with javascript -->
  <aside class="sidebar__right">
    <header><h4 class="nav__title"><img src="/assets/images/list-solid.svg" alt="Search" />   On this page</h4></header>
    <nav class="onthispage">
    </nav>
  </aside>
  <a href="/search.html" class="topbar-right-button" id="search-button">
    <img src="/assets/images/search-solid.svg" alt="Search" />
  </a>
</div>

      <main class="c-textbook__page" tabindex="-1">
            <div class="c-textbook__content" id="textbook_content">
                  <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Multivariate Prediction</div>
</div>
    
<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Multivariate-Prediction">Multivariate Prediction<a class="anchor-link" href="#Multivariate-Prediction"> </a></h1><p><em>Written by Luke Chang</em></p>
<p>The statistical methods we have discussed in this course so far have primarily been concerned with modeling activation in a <em>single voxel</em> and testing hypotheses in the form of "where in the brain is activation significantly greater in condition A relative condition B". As you may recall this involved using multilevel modeling with the GLM, where a voxel's time course was modeled using a first level GLM and then the contrast effect was aggregated across participants in the second level model. This procedure is often referred to as mass univariate testing and requires carefully considering how to correct for the many tests across voxels.</p>
$$\text{voxel} = \beta \cdot \text{task model} + \beta \cdot \text{covariates} + \epsilon$$<p>A completely different approach to the problem is to reverse the regression equation and identify patterns of voxel activations that predict an outcome. This might be <strong>classifying</strong> between different conditions of a task, or <strong>predicting</strong> the intensity of a continuous outcome measure (e.g., emotion, pain, working memory load, etc).</p>
$$\text{outcome} = \sum_{i}^n \beta_i\cdot \text{voxel}_i + \epsilon$$<p>Here we are learning a model of $\beta$ values across the brain that when multiplied by new data will predict the intensity of a psychological state or outcome or the probability of being a specific state.</p>
$$\text{predicted outcome} = \text{model} \cdot \text{brain data}$$<p>This is the general approach behind <em>supervised learning</em> algorithms. The intuition behind this approach is that brain signal might not  be functionally localizable to a single region, but instead might be distributed throughout the brain. Patterns of brain activity can thus be used to <em>decode</em> psychological states.</p>
<p>The focus of this supervised learning approach is to accurately predict or classify the outcome, whereas the goal in classical statistics is to test hypotheses about which regressor explains the most independent variance of the dependent variable. These two approaches are complementary, but require thinking carefully about different issues.</p>
<p>In mass-univariate testing, we spent a lot of time thinking carefully about independence of errors (e.g., multi-level models) and correcting for multiple hypothesis tests. In multivariate prediction/classification or <strong>multivoxel pattern analysis</strong> as it is often called, we need to carefully think about <strong>feature selection</strong> -  which voxels we will include in our model, and <strong>cross-validation</strong> - how well our model will <em>generalize</em> to new data. In MVPA, we typically have more features (i.e., voxels) then data points, so this requires performing feature selection or a data reduction step. The algorithms used to learn patterns come from the field of machine-learning are very good at detecting patterns, but have a tendency to <em>overfit</em> the training data.</p>
<p>In this tutorial, we will cover the basic steps of multivariate prediction/classification:</p>
<ol>
<li><strong>Data Extraction</strong> - what data should we use to train model?</li>
<li><strong>Feature Selection</strong> - which features or voxels should we use?</li>
<li><strong>Cross-validation</strong> - how do we train and test the model?</li>
<li><strong>Model Interpretation</strong> - how should we interpret the model?</li>
</ol>
<p>We will be using the nltools toolsbox to run these models, but also see (<a href="https://nilearn.github.io/">nilearn</a>, and <a href="http://www.pymvpa.org/">pyMPVA</a>). Running MVPA style analyses using multivariate regression is surprisingly easier and faster than univariate methods. All you need to do is specify the algorithm and cross-validation parameters. Currently, we have several different linear algorithms implemented from <a href="http://scikit-learn.org/stable/">scikit-learn</a> in the nltools package.</p>
<p>We encourage you to read some of the many review papers from <a href="https://www.nature.com/articles/nrn1931">Haynes &amp; Rees, 2006</a>, <a href="https://www.sciencedirect.com/science/article/pii/S1053811910010657">Naselaris et al., 2011</a>, <a href="https://www.annualreviews.org/doi/full/10.1146/annurev-neuro-062012-170325">Haxby et al., 2014</a>, <a href="http://cosanlab.com/static/papers/Woo_2017_NN.pdf">Woo et al, 2017</a>.</p>
<p>Here are some videos from <a href="https://www.youtube.com/channel/UC_BIby85hZmcItMrkAlc8eA/featured">Principles of fMRI</a> to explain these concepts in more detail:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=dJIb5bzkQHQ">MVPA Theory Part 1</a></li>
<li><p><a href="https://www.youtube.com/watch?v=zKMsJyiL5Dc">MVPA Theory Part 2</a></p>
</li>
<li><p><a href="https://www.youtube.com/watch?v=87yKz23sPnE">MVPA Applications Part 1</a></p>
</li>
<li><a href="https://www.youtube.com/watch?v=FAyPEr7eu4M">MVPA Applications Part 2</a></li>
<li><a href="https://www.youtube.com/watch?v=3iXh0FzuAjY">MVPA Applications Part 3</a></li>
</ul>
<p>Finally, there are many great books covering the machine-learning including the freely available <a href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">the elements of statistical learning</a> and <a href="http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf">pattern recognition and machine-learning</a>.</p>
<p>Here is a helpful <a href="http://blog.kaggle.com/2016/07/21/approaching-almost-any-machine-learning-problem-abhishek-thakur/">blog post</a> on different algorithms and reasonable default parameters.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-Extraction">Data Extraction<a class="anchor-link" href="#Data-Extraction"> </a></h2><p>The first step in MVPA is to decide what data you want to use to predict your outcome variable. Typically, researchers perform a temporal data reduction step, which involves estimating a standard univariate GLM using a single subject first-level model. This model will specify regressors for a single trial, or model a specific condition type over many trials. Just as in the standard univariate approach, these regressors are convolved with an HRF function. These models also usually include nuisance covariates (e.g., motion parameters, spikes, filters, linear trends, etc.). The estimated beta maps from this temporal reduction step are then used as the input data into the prediction model. Note that it is also possible to learn a <em>spatiotemporal</em> model that includes the voxels from each TR measured during a a given trial, but this is less common in practice.</p>
<p>First, let's load the modules we need for this analysis.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">from</span> <span class="nn">nltools.data</span> <span class="k">import</span> <span class="n">Brain_Data</span>

<span class="n">netid</span> <span class="o">=</span> <span class="s1">&#39;f00275v&#39;</span>
<span class="n">base_dir</span> <span class="o">=</span> <span class="s1">&#39;/dartfs/rc/lab/P/Psych60/&#39;</span>
<span class="n">base_dir</span> <span class="o">=</span> <span class="s1">&#39;/Volumes/Psych60/&#39;</span>
<span class="n">output_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;students_output&#39;</span><span class="p">,</span> <span class="n">netid</span><span class="p">)</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;brainomics_data&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now let's load some data to train a model.</p>
<p>In this example, let's continue to use data from the Pinel Localizer Task that we have been using throughout all of our tutorials. For our first analysis, let's attempt to classify <em>Left</em> from <em>Right</em> motor activation. We will load a single beta image for each subject that we already estimated in earlier tutorials. We are sorting the files so that subjects are in the same order, then we are stacking all of the images together using <code>.append()</code> such that the data looks like $Subject_{1, left}, ... Subject_{n, left}, Subject_{1, right}, ... Subject_{n, right}$.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">left_file_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span><span class="s1">&#39;*_beta_motor_left_visual.nii.gz&#39;</span><span class="p">))</span>
<span class="n">left_file_list</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">left</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">left_file_list</span><span class="p">)</span>

<span class="n">right_file_list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;*&#39;</span><span class="p">,</span><span class="s1">&#39;*_beta_motor_right_visual.nii.gz&#39;</span><span class="p">))</span>
<span class="n">right_file_list</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">right</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">right_file_list</span><span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">left</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">right</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next, we need to create the labels or outcome variable to train the model. We will make a vector of ones and zeros to indicate left images and right images, respectively.</p>
<p>We assign this vector to the <code>data.Y</code> attribute of the Brain_Data instance.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">left_file_list</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">left_file_list</span><span class="p">))]))</span>

<span class="n">data</span><span class="o">.</span><span class="n">Y</span> <span class="o">=</span> <span class="n">Y</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>okay, we are ready to go. Let's now train our first model. We will use a support vector machine (SVM) to learn a pattern that can discribute left from right motor responses across all 29 participants.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_stats</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span><span class="s2">&quot;linear&quot;</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>overall accuracy: 1.00
threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ValueError</span>                                Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-8-69aec54b7ae2&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">----&gt; 1</span><span class="ansi-red-fg"> </span>svm_stats <span class="ansi-blue-fg">=</span> data<span class="ansi-blue-fg">.</span>predict<span class="ansi-blue-fg">(</span>algorithm<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;svm&#39;</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span><span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;kernel&#39;</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">&#34;linear&#34;</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/nltools/data/brain_data.py</span> in <span class="ansi-cyan-fg">predict</span><span class="ansi-blue-fg">(self, algorithm, cv_dict, plot, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1090</span>                                 output<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;roc&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> Roc<span class="ansi-blue-fg">(</span>input_values<span class="ansi-blue-fg">=</span>output<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;prob_xval&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span> binary_outcome<span class="ansi-blue-fg">=</span>output<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;Y&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>astype<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;bool&#39;</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1091</span>                         output<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;roc&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>plot<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1092</span><span class="ansi-red-fg">             </span>output<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;weight_map&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>plot<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1093</span> 
<span class="ansi-green-intense-fg ansi-bold">   1094</span>         <span class="ansi-green-fg">return</span> output

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/nltools/data/brain_data.py</span> in <span class="ansi-cyan-fg">plot</span><span class="ansi-blue-fg">(self, limit, anatomical, view, threshold_upper, threshold_lower, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    441</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    442</span>                 <span class="ansi-red-fg"># anatomical = nib.load(resolve_mni_path(MNI_Template)[&#39;plot&#39;])</span>
<span class="ansi-green-fg">--&gt; 443</span><span class="ansi-red-fg">                 </span>anatomical <span class="ansi-blue-fg">=</span> get_mni_from_img_resolution<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> img_type<span class="ansi-blue-fg">=</span><span class="ansi-blue-fg">&#39;plot&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    444</span> 
<span class="ansi-green-intense-fg ansi-bold">    445</span>             <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">.</span>ndim <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/nltools/utils.py</span> in <span class="ansi-cyan-fg">get_mni_from_img_resolution</span><span class="ansi-blue-fg">(brain, img_type)</span>
<span class="ansi-green-intense-fg ansi-bold">     83</span>     voxel_dims <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>unique<span class="ansi-blue-fg">(</span>res_array<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     84</span>     <span class="ansi-green-fg">if</span> len<span class="ansi-blue-fg">(</span>voxel_dims<span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">!=</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 85</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">raise</span> ValueError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#34;Voxels are not isometric and cannot be visualized in standard space&#34;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     86</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     87</span>         dim <span class="ansi-blue-fg">=</span> str<span class="ansi-blue-fg">(</span>int<span class="ansi-blue-fg">(</span>voxel_dims<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> <span class="ansi-blue-fg">&#39;mm&#39;</span>

<span class="ansi-red-fg">ValueError</span>: Voxels are not isometric and cannot be visualized in standard space</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>the results of this analysis are stored in a dictionary.</p>
<ul>
<li><strong>Y</strong>: training labels</li>
<li><strong>yfit_all</strong>: predicted labels</li>
<li><strong>dist_from_hyperplane_all</strong>: how far the prediction is from the classifier hyperplane through feature space, &gt; 0 indicates left, while &lt; 0 indicates right.</li>
<li><strong>intercept</strong>: scalar value which indicates how much to add to the prediction to get the correct class label.</li>
<li><strong>weight_map</strong>: multivariate brain model</li>
<li><strong>mcr_all</strong>: overall model accuracy in classifying training data</li>
</ul>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">svm_stats</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>dict_keys([&#39;Y&#39;, &#39;yfit_all&#39;, &#39;dist_from_hyperplane_all&#39;, &#39;intercept&#39;, &#39;weight_map&#39;, &#39;mcr_all&#39;])
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see that that the model can perfectly discriminate between left and right using the training data. This is great, but we definitely shouldn't get our hopes up as this model is completely being overfit to the training data. To get an unbiased estimate of the accuracy we will need to test the model on independent data.</p>
<p>We can also examine the model weights more thoroughly by plotting it.  This shows that we see a very nice expected motor cortex representation, but notice that there are many other regions also contributing to the prediction.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_stats</span><span class="p">[</span><span class="s1">&#39;weight_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iplot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="812fa572-1941-4d49-b5a0-630cd4a4492c"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#812fa572-1941-4d49-b5a0-630cd4a4492c');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "fe64b7b304c74c4ba045ebb7f98e1e7d", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Feature-Selection">Feature Selection<a class="anchor-link" href="#Feature-Selection"> </a></h2><p>Feature selection describes the process of deciding which features to include when training the model.  Here it is simply, which voxels should we use to train the model?</p>
<p>There are several ways to perform feature selection.  Searchlights are a popular approach.  I personally have a preference for using parcellation schemes.</p>
<ul>
<li>Parcellations are orders of magnitude computationally less expensive than searchlights.</li>
<li>Parcellations are easier to correct for multiple comparisons (50 vs 300k)</li>
<li>Parcellations can include regions distributed throughout the brain (searchlights are only local)</li>
<li>Parcellations can be integrated into a meta-model.</li>
</ul>
<p>Here we download a single 50 parcel map from a forthcoming paper on conducting automated parcellations using neurosynth.</p>

<pre><code>Yarkoni, T., de la Vega, A., &amp; Chang, L.J. (In Prep).  Fully automated meta-analytic clustering and decoding of human brain activity

</code></pre>
<p>Some of the details can be found <a href="http://cosanlab.com/static/papers/delaVega_2016_JNeuro.pdf">here</a></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">mask</span> <span class="o">=</span> <span class="n">Brain_Data</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_dir</span><span class="p">,</span> <span class="s1">&#39;resources&#39;</span><span class="p">,</span> <span class="s1">&#39;masks&#39;</span><span class="p">,</span> <span class="s1">&#39;k50_2mm.nii.gz&#39;</span><span class="p">))</span>
<span class="n">mask_x</span> <span class="o">=</span> <span class="n">expand_mask</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_14_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's combine two parcels (left-26 and right-47 motor) to make a mask and use this as a feature extract method.</p>
<p>This means that we will only be training voxels to discriminate between the two conditions if they are in the right or left motor cortex.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">motor</span> <span class="o">=</span> <span class="n">mask_x</span><span class="p">[[</span><span class="mi">26</span><span class="p">,</span><span class="mi">47</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">data_masked</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">apply_mask</span><span class="p">(</span><span class="n">motor</span><span class="p">)</span>

<span class="n">svm_stats_masked</span> <span class="o">=</span> <span class="n">data_masked</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span><span class="s2">&quot;linear&quot;</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>overall accuracy: 1.00
threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_16_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_stats_masked</span><span class="p">[</span><span class="s1">&#39;weight_map&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">iplot</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="74430ff1-8856-41bf-92fa-24a06932f08e"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#74430ff1-8856-41bf-92fa-24a06932f08e');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "5d25d407e76145f2ba8c54dae6701796", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can see that this also correctly learns that left motor cortex is positive while right cortex is negative - left vs right classification.  In addition, the training accuracy is still 100%.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cross-Validation">Cross-Validation<a class="anchor-link" href="#Cross-Validation"> </a></h2><p>Clearly, our model is overfitting our training data. The next thing we need to do is to estimate how well our model will generalize to <em>new</em> data.  Ideally, we would have left out some data to test after we are done training and tuning our models.  This is called <strong>holdout data</strong> and should only be tested once when you are ready to write up your paper.</p>
<p>However, we don't always have the luxury of having so much extra data and also we might want to tune our model using different algorithms, features, or adjusting hyperparameters of the model.</p>
<p>The best way to do this, is to use <strong>cross-validation</strong>. The idea behind this is to subdivide the data into training and testing partitions - k-folds cross-validation is a common method - divide the data into $k$ separate folds and use all of the data except for one fold to train the model and then test the model using the left out fold. We iterate over this process for each fold. For example, consider k=2 or split-half cross-validation.</p>
<p><img src="../../images/multivariate/cv.png" alt="cv.png"></p>
<p>We divide the data into two partitions. We estimate the model using half of the data and test it on the other half and then evaluate how well the model performed. As you can see from this simulation, the model will almost always fit the training data better than the test data, because it is overfitting to the noise inherent to the training data, which is presumably independent across folds. More training data will lead to better estimation. This means that a k &gt; 2 will usually result in better model estimates. When k=number of subjects, we call this <em>leave-one-subject-out</em> cross-validation.</p>
<p>One key concept to note is that it is very important to ensure that the data is independent across folds or this will lead to a biased and usually overly optimistic generalization. This can happen if you have multiple data from the same participant. You will need to make sure that the data from the same participants are held out together. We can do this by passing a vector of group labels to make sure that data within the same group are held out together. Another approach is to make sure that the data is equally representative across folds. We can use something called stratified sampling to achieve this (see <a href="http://cosanlab.com/static/papers/Changetal2015PLoSBiology.pdf">here</a> for more details)</p>
<p>Let's add cross-validation to our SVM model.  We will start with $k=5$, and will pass a vector indicating subject labels as our grouping variable.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sub_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">right_file_list</span><span class="p">]</span>
<span class="n">subject_id</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">sub_list</span> <span class="o">+</span> <span class="n">sub_list</span><span class="p">)</span>

<span class="n">svm_stats</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="n">cv_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;kfolds&#39;</span><span class="p">,</span><span class="s1">&#39;n_folds&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;subject_id&#39;</span><span class="p">:</span><span class="n">subject_id</span><span class="p">},</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span><span class="s2">&quot;linear&quot;</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>overall accuracy: 1.00
overall CV accuracy: 0.93
threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_20_2.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_20_3.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we see that our whole-brain model is still performing very well ~94% accuracy.</p>
<p>What about our masked version?</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">motor</span> <span class="o">=</span> <span class="n">mask_x</span><span class="p">[[</span><span class="mi">26</span><span class="p">,</span><span class="mi">47</span><span class="p">]]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">data_masked</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">apply_mask</span><span class="p">(</span><span class="n">motor</span><span class="p">)</span>

<span class="n">svm_stats_masked</span> <span class="o">=</span> <span class="n">data_masked</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="n">cv_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;kfolds&#39;</span><span class="p">,</span><span class="s1">&#39;n_folds&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;subject_id&#39;</span><span class="p">:</span><span class="n">subject_id</span><span class="p">},</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span><span class="s2">&quot;linear&quot;</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>overall accuracy: 1.00
overall CV accuracy: 0.98
threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_22_2.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_22_3.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Wow, it looks like the model with feature selection actually outperforms the whole-brain model in cross-validation! 98% &gt; 93% accuracy.</p>
<p>Why do you think this is the case?</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Regularization">Regularization<a class="anchor-link" href="#Regularization"> </a></h2><p>Another key concept that is used to help with feature selection is called regularization. Regularization is a method to help deal with <a href="https://en.wikipedia.org/wiki/Multicollinearity">multicollinearity</a> and also avoid <a href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>. Overfitting occurs when you have an overly complex model such as having more features(Xs) than observations(Y). For instance, if you try to fit 10 observations with 10 features, each coefficient can be adjusted for a perfect fit but it wouldn't generalize well. In other cases, you might face the problem of feature selection. If you have numerous variables, it is time consuming to try every single combination of features in your model to see what yields the best result. 
<img src="http://i.stack.imgur.com/0NbOY.png"></p>
<p>Regularization attempts to solve this problem by introducting a loss function that penalizes the model for each additional features added to the model. There are two common types of loss functions <em>L1</em> and <em>L2</em>. L1 regularization is commonly referred to as <em>lasso</em> and leads to sparse solutions, where some regressors are set to zero. L2 regularization, does not lead to a sparse solution, but instead shrinks collinear variables towards zero. Elastic Nets are a type of model that combine L1 and L2 penalizations.</p>
<h3 id="Lasso-regression---L1-Regularization">Lasso regression - L1 Regularization<a class="anchor-link" href="#Lasso-regression---L1-Regularization"> </a></h3><p>In short, <a href="http://stats.stackexchange.com/questions/17251/what-is-the-lasso-in-regression-analysis">Lasso</a> is a feature selection method that reduces the number of features to use in a regression.<br>
This is useful if you have a lot of variables that are correlated or you have more variables than observations.</p>
<h3 id="Ridge-Regression---L2-Regularization">Ridge Regression - L2 Regularization<a class="anchor-link" href="#Ridge-Regression---L2-Regularization"> </a></h3><p>The goal of the ridge function is to choose a penalty $\lambda$ for which the coefficients are not rapidly changing and have sensible signs. It is especially useful when data suffers from multicollinearity, that is some of your predictor variables are highly correlated. Unlike LASSO, ridge does not produce a sparse solution, but rather shrinks variables that are highly collinear towards zero.</p>
<h3 id="How-do-we-determine-the-penalty-value?">How do we determine the penalty value?<a class="anchor-link" href="#How-do-we-determine-the-penalty-value?"> </a></h3><p>Both Lasso and Ridge regressions have a penalty hyperparameter $\lambda$. Essentially, we want to select the regularization parameter by identifying the one from a set of possible values (e.g. grid search) that results in the best fit of the model to the data.  However, it is important to note that it is easy to introduce bias into this process by trying a bunch of alphas and selecting the one that works best.  This can lead to optimistic evaluations of how well your model works.</p>
<p>Cross-validation is an ideal method to deal with this.  We can use cross-validation to select the alpha while adding minimal bias to the overall model prediction.</p>
<p>Here we will demonstrate using both to select an optimal value of the regularization parameter alpha of the Lasso estimator from an example provided by <a href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html">scikit-learn</a>. For cross-validation, we will use a nested cross-validation as implemented by the LassoCV algorithm.  Note that these examples with nested cross-validation take much longer to run.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ridge_stats</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ridgeClassifier&#39;</span><span class="p">,</span> 
                        <span class="n">cv_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;kfolds&#39;</span><span class="p">,</span><span class="s1">&#39;n_folds&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span><span class="s1">&#39;subject_id&#39;</span><span class="p">:</span><span class="n">subject_id</span><span class="p">},</span>
                           <span class="o">**</span><span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="o">.</span><span class="mi">01</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:839: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:839: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:839: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:839: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:839: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>overall accuracy: 1.00
overall CV accuracy: 0.91
threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_25_2.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_25_3.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ridge_stats</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;ridgeCV&#39;</span><span class="p">,</span>
    <span class="n">cv_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;kfolds&#39;</span><span class="p">,</span><span class="s1">&#39;n_folds&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;subject_id&#39;</span><span class="p">:</span><span class="n">subject_id</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lasso_cv_stats</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;lassoCV&#39;</span><span class="p">,</span>
    <span class="n">cv_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;kfolds&#39;</span><span class="p">,</span><span class="s1">&#39;n_folds&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;subject_id&#39;</span><span class="p">:</span><span class="n">subject_id</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for &#39;cv&#39; instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.
  warnings.warn(CV_WARNING, FutureWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.
  ConvergenceWarning)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">-----------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyboardInterrupt</span>                     Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-102-4c6cf2662323&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> ridge_stats = data.predict(algorithm=&#39;lassoCV&#39;,
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg">     cv_dict={&#39;type&#39;: &#39;kfolds&#39;,&#39;n_folds&#39;: 5, &#39;subject_id&#39;:subject_id})
</span>
<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/nltools/data/brain_data.py</span> in <span class="ansi-cyan-fg">predict</span><span class="ansi-blue-fg">(self, algorithm, cv_dict, plot, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    844</span> 
<span class="ansi-green-intense-fg ansi-bold">    845</span>         <span class="ansi-red-fg"># Overall Fit for weight map</span>
<span class="ansi-green-fg">--&gt; 846</span><span class="ansi-red-fg">         </span>predictor<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">,</span> output<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;Y&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    847</span>         output<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;yfit_all&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> predictor<span class="ansi-blue-fg">.</span>predict<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>data<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    848</span>         <span class="ansi-green-fg">if</span> predictor_settings<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;prediction_type&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">==</span> <span class="ansi-blue-fg">&#39;classification&#39;</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, X, y)</span>
<span class="ansi-green-intense-fg ansi-bold">   1205</span>                 for train, test in folds)
<span class="ansi-green-intense-fg ansi-bold">   1206</span>         mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,
<span class="ansi-green-fg">-&gt; 1207</span><span class="ansi-red-fg">                              **_joblib_parallel_args(prefer=&#34;threads&#34;))(jobs)
</span><span class="ansi-green-intense-fg ansi-bold">   1208</span>         mse_paths <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>reshape<span class="ansi-blue-fg">(</span>mse_paths<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">(</span>n_l1_ratio<span class="ansi-blue-fg">,</span> len<span class="ansi-blue-fg">(</span>folds<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">-</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1209</span>         mean_mse <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>mean<span class="ansi-blue-fg">(</span>mse_paths<span class="ansi-blue-fg">,</span> axis<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self, iterable)</span>
<span class="ansi-green-intense-fg ansi-bold">    915</span>             <span class="ansi-red-fg"># remaining jobs.</span>
<span class="ansi-green-intense-fg ansi-bold">    916</span>             self<span class="ansi-blue-fg">.</span>_iterating <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">False</span>
<span class="ansi-green-fg">--&gt; 917</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>dispatch_one_batch<span class="ansi-blue-fg">(</span>iterator<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    918</span>                 self<span class="ansi-blue-fg">.</span>_iterating <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_original_iterator <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span>
<span class="ansi-green-intense-fg ansi-bold">    919</span> 

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py</span> in <span class="ansi-cyan-fg">dispatch_one_batch</span><span class="ansi-blue-fg">(self, iterator)</span>
<span class="ansi-green-intense-fg ansi-bold">    757</span>                 <span class="ansi-green-fg">return</span> <span class="ansi-green-fg">False</span>
<span class="ansi-green-intense-fg ansi-bold">    758</span>             <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 759</span><span class="ansi-red-fg">                 </span>self<span class="ansi-blue-fg">.</span>_dispatch<span class="ansi-blue-fg">(</span>tasks<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    760</span>                 <span class="ansi-green-fg">return</span> <span class="ansi-green-fg">True</span>
<span class="ansi-green-intense-fg ansi-bold">    761</span> 

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py</span> in <span class="ansi-cyan-fg">_dispatch</span><span class="ansi-blue-fg">(self, batch)</span>
<span class="ansi-green-intense-fg ansi-bold">    714</span>         <span class="ansi-green-fg">with</span> self<span class="ansi-blue-fg">.</span>_lock<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    715</span>             job_idx <span class="ansi-blue-fg">=</span> len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_jobs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 716</span><span class="ansi-red-fg">             </span>job <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_backend<span class="ansi-blue-fg">.</span>apply_async<span class="ansi-blue-fg">(</span>batch<span class="ansi-blue-fg">,</span> callback<span class="ansi-blue-fg">=</span>cb<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    717</span>             <span class="ansi-red-fg"># A job can complete so quickly than its callback is</span>
<span class="ansi-green-intense-fg ansi-bold">    718</span>             <span class="ansi-red-fg"># called before we get here, causing self._jobs to</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py</span> in <span class="ansi-cyan-fg">apply_async</span><span class="ansi-blue-fg">(self, func, callback)</span>
<span class="ansi-green-intense-fg ansi-bold">    180</span>     <span class="ansi-green-fg">def</span> apply_async<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> func<span class="ansi-blue-fg">,</span> callback<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    181</span>         <span class="ansi-blue-fg">&#34;&#34;&#34;Schedule a func to be run&#34;&#34;&#34;</span>
<span class="ansi-green-fg">--&gt; 182</span><span class="ansi-red-fg">         </span>result <span class="ansi-blue-fg">=</span> ImmediateResult<span class="ansi-blue-fg">(</span>func<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    183</span>         <span class="ansi-green-fg">if</span> callback<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    184</span>             callback<span class="ansi-blue-fg">(</span>result<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, batch)</span>
<span class="ansi-green-intense-fg ansi-bold">    547</span>         <span class="ansi-red-fg"># Don&#39;t delay the application, to avoid keeping the input</span>
<span class="ansi-green-intense-fg ansi-bold">    548</span>         <span class="ansi-red-fg"># arguments in memory</span>
<span class="ansi-green-fg">--&gt; 549</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>results <span class="ansi-blue-fg">=</span> batch<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    550</span> 
<span class="ansi-green-intense-fg ansi-bold">    551</span>     <span class="ansi-green-fg">def</span> get<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py</span> in <span class="ansi-cyan-fg">__call__</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">    223</span>         <span class="ansi-green-fg">with</span> parallel_backend<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_backend<span class="ansi-blue-fg">,</span> n_jobs<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>_n_jobs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    224</span>             return [func(*args, **kwargs)
<span class="ansi-green-fg">--&gt; 225</span><span class="ansi-red-fg">                     for func, args, kwargs in self.items]
</span><span class="ansi-green-intense-fg ansi-bold">    226</span> 
<span class="ansi-green-intense-fg ansi-bold">    227</span>     <span class="ansi-green-fg">def</span> __len__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py</span> in <span class="ansi-cyan-fg">&lt;listcomp&gt;</span><span class="ansi-blue-fg">(.0)</span>
<span class="ansi-green-intense-fg ansi-bold">    223</span>         <span class="ansi-green-fg">with</span> parallel_backend<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>_backend<span class="ansi-blue-fg">,</span> n_jobs<span class="ansi-blue-fg">=</span>self<span class="ansi-blue-fg">.</span>_n_jobs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    224</span>             return [func(*args, **kwargs)
<span class="ansi-green-fg">--&gt; 225</span><span class="ansi-red-fg">                     for func, args, kwargs in self.items]
</span><span class="ansi-green-intense-fg ansi-bold">    226</span> 
<span class="ansi-green-intense-fg ansi-bold">    227</span>     <span class="ansi-green-fg">def</span> __len__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py</span> in <span class="ansi-cyan-fg">_path_residuals</span><span class="ansi-blue-fg">(X, y, train, test, path, path_params, alphas, l1_ratio, X_order, dtype)</span>
<span class="ansi-green-intense-fg ansi-bold">   1020</span>     <span class="ansi-red-fg"># X is copied and a reference is kept here</span>
<span class="ansi-green-intense-fg ansi-bold">   1021</span>     X_train <span class="ansi-blue-fg">=</span> check_array<span class="ansi-blue-fg">(</span>X_train<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;csc&#39;</span><span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">=</span>dtype<span class="ansi-blue-fg">,</span> order<span class="ansi-blue-fg">=</span>X_order<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">-&gt; 1022</span><span class="ansi-red-fg">     </span>alphas<span class="ansi-blue-fg">,</span> coefs<span class="ansi-blue-fg">,</span> _ <span class="ansi-blue-fg">=</span> path<span class="ansi-blue-fg">(</span>X_train<span class="ansi-blue-fg">,</span> y_train<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>path_params<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1023</span>     <span class="ansi-green-fg">del</span> X_train<span class="ansi-blue-fg">,</span> y_train
<span class="ansi-green-intense-fg ansi-bold">   1024</span> 

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py</span> in <span class="ansi-cyan-fg">lasso_path</span><span class="ansi-blue-fg">(X, y, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, **params)</span>
<span class="ansi-green-intense-fg ansi-bold">    264</span>                      alphas<span class="ansi-blue-fg">=</span>alphas<span class="ansi-blue-fg">,</span> precompute<span class="ansi-blue-fg">=</span>precompute<span class="ansi-blue-fg">,</span> Xy<span class="ansi-blue-fg">=</span>Xy<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    265</span>                      copy_X<span class="ansi-blue-fg">=</span>copy_X<span class="ansi-blue-fg">,</span> coef_init<span class="ansi-blue-fg">=</span>coef_init<span class="ansi-blue-fg">,</span> verbose<span class="ansi-blue-fg">=</span>verbose<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 266</span><span class="ansi-red-fg">                      positive=positive, return_n_iter=return_n_iter, **params)
</span><span class="ansi-green-intense-fg ansi-bold">    267</span> 
<span class="ansi-green-intense-fg ansi-bold">    268</span> 

<span class="ansi-green-fg">~/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py</span> in <span class="ansi-cyan-fg">enet_path</span><span class="ansi-blue-fg">(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)</span>
<span class="ansi-green-intense-fg ansi-bold">    476</span>             model = cd_fast.enet_coordinate_descent(
<span class="ansi-green-intense-fg ansi-bold">    477</span>                 coef_<span class="ansi-blue-fg">,</span> l1_reg<span class="ansi-blue-fg">,</span> l2_reg<span class="ansi-blue-fg">,</span> X<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> max_iter<span class="ansi-blue-fg">,</span> tol<span class="ansi-blue-fg">,</span> rng<span class="ansi-blue-fg">,</span> random<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 478</span><span class="ansi-red-fg">                 positive)
</span><span class="ansi-green-intense-fg ansi-bold">    479</span>         <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    480</span>             raise ValueError(&#34;Precompute should be one of True, False, &#34;

<span class="ansi-red-fg">KeyboardInterrupt</span>: </pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Classification-and-Class-Imbalance">Classification and Class Imbalance<a class="anchor-link" href="#Classification-and-Class-Imbalance"> </a></h2><p>One important thing to note is that when you use classification, it is important to account for class imbalances. i.e., that there might be unequal amounts of data in each group.  The reason why this is a problem is that chance classification is no longer at 50% when there is a class imbalance.  Suppose you were trying to classify A from B, but 80% of the data were instances of B. A classifier that always says B, would be correct 80% of the time.</p>
<p>There are several different ways to deal with class imbalance.</p>
<p>1) <strong>Make the Class Sizes Equal</strong> You can randomly sample data that is overrepresented to create your own balanced dataset. Advantages are that the data classes will be balanced. The disadvantage of this approach is that you are not using all of your data.</p>
<p>2) <strong>Average Data</strong> You can average all of the data within a class so that each participant only has one data point per class. Advantages are the data are balanced. Disadvantages are that you have dramatically reduced the amount of data going into training the model.</p>
<p>3) <strong>Balance Class Weights</strong> If you are using SVM, you can set <code>class_weight=balanced</code>. The general idea is to increase the penalty for misclassifying minority classes to prevent them from being overwhelmed by the majority class. See <a href="https://chrisalbon.com/machine_learning/support_vector_machines/imbalanced_classes_in_svm/">here</a> for a brief overview.</p>
<p>When testing your model you can also make adjustments to calculate a balanced accuracy. Scikit-learn has the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html"><code>balanced_accuracy_score</code> method</a>, which implements the technique outlined in <a href="https://ieeexplore.ieee.org/document/5597285">this</a> paper. It essentially defines accuracy as the average recall obtained on each class.</p>
<p>Let's test an example using the <code>'class_weight'='balanced'</code> approach.</p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">svm_stats</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">algorithm</span><span class="o">=</span><span class="s1">&#39;svm&#39;</span><span class="p">,</span> <span class="n">cv_dict</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;kfolds&#39;</span><span class="p">,</span><span class="s1">&#39;n_folds&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span> <span class="s1">&#39;subject_id&#39;</span><span class="p">:</span><span class="n">subject_id</span><span class="p">},</span> <span class="o">**</span><span class="p">{</span><span class="s1">&#39;class_weight&#39;</span><span class="p">:</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:</span><span class="s2">&quot;linear&quot;</span><span class="p">})</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/Users/lukechang/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>overall accuracy: 1.00
overall CV accuracy: 0.93
threshold is ignored for simple axial plots
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_29_2.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../images/features/notebooks/14_Multivariate_Prediction_29_3.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    
            </div>
            <div class="c-textbook__footer" id="textbook_footer">
              
<nav class="c-page__nav">
  
    
    

    <a id="js-page__nav__prev" class="c-page__nav__prev" href="/features/notebooks/13_Connectivity.html">
       <span class="u-margin-right-tiny"></span> Connectivity
    </a>
  

  
    

    
    <a id="js-page__nav__next" class="c-page__nav__next" href="/features/notebooks/15_RSA.html">
      Representational Similarity Analysis <span class="u-margin-right-tiny"></span> 
    </a>
  
</nav>

              <footer>
  <p class="footer">This page was created by <a href="http://www.lukejchang.com/">Luke Chang<a> using <a href="https://jupyterbook.org/">Jupyter Book</a></p>
</footer>

            </div>

        </div>
      </main>
    </div>
  </body>
</html>
